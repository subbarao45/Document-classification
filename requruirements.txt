import json

def restructure_json(input_file_path):
    # Read the input JSON from the file
    with open(input_file_path, "r") as input_file:
        input_json = json.load(input_file)

    # Ensure input_json is a list
    if not isinstance(input_json, list):
        raise ValueError("Expected a list as the root element, but got something else.")

    structured_data = {"pages": []}

    # Process each item in the list
    for page in input_json:
        if not isinstance(page, dict):
            print(f"Skipping invalid page entry: {page}")
            continue

        # Extract text and page number
        text = page.get("text", "").strip()
        page_number = page.get("page_number", 0)

        # Debugging print statement to identify empty or missing text
        if not text:
            print(f"[!] Warning: Empty or missing text on page {page_number}")

        structured_data["pages"].append({
            "page_number": page_number,
            "content": text if text else "[No content available]"  # Placeholder for empty content
        })

    return structured_data

# Example usage
input_file = "path/to/your/extracted_pdf_data.json"  # Replace with your JSON file path
restructured_data = restructure_json(input_file)
print(json.dumps(restructured_data, indent=2))







import json

def restructure_json(input_file_path):
    # Read the input JSON from the file
    with open(input_file_path, "r") as input_file:
        input_json = json.load(input_file)

    # Ensure input_json is a list
    if not isinstance(input_json, list):
        raise ValueError("Expected a list as the root element, but got something else.")

    structured_data = {"pages": []}

    # Process each item in the list
    for page in input_json:
        if not isinstance(page, dict):
            print(f"Skipping invalid page entry: {page}")
            continue

        # Extract text and page number
        text = page.get("text", "").strip()
        page_number = page.get("page_number", 0)

        structured_data["pages"].append({
            "page_number": page_number,
            "content": text
        })

    return structured_data

# Example usage
input_file = "path/to/your/extracted_pdf_data.json"  # Replace with your JSON file path
restructured_data = restructure_json(input_file)
print(json.dumps(restructured_data, indent=2))










import os
import json
from collections import defaultdict

def restructure_and_store_json(input_file_path, output_dir="outputs_sdr"):
    restructured_data = {
        "metadata": {},
        "pages": []
    }

    os.makedirs(output_dir, exist_ok=True)

    with open(input_file_path, "r") as input_file:
        input_json = json.load(input_file)

    # Ensure input_json is a list
    if not isinstance(input_json, list):
        raise ValueError("Expected a list of image entries, but got something else.")

    # Group images by page number
    page_images = defaultdict(list)
    for entry in input_json:
        page_number = entry.get("page_number", None)
        image_name = entry.get("image_name", entry.get("image name", "")).strip()
        image_description = entry.get("image_description", entry.get("image description", "")).strip()

        if page_number is not None and image_name:
            page_images[page_number].append({
                "image_name": image_name,
                "image_description": image_description
            })

    # Create page entries with images
    for page_number, images in page_images.items():
        restructured_data["pages"].append({
            "page_number": page_number,
            "text": f"Placeholder text for page {page_number}",  # Replace with actual page text if needed
            "images": images
        })

    # Define output file path and save JSON
    output_file_path = os.path.join(output_dir, "restructured_pdf_data.json")
    with open(output_file_path, "w") as output_file:
        json.dump(restructured_data, output_file, indent=2)
    print(f"[+] Restructured data saved to {output_file_path}")

    # Return the restructured data
    return restructured_data

# Example usage
input_file = "path/to/your/merged_text_image.json"  # Replace with the correct file path
restructured_data = restructure_and_store_json(input_file)

# Printing the returned data if needed
print(json.dumps(restructured_data, indent=2))










import os
import json

def save_json(data, output_file_path):
    with open(output_file_path, "w") as json_file:
        json.dump(data, json_file, indent=2)
    print(f"[+] Data saved to {output_file_path}")

def restructure_and_store_json(input_file_path, output_dir="outputs_sdr"):
    restructured_data = {
        "metadata": {},
        "pages": []
    }

    os.makedirs(output_dir, exist_ok=True)

    with open(input_file_path, "r") as input_file:
        input_json = json.load(input_file)

    # Copy metadata
    restructured_data["metadata"] = input_json.get("metadata", {})

    # Process pages
    for page in input_json.get("pages", []):
        text = page.get("text", "").strip()
        combined_content = text

        # Append image descriptions
        for image in page.get("images", []):
            image_description = image.get("image_description", image.get("image description", "")).strip()
            if image_description:
                combined_content += f" The image shows: {image_description}."

        restructured_data["pages"].append({
            "page_number": page.get("page_number", 0),
            "text": combined_content
        })

    # Define output file path and save JSON
    output_file_path = os.path.join(output_dir, "restructured_pdf_data.json")
    save_json(restructured_data, output_file_path)

    # Return the restructured data for further use if needed
    return restructured_data

# Example usage
input_file = "path/to/your/merged_text_image.json"  # Replace with your input JSON file path
restructured_data = restructure_and_store_json(input_file)








import os
import json

def save_json(data, output_file_path):
    """Save the given data to a JSON file."""
    with open(output_file_path, "w") as json_file:
        json.dump(data, json_file, indent=2)
    print(f"[+] Data saved to {output_file_path}")

def restructure_and_store_json(input_file_path, output_dir="outputs_sdr"):
    # Initialize the structure similar to your provided example
    restructured_data = {
        "metadata": {},
        "pages": []
    }

    # Ensure the output directory exists
    os.makedirs(output_dir, exist_ok=True)

    try:
        # Read input JSON from the provided file path
        with open(input_file_path, "r") as input_file:
            input_json = json.load(input_file)

        # Copy metadata from the input JSON if available
        restructured_data["metadata"] = input_json.get("metadata", {})

        # Process pages
        pages = input_json.get("pages", [])
        for page in pages:
            # Ensure 'text' and 'page_number' are present
            text = page.get("text", "").strip()
            page_number = page.get("page_number", 0)

            # Initialize combined content with text
            combined_content = text

            # Check for images and append descriptions if available
            images = page.get("images", [])
            if isinstance(images, list):
                for image in images:
                    if isinstance(image, dict):
                        # Handle inconsistent keys ('image description' or 'image_description')
                        image_description = image.get("image_description", image.get("image description", "")).strip()
                        if image_description:
                            combined_content += f" The image shows: {image_description}."

            # Append the processed page data
            restructured_data["pages"].append({
                "page_number": page_number,
                "text": combined_content
            })

        # Define output file path
        output_file_path = os.path.join(output_dir, "restructured_pdf_data.json")

        # Save the restructured data using save_json function
        save_json(restructured_data, output_file_path)

    except json.JSONDecodeError as e:
        print(f"Error decoding JSON: {e}")
    except FileNotFoundError as e:
        print(f"Error: {e}")
    except ValueError as e:
        print(f"Error processing JSON: {e}")

# Example usage
input_file = "path/to/your/merged_text_image.json"  # Replace with your input JSON file path
restructure_and_store_json(input_file)










import os
import json
import PyPDF2

def extract_text_and_metadata_pagewise(file, output_dir="outputs_sdr"):
    pdf_data = {
        "metadata": {},
        "pages": []
    }

    # Ensure output directory exists
    os.makedirs(output_dir, exist_ok=True)

    # Open the PDF file and read metadata
    with open(file, 'rb') as pdf_file:
        reader = PyPDF2.PdfReader(pdf_file)

        # Extract metadata if available
        if reader.metadata:
            pdf_data["metadata"] = {k[1:]: v for k, v in reader.metadata.items()}
        else:
            pdf_data["metadata"] = {}

        # Extract text page by page
        for page_index, page in enumerate(reader.pages):
            page_text = page.extract_text() if page.extract_text() else ""
            pdf_data["pages"].append({
                "page_number": page_index + 1,
                "text": page_text.strip()
            })
            print(f"[+] Extracted text from page {page_index + 1}")

    # Save the result to a JSON file
    output_file = os.path.join(output_dir, "extracted_pdf_data.json")
    with open(output_file, "w") as json_file:
        json.dump(pdf_data, json_file, indent=2)
    print(f"[+] Data saved to {output_file}")

# Example usage:
file_path = "path/to/your/input.pdf"  # Replace with your PDF file path
extract_text_and_metadata_pagewise(file_path)








import json

def restructure_json(input_json):
    structured_data = {"pages": []}

    # Check if input_json has 'pages' key and it is a list
    pages = input_json.get("pages", [])
    if not isinstance(pages, list):
        raise ValueError("Expected 'pages' to be a list, but got something else.")

    for page in pages:
        # Ensure page is a dictionary
        if not isinstance(page, dict):
            raise ValueError(f"Expected a dictionary for each page, but got {type(page)}: {page}")

        # Access and validate 'text'
        text = page.get("text", "")
        if not isinstance(text, str):
            raise ValueError(f"Expected 'text' to be a string, but got {type(text)}")

        # Initialize combined content with the page text
        combined_content = text.strip()

        # Check for images and append descriptions
        images = page.get("images", [])
        if isinstance(images, list):
            for image in images:
                if not isinstance(image, dict):
                    print(f"Skipping invalid image entry: {image}")
                    continue  # Skip invalid image entries

                # Fix possible key inconsistency ('image description' -> 'image_description')
                image_description = image.get("image_description", image.get("image description", "")).strip()
                if image_description:
                    combined_content += f" The image shows: {image_description}."

        # Append structured page data
        structured_data["pages"].append({
            "page_number": page.get("page_number", 0),
            "content": combined_content.strip(),
            "source": "text and image_description"
        })

    return structured_data

# Read the JSON data from a file
file_path = "path/to/your/merged_text_image.json"

try:
    with open(file_path, "r") as file:
        input_json = json.load(file)  # Load JSON content from the file

    # Restructure the JSON
    restructured_json = restructure_json(input_json)
    print(json.dumps(restructured_json, indent=2))

except json.JSONDecodeError as e:
    print(f"Error decoding JSON: {e}")

except FileNotFoundError as e:
    print(f"Error: {e}")

except ValueError as e:
    print(f"Error processing JSON: {e}")













import json

def restructure_json(input_json):
    structured_data = {"pages": []}

    # Check if input_json has 'pages' key and it is a list
    pages = input_json.get("pages", [])
    if not isinstance(pages, list):
        raise ValueError("Expected 'pages' to be a list, but got something else.")

    for page in pages:
        # Ensure page is a dictionary
        if not isinstance(page, dict):
            raise ValueError(f"Expected a dictionary for each page, but got {type(page)}: {page}")

        # Access and validate 'text'
        text = page.get("text", "")
        if not isinstance(text, str):
            raise ValueError(f"Expected 'text' to be a string, but got {type(text)}")

        # Initialize combined content with the page text
        combined_content = text.strip()

        # Check for images and append descriptions
        images = page.get("images", [])
        if isinstance(images, list):
            for image in images:
                if isinstance(image, dict):
                    # Fixing possible key inconsistency ('image description' -> 'image_description')
                    image_description = image.get("image_description", image.get("image description", "")).strip()
                    if image_description:
                        combined_content += f" The image shows: {image_description}."

        # Append structured page data
        structured_data["pages"].append({
            "page_number": page.get("page_number", 0),
            "content": combined_content.strip(),
            "source": "text and image_description"
        })

    return structured_data

# Example input JSON based on your provided structure
input_json = {
    "metadata": {
        "Author": "Gilman-Cabral, Betsy S",
        "Keywords": "Limited Access",
        "Creator": "Microsoft Word",
        "CreationDate": "D:20241201170842+00'00'",
        "ModDate": "D:20241201170842+00'00'"
    },
    "pages": [
        {
            "page_number": 1,
            "text": "Information Classification: Limited Access.",
            "images": [
                {
                 












import json

def restructure_json(input_json):
    structured_data = {"pages": []}

    # Check if input is a list of pages
    if not isinstance(input_json, list):
        raise ValueError("Expected a list of pages, but got something else.")

    for page in input_json:
        # Ensure page is a dictionary
        if not isinstance(page, dict):
            raise ValueError(f"Expected a dictionary for each page, but got {type(page)}: {page}")

        # Access the 'text' field
        text = page.get("text", "")
        if not isinstance(text, str):
            raise ValueError(f"Expected 'text' to be a string, but got {type(text)}")

        # Start combining content
        combined_content = text

        # Check and append image descriptions
        images = page.get("images", [])
        if not isinstance(images, list):
            raise ValueError(f"Expected 'images' to be a list, but got {type(images)}")

        for image in images:
            if not isinstance(image, dict):
                raise ValueError(f"Expected each image to be a dictionary, but got {type(image)}")

            image_description = image.get("image_description", "")
            if image_description:
                combined_content += f" The image shows: {image_description}."

        # Append the structured data for this page
        structured_data["pages"].append({
            "page_number": page.get("page_number", 0),
            "content": combined_content.strip(),
            "source": "text and image_description"
        })

    return structured_data

# Example Input JSON
input_json = [
    {
        "page_number": 1,
        "text": "Information Classification: Limited Access.",
        "images": [
            {
                "image_name": "image_page1_1.png",
                "image_description": "The document appears to be a professional financial statement."
            }
        ]
    },
    {
        "page_number": 2,
        "text": "Hub Procedure Oversight Owner Names(s): Not Applicable.",
        "images": []
    },
    {
        "page_number": 3,
        "text": "1. DMH Data Maintenance - Ensure monthly book in MCH has been released.",
        "images": [
            {
                "image_name": "image_page3_1.png",
                "image_description": "The image depicts a detailed financial document."
            }
        ]
    }
]

try:
    # Restructure the JSON
    restructured_json = restructure_json(input_json)
    print(json.dumps(restructured_json, indent=2))
except ValueError as e:
    print(f"Error: {e}")










import json

def restructure_json(input_json):
    structured_data = {"pages": []}

    for page in input_json:  # Correct iteration over list of pages
        combined_content = page["text"]

        # Check and append image descriptions if available
        if "images" in page and isinstance(page["images"], list):
            for image in page["images"]:
                combined_content += f" The image shows: {image['image_description']}."

        # Append structured content for each page
        structured_data["pages"].append({
            "page_number": page["page_number"],
            "content": combined_content.strip(),
            "source": "text and image_description"
        })

    return structured_data

# Example Input JSON (list of pages, simplified)
input_json = [
    {
        "page_number": 1,
        "text": "Information Classification: Limited Access.",
        "images": [
            {
                "image_name": "image_page1_1.png",
                "image_description": "The document in question appears to be a professional financial statement."
            }
        ]
    },
    {
        "page_number": 2,
        "text": "Hub Procedure Oversight Owner Names(s): Not Applicable.",
        "images": []
    },
    {
        "page_number": 3,
        "text": "1. DMH Data Maintenance - Ensure monthly book in MCH has been released.",
        "images": [
            {
                "image_name": "image_page3_1.png",
                "image_description": "The image depicts a detailed financial document."
            },
            {
                "image_name": "image_page3_2.png",
                "image_description": "The image depicts a professional financial document."
            }
        ]
    }
]

# Restructure the JSON
restructured_json = restructure_json(input_json)

# Print the result
print(json.dumps(restructured_json, indent=2))










import json

def restructure_json(input_json):
    structured_data = {"pages": []}

    for page in input_json["pages"]:
        # Initialize combined content with page text
        combined_content = page["text"]

        # Add image descriptions if they exist
        if "images" in page and page["images"]:
            for image in page["images"]:
                combined_content += f" The image shows: {image['image_description']}."

        # Append structured page data
        structured_data["pages"].append({
            "page_number": page["page_number"],
            "content": combined_content.strip(),
            "source": "text and image_description"
        })

    return structured_data

# Example Input JSON (similar to yours)
input_json = {
    "pages": [
        {
            "page_number": 1,
            "text": "Information Classification: Limited Access.",
            "images": [
                {
                    "image_name": "image_page1_1.png",
                    "image_description": "The document in question appears to be a professional financial statement."
                }
            ]
        },
        {
            "page_number": 2,
            "text": "Hub Procedure Oversight Owner Names(s): Not Applicable.",
            "images": []
        },
        {
            "page_number": 3,
            "text": "1. DMH Data Maintenance - Ensure monthly book in MCH has been released.",
            "images": [
                {
                    "image_name": "image_page3_1.png",
                    "image_description": "The image depicts a detailed financial document."
                },
                {
                    "image_name": "image_page3_2.png",
                    "image_description": "The image depicts a professional financial document."
                }
            ]
        }
    ]
}

# Restructure the JSON
restructured_json = restructure_json(input_json)

# Print the result or save it to a file
print(json.dumps(restructured_json, indent=2))






from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.chat_models import AzureChatOpenAI

# Initialize Azure OpenAI LLM
llm = AzureChatOpenAI(
    temperature=0.7,
    api_version="azure_openai_api_version",
    azure_endpoint="azure_openai_endpoint",
    deployment_name="deployment_name"
)

def generate_questions(paragraph, question_type, num_questions, prompt_template):
    # Create the prompt template
    prompt = PromptTemplate(
        input_variables=["paragraph", "num_questions", "question_type"],
        template=prompt_template
    )

    # Fill the prompt using format
    fill_prompt = prompt.format(
        paragraph=paragraph, 
        num_questions=num_questions, 
        question_type=question_type
    )

    print(f"Generated the prompt:\n{fill_prompt}")

    # Create the LLM chain
    llm_chain = LLMChain(llm=llm, prompt=prompt)

    try:
        # Generate questions using the LLM chain
        response = llm_chain.predict(
            paragraph=paragraph,
            num_questions=str(num_questions),
            question_type=str(question_type)
        )

        # Extract and return valid JSON from the response
        return extract_valid_json(response)
    except Exception as e:
        print(f"Error generating questions: {e}")
        return []

def generate_questions_in_chunks(paragraph, question_type, total_questions, prompt_template, chunk_size=10):
    all_questions = []

    for i in range(0, total_questions, chunk_size):
        try:
            chunk_questions = generate_questions(
                paragraph=paragraph, 
                question_type=question_type, 
                num_questions=min(chunk_size, total_questions - i), 
                prompt_template=prompt_template
            )
            all_questions.extend(chunk_questions)
        except Exception as e:
            print(f"Error generating chunk for {question_type}: {e}")
            continue

    return all_questions

# Example usage (Replace with actual prompt and API settings)
paragraph = "Machine learning is a subset of artificial intelligence (AI) focused on building systems that learn from data."
question_type = "Factual"
total_questions = 25
prompt_template = (
    "Generate {num_questions} {question_type} questions based on the following paragraph:\n"
    "{paragraph}\n"
    "Provide the questions in JSON format."
)

questions = generate_questions_in_chunks(
    paragraph=paragraph,
    question_type=question_type,
    total_questions=total_questions,
    prompt_template=prompt_template
)

print("Generated Questions:", questions)








import fitz  # PyMuPDF for PDF parsing
import openai
from PIL import Image
import io
import os

# Initialize OpenAI API (replace with your actual API key)
openai.api_key = "43d6ab1448834574807eff7a195f76f3"

def extract_procedural_steps_with_images(pdf_path):
    # Open the PDF
    doc = fitz.open(pdf_path)
    procedure_steps = []

    # Iterate through the pages and extract relevant text and images
    for page_num in range(len(doc)):
        page = doc[page_num]
        text = page.get_text()

        # Identify procedural step headings and related text (using keyword heuristic)
        lines = text.split('\n')
        step_content = []

        for i, line in enumerate(lines):
            if line.lower().startswith("step"):
                step_content = [line.strip()]

                # Gather subsequent lines related to the step until another step or blank line is encountered
                for j in range(i + 1, len(lines)):
                    if lines[j].strip().lower().startswith("step") or lines[j].strip() == "":
                        break
                    step_content.append(lines[j].strip())

                step_text = "\n".join(step_content)

                # Check if the page contains any images related to this step
                images = page.get_images(full=True)
                image_data = []

                for img_index, img in enumerate(images):
                    xref = img[0]
                    base_image = doc.extract_image(xref)
                    image_bytes = base_image["image"]
                    image_ext = base_image["ext"]
                    image = Image.open(io.BytesIO(image_bytes))

                    # Save the image temporarily
                    image_filename = f"temp_image_{page_num}_{img_index}.{image_ext}"
                    image.save(image_filename)
                    image_data.append(image_filename)

                # Add the step and any associated images
                procedure_steps.append({"text": step_text, "images": image_data})

    return procedure_steps

def generate_procedural_qna_with_images(procedure_steps, prompt_template):
    qna_pairs = []

    for step_data in procedure_steps:
        step_text = step_data["text"]
        prompt = prompt_template.format(procedure_text=step_text)

        response = openai.Completion.create(
            engine="text-davinci-003",
            prompt=prompt,
            max_tokens=300
        )

        generated_text = response.choices[0].text.strip()

        # Split the generated output into question-answer pairs
        for line in generated_text.split('\n'):
            if '|' in line:
                question, answer = line.split('|', 1)
                qna_pairs.append({
                    "question": question.strip(),
                    "answer": answer.strip(),
                    "images": step_data["images"]
                })

    return qna_pairs

def save_qna_to_file(qna_pairs, output_file):
    with open(output_file, 'w') as f:
        for pair in qna_pairs:
            f.write(f"Question: {pair['question']}\nAnswer: {pair['answer']}\n")
            if pair["images"]:
                f.write(f"Related Images: {', '.join(pair['images'])}\n\n")

pdf_path = r"h:\Question and answer\Fund accounting (Resubmit_1025)36. VFMC AAS25 SOP 5.0.pdf"
output_file = r"h:\Question and answer\Fund accounting\procedural_qna_with_images.txt"

# Define a prompt template for procedural Q&A generation
prompt_template = (
    "You are an AI assistant tasked with generating procedural questions and answers. "
    "Given the following procedure step, generate questions that can help clarify the task, "
    "and provide an answer for each question in the format 'Question | Answer'.\n\n"
    "Procedure Step:\n{procedure_text}"
)

# Step 1: Extract procedural steps and associated images from the PDF
procedure_steps = extract_procedural_steps_with_images(pdf_path)
print(procedure_steps)

# Step 2: Generate procedural Q&A pairs
qna_pairs = generate_procedural_qna_with_images(procedure_steps, prompt_template)

# Step 3: Save Q&A pairs to the output file
save_qna_to_file(qna_pairs, output_file)

print(f"Generated Q&A pairs with images saved to {output_file}")















import json
import os
import re

def fix_and_load_json(json_file):
    """Fix any trailing commas and load JSON from a file."""
    with open(json_file, 'r', encoding="utf-8-sig") as file:
        json_content = file.read()

    # Basic fix for trailing commas before closing brackets
    fixed_json = re.sub(r',\s*([\]])', r'\1', json_content)

    try:
        return json.loads(fixed_json)
    except json.JSONDecodeError as e:
        print(f"JSON decoding error in file {json_file}: {e}")
        return None


def merge_json_files(text_json_path, image_json_path, output_dir="outputs_sdr"):
    """Merge text and image JSON files based on 'page_number'."""
    # Ensure the output directory exists
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # Fix and load JSON data
    text_data = fix_and_load_json(text_json_path)
    image_data = fix_and_load_json(image_json_path)

    if text_data is None or image_data is None:
        print("Error in loading JSON files. Please check their format.")
        return None

    # Convert image JSON to a dictionary for quick lookup by page_number
    image_dict = {}

    for image in image_data.get("pages", []):  # Assuming image_data also has a 'pages' key
        page_number = image.get("page_number")
        if page_number not in image_dict:
            image_dict[page_number] = []
        image_dict[page_number].append({
            "image_name": image.get("image_name"),
            "image_description": image.get("image_description")
        })

    # Merge text and image data based on 'page_number'
    for page in text_data.get("pages", []):
        page_number = page.get("page_number")
        if page_number in image_dict:
            page["images"] = image_dict[page_number]

    # Save the merged JSON file
    save_json_image(output_dir, text_data)

    # Return the merged data (or other useful information)
    return text_data  # Returning the merged data


def save_json_image(output_dir, image_descriptions):
    """Save the merged JSON data to a file."""
    json_file_path = os.path.join(output_dir, "merged_text_image.json")
    with open(json_file_path, "w", encoding="utf-8") as json_file:
        json.dump(image_descriptions, json_file, indent=4)

    print(f"Merged JSON saved to: {json_file_path}")


# Example usage
text_json_path = r'h:\Q & A Note Book\final\outputs_sdr\text.json'
image_json_path = r'h:\Q & A Note Book\final\outputs_sdr\image.json'

# Now you can use the return value from the merge_json_files function
merged_data = merge_json_files(text_json_path, image_json_path)

# If you need to do something further with the returned data
if merged_data:
    print(f"Merged data: {merged_data}")
else:
    print("No merged data to process.")






import json
import os
import re

def fix_and_load_json(json_file):
    """Fix any trailing commas and load JSON from a file."""
    with open(json_file, 'r', encoding="utf-8-sig") as file:
        json_content = file.read()

    # Basic fix for trailing commas before closing brackets
    fixed_json = re.sub(r',\s*([\]])', r'\1', json_content)

    try:
        return json.loads(fixed_json)
    except json.JSONDecodeError as e:
        print(f"JSON decoding error in file {json_file}: {e}")
        return None


def merge_json_files(text_json_path, image_json_path, output_dir="outputs_sdr"):
    """Merge text and image JSON files based on 'page_number'."""
    # Ensure the output directory exists
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # Fix and load JSON data
    text_data = fix_and_load_json(text_json_path)
    image_data = fix_and_load_json(image_json_path)

    if text_data is None or image_data is None:
        print("Error in loading JSON files. Please check their format.")
        return

    # Convert image JSON to a dictionary for quick lookup by page_number
    image_dict = {}

    for image in image_data.get("pages", []):  # Assuming image_data also has a 'pages' key
        page_number = image.get("page_number")
        if page_number not in image_dict:
            image_dict[page_number] = []
        image_dict[page_number].append({
            "image_name": image.get("image_name"),
            "image_description": image.get("image_description")
        })

    # Merge text and image data based on 'page_number'
    for page in text_data.get("pages", []):
        page_number = page.get("page_number")
        if page_number in image_dict:
            page["images"] = image_dict[page_number]

    # Save the merged JSON file
    save_json_image(output_dir, text_data)


def save_json_image(output_dir, image_descriptions):
    """Save the merged JSON data to a file."""
    json_file_path = os.path.join(output_dir, "merged_text_image.json")
    with open(json_file_path, "w", encoding="utf-8") as json_file:
        json.dump(image_descriptions, json_file, indent=4)

    print(f"Merged JSON saved to: {json_file_path}")


# Example usage
text_json_path = r'h:\Q & A Note Book\final\outputs_sdr\text.json'
image_json_path = r'h:\Q & A Note Book\final\outputs_sdr\image.json'

merge_json_files(text_json_path, image_json_path)







import json
import re
import os

def fix_and_load_json(json_file):
    with open(json_file, 'r', encoding='utf-8-sig') as file:
        json_content = file.read()
    
    # Basic fix for trailing commas before closing brackets
    fixed_json = re.sub(r',\s*([}\]])', r'\1', json_content)
    
    try:
        return json.loads(fixed_json)
    except json.JSONDecodeError as e:
        print(f"JSON decoding error in file {json_file}: {e}")
        return None

def merge_json_files(text_json_path, image_json_path, output_dir="outputs_sdr"):
    # Ensure the output directory exists
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # Fix and load JSON data
    text_data = fix_and_load_json(text_json_path)
    image_data = fix_and_load_json(image_json_path)

    if text_data is None or image_data is None:
        print("Error in loading JSON files. Please check their format.")
        return

    # Convert image JSON to a dictionary for quick lookup by page_number
    image_dict = {}
    for image in image_data:
        page_number = image.get("page_number")
        if page_number not in image_dict:
            image_dict[page_number] = []
        image_dict[page_number].append({
            "image_name": image.get("image_name"),
            "description": image.get("description")
        })

    # Merge text and image data based on page_number
    for page in text_data["pages"]:
        page_number = page.get("page_number")
        if page_number in image_dict:
            page["images"] = image_dict[page_number]

    # Save the merged data to a new file in the output directory
    output_file_path = os.path.join(output_dir, "merged_data.json")
    with open(output_file_path, 'w', encoding='utf-8') as output_file:
        json.dump(text_data, output_file, indent=4)

    print(f"Merged JSON saved to: {output_file_path}")

# Example usage
text_json_path = 'path/to/text.json'  # Replace with your actual path
image_json_path = 'path/to/image.json'  # Replace with your actual path

merge_json_files(text_json_path, image_json_path)











import json
import re
import os

def fix_and_load_json(json_file):
    with open(json_file, 'r', encoding='utf-8-sig') as file:
        json_content = file.read()
    
    # Basic fix for trailing commas before closing brackets
    fixed_json = re.sub(r',\s*([}\]])', r'\1', json_content)
    
    try:
        return json.loads(fixed_json)
    except json.JSONDecodeError as e:
        print(f"JSON decoding error in file {json_file}: {e}")
        return None

def merge_json_files(text_json_path, image_json_path, output_path):
    # Fix and load JSON data
    text_data = fix_and_load_json(text_json_path)
    image_data = fix_and_load_json(image_json_path)

    if text_data is None or image_data is None:
        print("Error in loading JSON files. Please check their format.")
        return

    # Convert image JSON to a dictionary for quick lookup by page_number
    image_dict = {}
    for image in image_data:
        page_number = image.get("page_number")
        if page_number not in image_dict:
            image_dict[page_number] = []
        image_dict[page_number].append({
            "image_name": image.get("image_name"),
            "description": image.get("description")
        })

    # Merge text and image data based on page_number
    for page in text_data["pages"]:
        page_number = page.get("page_number")
        if page_number in image_dict:
            page["images"] = image_dict[page_number]

    # Create the output directory if it doesn't exist
    os.makedirs(output_path, exist_ok=True)

    # Save the merged data to a new file
    output_file_path = os.path.join(output_path, "merged_data.json")
    with open(output_file_path, 'w', encoding='utf-8') as output_file:
        json.dump(text_data, output_file, indent=4)

    print(f"Merged JSON saved to: {output_file_path}")

# Example usage
text_json_path = 'path/to/text.json'  # Replace with actual path
image_json_path = 'path/to/image.json'  # Replace with actual path
output_path = 'path/to/output_directory'  # Replace with desired output directory

merge_json_files(text_json_path, image_json_path, output_p











import json
import os

def merge_json_files(text_json_path, image_json_path, output_path):
    # Load the JSON data from the files with specified encoding
    with open(text_json_path, 'r', encoding='utf-8-sig') as text_file:
        text_data = json.load(text_file)
    
    with open(image_json_path, 'r', encoding='utf-8-sig') as image_file:
        image_data = json.load(image_file)

    # Convert image JSON to a dictionary for quick lookup by page_number
    image_dict = {}
    for image in image_data:
        page_number = image.get("page_number")
        if page_number not in image_dict:
            image_dict[page_number] = []
        image_dict[page_number].append({
            "image_name": image.get("image_name"),
            "description": image.get("description")
        })

    # Merge text and image data based on page_number
    for page in text_data["pages"]:
        page_number = page.get("page_number")
        if page_number in image_dict:
            page["images"] = image_dict[page_number]

    # Create the output directory if it doesn't exist
    os.makedirs(output_path, exist_ok=True)

    # Save the merged data to a new file
    output_file_path = os.path.join(output_path, "merged_data.json")
    with open(output_file_path, 'w', encoding='utf-8') as output_file:
        json.dump(text_data, output_file, indent=4)

    print(f"Merged JSON saved to: {output_file_path}")

# Example usage
text_json_path = 'path/to/text.json'  # Replace with actual path
image_json_path = 'path/to/image.json'  # Replace with actual path
output_path = 'path/to/output_directory'  # Replace with desired output directory

merge_json_files(text_json_path, image_json_path, output_path)










import json
import os

def merge_json_files(text_json_path, image_json_path, output_path):
    # Load the JSON data from the files
    with open(text_json_path, 'r') as text_file:
        text_data = json.load(text_file)
    
    with open(image_json_path, 'r') as image_file:
        image_data = json.load(image_file)

    # Convert image JSON to a dictionary for quick lookup by page_number
    image_dict = {}
    for image in image_data:
        page_number = image.get("page_number")
        if page_number not in image_dict:
            image_dict[page_number] = []
        image_dict[page_number].append({
            "image_name": image.get("image_name"),
            "description": image.get("description")
        })

    # Merge text and image data based on page_number
    for page in text_data["pages"]:
        page_number = page.get("page_number")
        if page_number in image_dict:
            page["images"] = image_dict[page_number]

    # Create the output directory if it doesn't exist
    os.makedirs(output_path, exist_ok=True)

    # Save the merged data to a new file
    output_file_path = os.path.join(output_path, "merged_data.json")
    with open(output_file_path, 'w') as output_file:
        json.dump(text_data, output_file, indent=4)

    print(f"Merged JSON saved to: {output_file_path}")

# Example usage
text_json_path = 'path/to/text.json'  # Replace with actual path
image_json_path = 'path/to/image.json'  # Replace with actual path
output_path = 'path/to/output_directory'  # Replace with desired output directory

merge_json_files(text_json_path, image_json_path, output_path)











# Prompt for generating step-wise answers combining text and image descriptions with the given output format

"""
Given a JSON input containing procedural steps with textual content and image descriptions, generate a structured output with step-by-step answers formatted as specified. Each step may reference text, images, or both. Ensure that:

1. Steps should follow the order mentioned in the input (Step 1, Step 2, etc.).
2. If a step includes both textual and image information, merge them into a single, coherent answer.
3. Image descriptions should be included where applicable (e.g., Step 3 or Step 5).
4. All critical details, such as addresses, instructions, and labeled components, should be included without omissions.
5. Include the source of the extracted content, either from the paragraph or image descriptions.

### **Input Format:**
- Text: A JSON object with a key "text" containing step-by-step instructions.
- Image description: A JSON object with keys like "Step 3", "Step 5", etc., containing visual descriptions.

### **Output Format:**
{
    "question": "What are the steps to achieve or complete this process?",
    "answer": [
        "Step 1: [Description of Step 1, including any textual or image-based content].",
        "Step 2: [Description of Step 2, with any relevant details from text or images].",
        "Step n: [Description of Step n, combining textual and image information where needed]."
    ],
    "extracted": "paragraph/image_content"
}

### **Example Input:**
- Text: 
{
    "text": "Step 1: Gather materials. Step 2: Visit 45 Pine Street to collect the tools. Step 3: Assemble the parts using the diagram. Step 4: Install the system. Step 5: Verify the setup visually."
}
- Image description: 
{
    "description": {
        "Step 3": "An image showing the components for assembly with labeled parts.",
        "Step 5": "An image of the fully assembled system."
    }
}

### **Expected Output:**
{
    "question": "What are the steps to achieve or complete this process?",
    "answer": [
        "Step 1: Gather the necessary materials before beginning the process.",
        "Step 2: Visit 45 Pine Street to collect the required tools.",
        "Step 3: Assemble the parts using the provided diagram. The image shows the components for assembly with labeled parts.",
        "Step 4: Install the system as described in the instructions.",
        "Step 5: Verify the setup visually using the image of the fully assembled system."
    ],
    "extracted": "paragraph/image_content"
}

Generate the output exactly in the structured format specified.
"""









import json

def merge_text_and_description(text_file_path, image_file_path, output_file_path):
    # Load the text JSON from the file with explicit encoding
    with open(text_file_path, 'r', encoding='utf-8') as text_file:
        text_json = json.load(text_file)

    # Load the image JSON from the file with explicit encoding
    with open(image_file_path, 'r', encoding='utf-8') as image_file:
        image_json = json.load(image_file)

    # Create a dictionary of images based on page_number for easy lookup
    image_dict = {image["page_number"]: image for image in image_json}

    # Initialize the merged JSON
    merged_json = {"metadata": text_json["metadata"], "pages": []}

    # Merge text and images based on page number
    for text_page in text_json["pages"]:
        page_number = text_page["page_number"]
        
        # Create a new page entry with text and image combined into 'text_and_description'
        merged_page = {
            "page_number": page_number,
            "text_and_description": str(text_page["text"])  # Ensure text is a string
        }
        
        # Add image description to 'text_and_description' if available for that page
        if page_number in image_dict:
            # Ensure description is a string
            merged_page["text_and_description"] += "\n" + str(image_dict[page_number]["description"])  # Concatenate description
        
        # Append merged page to the result
        merged_json["pages"].append(merged_page)

    # Save the merged JSON to the output file with explicit encoding
    with open(output_file_path, 'w', encoding='utf-8') as output_file:
        json.dump(merged_json, output_file, indent=2, ensure_ascii=False)

    # Optionally, return the merged JSON or print it
    return merged_json

# Example usage
merged_json = merge_text_and_description('text.json', 'images.json', 'merged.json')
print(json.dumps(merged_json, indent=2, ensure_ascii=False))











import json

def merge_text_and_description(text_file_path, image_file_path, output_file_path):
    # Load the text JSON from the file with explicit encoding
    with open(text_file_path, 'r', encoding='utf-8') as text_file:
        text_json = json.load(text_file)

    # Load the image JSON from the file with explicit encoding
    with open(image_file_path, 'r', encoding='utf-8') as image_file:
        image_json = json.load(image_file)

    # Create a dictionary of images based on page_number for easy lookup
    image_dict = {image["page_number"]: image for image in image_json}

    # Initialize the merged JSON
    merged_json = {"metadata": text_json["metadata"], "pages": []}

    # Merge text and images based on page number
    for text_page in text_json["pages"]:
        page_number = text_page["page_number"]
        
        # Create a new page entry with text and image combined into 'text_and_description'
        merged_page = {
            "page_number": page_number,
            "text_and_description": text_page["text"]  # Start with text field
        }
        
        # Add image description to 'text_and_description' if available for that page
        if page_number in image_dict:
            merged_page["text_and_description"] += "\n" + image_dict[page_number]["description"]  # Concatenate description
        
        # Append merged page to the result
        merged_json["pages"].append(merged_page)

    # Save the merged JSON to the output file with explicit encoding
    with open(output_file_path, 'w', encoding='utf-8') as output_file:
        json.dump(merged_json, output_file, indent=2, ensure_ascii=False)

    # Optionally, return the merged JSON or print it
    return merged_json

# Example usage
merged_json = merge_text_and_description('text.json', 'images.json', 'merged.json')
print(json.dumps(merged_json, indent=2, ensure_ascii=False))









import json

def merge_text_and_description(text_file_path, image_file_path, output_file_path):
    # Load the text JSON from the file
    with open(text_file_path, 'r') as text_file:
        text_json = json.load(text_file)

    # Load the image JSON from the file
    with open(image_file_path, 'r') as image_file:
        image_json = json.load(image_file)

    # Create a dictionary of images based on page_number for easy lookup
    image_dict = {image["page_number"]: image for image in image_json}

    # Initialize the merged JSON
    merged_json = {"metadata": text_json["metadata"], "pages": []}

    # Merge text and images based on page number
    for text_page in text_json["pages"]:
        page_number = text_page["page_number"]
        
        # Create a new page entry with text and image combined into 'text_and_description'
        merged_page = {
            "page_number": page_number,
            "text_and_description": text_page["text"]  # Start with text field
        }
        
        # Add image description to 'text_and_description' if available for that page
        if page_number in image_dict:
            merged_page["text_and_description"] += "\n" + image_dict[page_number]["description"]  # Concatenate description
        
        # Append merged page to the result
        merged_json["pages"].append(merged_page)

    # Save the merged JSON to the output file
    with open(output_file_path, 'w') as output_file:
        json.dump(merged_json, output_file, indent=2)

    # Optionally, return the merged JSON or print it
    return merged_json

# Example usage
merged_json = merge_text_and_description('text.json', 'images.json', 'merged.json')
print(json.dumps(merged_json, indent=2))











import json

# Load the text JSON from the file
with open('text.json', 'r') as text_file:
    text_json = json.load(text_file)

# Load the image JSON from the file
with open('images.json', 'r') as image_file:
    image_json = json.load(image_file)

# Create a dictionary of images based on page_number for easy lookup
image_dict = {image["page_number"]: image for image in image_json}

# Initialize the merged JSON
merged_json = {"metadata": text_json["metadata"], "pages": []}

# Merge text and images based on page number
for text_page in text_json["pages"]:
    page_number = text_page["page_number"]
    
    # Create a new page entry with text and image combined into 'text_and_description'
    merged_page = {
        "page_number": page_number,
        "text_and_description": text_page["text"]  # Start with text field
    }
    
    # Add image description to 'text_and_description' if available for that page
    if page_number in image_dict:
        merged_page["text_and_description"] += "\n" + image_dict[page_number]["description"]  # Concatenate description
    
    # Append merged page to the result
    merged_json["pages"].append(merged_page)

# Save the merged JSON to a new file
with open('merged.json', 'w') as output_file:
    json.dump(merged_json, output_file, indent=2)

# Optionally print the merged JSON
print(json.dumps(merged_json, indent=2))







import json

def generate_procedural_questions(text_json, image_json, num_questions=5):
    questions = []

    # Load both JSON files
    with open(text_json, 'r', encoding='utf-8') as f:
        text_data = json.load(f)

    with open(image_json, 'r', encoding='utf-8') as f:
        image_data = json.load(f)

    # Organize image descriptions by page number (convert page_number to string consistently)
    images_by_page = {}
    for image_entry in image_data:
        page_number = str(image_entry["page_number"])  # Convert to string
        if page_number not in images_by_page:
            images_by_page[page_number] = []
        images_by_page[page_number].append(image_entry["description"])

    # Generate questions by combining text and images dynamically
    for page in text_data["pages"]:
        page_number = str(page["page_number"])  # Convert to string
        page_text = page["text"].strip()

        # Skip pages with no meaningful text
        if not page_text or len(page_text) < 50:  # Threshold to ignore headers or empty pages
            continue

        # Combine with image descriptions if available
        combined_text = page_text
        if page_number in images_by_page:
            combined_text += "\n\n" + "\n".join(images_by_page[page_number])

        # Create the question-answer pair
        question_answer = {
            "question": f"What are the key procedural steps for page {page_number}?",
            "answer": generate_steps_from_text(combined_text),
            "extracted": combined_text
        }

        questions.append(question_answer)
        if len(questions) >= num_questions:
            break

    return questions

def generate_steps_from_text(combined_text):
    # Splitting the combined content into logical steps
    steps = []
    lines = combined_text.split("\n")
    
    step_number = 1
    for line in lines:
        line = line.strip()
        if len(line) > 20:  # Ignore short or meaningless lines
            steps.append(f"Step {step_number}: {line}")
            step_number += 1

    return steps

# Example usage
text_json = "path/to/text.json"
image_json = "path/to/image.json"
try:
    questions = generate_procedural_questions(text_json, image_json, num_questions=5)

    # Output the results to a JSON file
    with open("procedural_questions.json", "w", encoding="utf-8") as outfile:
        json.dump(questions, outfile, indent=4, ensure_ascii=False)

    print("Procedural questions generated successfully.")

except json.JSONDecodeError as e:
    print(f"JSON decoding error: {e}")
except FileNotFoundError as e:
    print(f"File not found: {e}")
except ValueError as e:
    print(f"ValueError: {e}")
except Exception as e:
    print(f"An unexpected error occurred: {e}")










import json

def generate_procedural_questions(text_json, image_json, num_questions=5):
    questions = []

    # Load and validate JSON files
    with open(text_json, 'r', encoding='utf-8') as f:
        text_data = json.load(f)

    with open(image_json, 'r', encoding='utf-8') as f:
        image_data = json.load(f)

    # Validate JSON structure
    if not isinstance(text_data, dict) or "pages" not in text_data or not isinstance(text_data["pages"], list):
        raise ValueError("Invalid structure in text JSON. Expected a dictionary with a 'pages' key containing a list.")

    if not isinstance(image_data, list):
        raise ValueError("Invalid structure in image JSON. Expected a list of dictionaries.")

    # Organize image descriptions by page number (convert page_number to string consistently)
    images_by_page = {}
    for image_entry in image_data:
        if not isinstance(image_entry, dict) or "page_number" not in image_entry or "description" not in image_entry:
            raise ValueError(f"Invalid image entry format: {image_entry}")
        
        page_number = str(image_entry["page_number"])  # Convert to string
        if page_number not in images_by_page:
            images_by_page[page_number] = []
        images_by_page[page_number].append(image_entry["description"])

    # Generate questions by combining text and images dynamically
    for page in text_data["pages"]:
        if not isinstance(page, dict) or "page_number" not in page or "text" not in page:
            raise ValueError(f"Invalid page entry format: {page}")

        page_number = str(page["page_number"])  # Convert to string
        page_text = page["text"].strip()

        # Skip pages with no meaningful text
        if not page_text or len(page_text) < 50:  # Threshold to ignore headers or empty pages
            continue

        # Combine with image descriptions if available
        combined_text = page_text
        if page_number in images_by_page:
            combined_text += "\n\n" + "\n".join(images_by_page[page_number])

        # Create the question-answer pair
        question_answer = {
            "question": "What are the key procedural steps for page {}?".format(page_number),
            "answer": generate_steps_from_text(combined_text),
            "extracted": combined_text
        }

        questions.append(question_answer)
        if len(questions) >= num_questions:
            break

    return questions

def generate_steps_from_text(combined_text):
    # Splitting the combined content into logical steps
    steps = []
    lines = combined_text.split("\n")
    
    step_number = 1
    for line in lines:
        line = line.strip()
        if len(line) > 20:  # Ignore short or meaningless lines
            steps.append(f"Step {step_number}: {line}")
            step_number += 1

    return steps

# Example usage
text_json = "path/to/text.json"
image_json = "path/to/image.json"
try:
    questions = generate_procedural_questions(text_json, image_json, num_questions=5)

    # Output the results to a JSON file
    with open("procedural_questions.json", "w", encoding="utf-8") as outfile:
        json.dump(questions, outfile, indent=4, ensure_ascii=False)

    print("Procedural questions generated successfully.")

except json.JSONDecodeError as e:
    print(f"JSON decoding error: {e}")
except FileNotFoundError as e:
    print(f"File not found: {e}")
except ValueError as e:
    print(f"ValueError: {e}")
except Exception as e:
    print(f"An unexpected error occurred: {e}")







import json

def generate_procedural_questions(text_json, image_json, num_questions=5):
    questions = []

    # Load both JSON files
    with open(text_json, 'r', encoding='utf-8') as f:
        text_data = json.load(f)

    with open(image_json, 'r', encoding='utf-8') as f:
        image_data = json.load(f)

    # Organize image descriptions by page number (convert page_number to string consistently)
    images_by_page = {}
    for image_entry in image_data:
        try:
            page_number = str(image_entry["page_number"])  # Convert to string
            if page_number not in images_by_page:
                images_by_page[page_number] = []
            images_by_page[page_number].append(image_entry["description"])
        except KeyError as e:
            print(f"KeyError in image data: {e}")
        except Exception as e:
            print(f"Unexpected error in image processing: {e}")

    # Generate questions by combining text and images dynamically
    for page in text_data["pages"]:
        try:
            page_number = str(page["page_number"])  # Convert to string
            page_text = page["text"].strip()

            # Skip pages with no meaningful text
            if not page_text or len(page_text) < 50:  # Threshold to ignore headers or empty pages
                continue

            # Combine with image descriptions if available
            combined_text = page_text
            if page_number in images_by_page:
                combined_text += "\n\n" + "\n".join(images_by_page[page_number])

            # Create the question-answer pair
            question_answer = {
                "question": "What are the key procedural steps for page {}?".format(page_number),
                "answer": generate_steps_from_text(combined_text),
                "extracted": combined_text
            }

            questions.append(question_answer)
            if len(questions) >= num_questions:
                break
        except KeyError as e:
            print(f"KeyError in text data: {e}")
        except Exception as e:
            print(f"Unexpected error in text processing: {e}")

    return questions

def generate_steps_from_text(combined_text):
    # Splitting the combined content into logical steps
    steps = []
    lines = combined_text.split("\n")
    
    step_number = 1
    for line in lines:
        line = line.strip()
        if len(line) > 20:  # Ignore short or meaningless lines
            steps.append(f"Step {step_number}: {line}")
            step_number += 1

    return steps

# Example usage
text_json = "path/to/text.json"
image_json = "path/to/image.json"
try:
    questions = generate_procedural_questions(text_json, image_json, num_questions=5)

    # Output the results to a JSON file
    with open("procedural_questions.json", "w", encoding="utf-8") as outfile:
        json.dump(questions, outfile, indent=4, ensure_ascii=False)

    print("Procedural questions generated successfully.")

except json.JSONDecodeError as e:
    print(f"JSON decoding error: {e}")
except FileNotFoundError as e:
    print(f"File not found: {e}")
except Exception as e:
    print(f"An unexpected error occurred: {e}")











import json

def generate_procedural_questions(text_json, image_json, num_questions=5):
    questions = []

    # Load both JSON files
    with open(text_json, 'r', encoding='utf-8') as f:
        text_data = json.load(f)

    with open(image_json, 'r', encoding='utf-8') as f:
        image_data = json.load(f)

    # Organize image descriptions by page number
    images_by_page = {}
    for image_entry in image_data:
        page_number = image_entry["page_number"]
        if page_number not in images_by_page:
            images_by_page[page_number] = []
        images_by_page[page_number].append(image_entry["description"])

    # Generate questions by combining text and images dynamically
    for page in text_data["pages"]:
        page_number = page["page_number"]
        page_text = page["text"].strip()

        # Skip pages with no meaningful text
        if not page_text or len(page_text) < 50:  # Threshold to ignore headers or empty pages
            continue

        # Combine with image descriptions if available
        combined_text = page_text
        if page_number in images_by_page:
            combined_text += "\n\n" + "\n".join(images_by_page[page_number])

        # Create the question-answer pair
        question_answer = {
            "question": "What are the key procedural steps for page {}?".format(page_number),
            "answer": generate_steps_from_text(combined_text),
            "extracted": combined_text
        }

        questions.append(question_answer)
        if len(questions) >= num_questions:
            break

    return questions

def generate_steps_from_text(combined_text):
    # Splitting the combined content into logical steps
    steps = []
    lines = combined_text.split("\n")
    
    step_number = 1
    for line in lines:
        line = line.strip()
        if len(line) > 20:  # Ignore short or meaningless lines
            steps.append(f"Step {step_number}: {line}")
            step_number += 1

    return steps

# Example usage
text_json = "path/to/text.json"
image_json = "path/to/image.json"
questions = generate_procedural_questions(text_json, image_json, num_questions=5)

# Output the results to a JSON file
with open("procedural_questions.json", "w", encoding="utf-8") as outfile:
    json.dump(questions, outfile, indent=4, ensure_ascii=False)

print("Procedural questions generated successfully.")







# Procedural Prompt for LLM: Ensure Image Content Is Always Included in the Generated QA Pairs

"""
You are a financial expert with expertise in corporate finance, investment strategies, and accounting. 
Generate distinct and meaningful procedural question-answer pairs by combining the provided paragraph text and image descriptions. 
Questions and answers must be unique, logical, and must always seamlessly include relevant image content in the answer.

---

### Key Instructions:

1. **Combine Text and Image Content:**
    - For each section of text, identify and merge the corresponding image description if the image belongs to the same or adjacent page.
    - Always reference key visual details, descriptions of tables, interfaces, or processes from the image description in the answers.

2. **Summarize Relevant Details:**
    - Extract and summarize necessary tables, data fields, financial documents, or interface instructions from both the text and image descriptions.
    - Ensure image-based data, such as descriptions of financial tables or software interfaces, are directly integrated into the steps.

3. **Maintain Step-Wise Logical Flow:**
    - Provide a step-by-step explanation of the task or process, incorporating VLOOKUPs, missing data checks, and decision-making steps.
    - Where applicable, explain how image-related information guides or supports each step.

4. **Mandatory Image Integration:**
    - If an image contains tables, fields, or interface actions, describe them explicitly and explain how they influence or support the process.
    - Avoid generic instructions; each answer must incorporate visual content to enhance or clarify the steps.

5. **Include Branching or Conditional Logic:**
    - Include conditions (e.g., handling missing fund codes or errors). Reference images that depict relevant screens, documents, or fields for decision-making.

---

### Input Format:

- **Text:** {paragraph}
- **Image descriptions:** {image_content}

---

### Output Format:
Generate a JSON array with entries structured as follows:

[
  {
    "question": "What are the steps to complete this task involving financial oversight and job monitoring?",
    "answer": [
      "Step 1: Review the job monitoring data mentioned in the text and refer to the image description of the job monitoring tool. Double-click the job code 'AAS_MC_UPDATE_CLIENT_VFM' as depicted in the image.",
      "Step 2: Verify the job status using the Job Monitor interface (refer to the image description showing the monitoring system). If an issue is detected, consult any warnings or messages displayed on the screen.",
      "Step 3: Perform a VLOOKUP on job codes using the corresponding financial tables shown in the text and the financial statement depicted in the image description. Address any discrepancies, especially those involving missing or invalid fund codes.",
      "Step 4: Cross-reference the extracted job monitoring logs and ensure completion using the UI shown in the job monitor interface described in the image. If the system raises a flag (e.g., CHECK FUND), investigate by referring to details in the financial document image."
    ],
    "extracted": "Combined content from text and image descriptions for job monitoring, oversight, and financial review."
  }
]

---

### Handling Image Content:

- Always include and reference relevant images in each answer step. Ensure that if an image shows a tool, financial document, or process, it is directly linked to the respective instructions.
- Integrate images logically to provide enhanced clarity or guidance for each procedural step.
- If an image description contains key tables or financial data, explain their importance in relation to the task.

Ensure the LLM generates comprehensive answers by integrating both textual and image-based information seamlessly.
"""





# Procedural Prompt for LLM: Combining Text and Image Content for QA Generation

"""
You are a financial expert with expertise in corporate finance, investment strategies, and accounting. 
Generate distinct and meaningful procedural question-answer pairs by combining the provided paragraph text and image descriptions. 
Questions and answers must be unique, logical, and should seamlessly include relevant image content.

---

Key Instructions:

1. Combine Text and Image Content:
    - For each section of the text, identify and merge the corresponding image description if the image belongs to the same or adjacent page.  
    - Integrate relevant image details such as interface descriptions, financial documents, or job-monitoring tools into the question and answer content.

2. Summarize Relevant Details:
    - Extract tables, data points, financial details, or interface descriptions mentioned in both text and images to provide enhanced answers.  
    - If a step involves navigating through a tool or UI, use image descriptions to explain the user interaction.

3. Maintain Step-Wise Logical Flow:
    - Provide a step-wise explanation of the process, incorporating VLOOKUPs, status updates, fund checks, or any missing/invalid codes.  
    - Use conditions and branching logic (e.g., instructions when a fund code is labeled CHECK FUND).

4. Include Visual Instructions:
    - If an image shows a table, field, or action, describe how it relates to the corresponding step in the text.  
    - Avoid redundancy by merging image content directly into relevant steps.

5. Integrate Tables, Columns, and Conditions:
    - Reference any specific tables, column headers, job monitors, or data points as described in either the text or image description.  
    - Ensure each step meaningfully contributes to achieving the overall task.

---

### Input Format:

- Text: {paragraph}
- Image descriptions: {image_content}

---

### Output Format:
Generate a JSON array with entries structured as follows:

[
  {
    "question": "What are the steps to complete this task involving financial oversight and job monitoring?",
    "answer": [
      "Step 1: Review the provided job monitoring data, ensuring that relevant jobs (e.g., 'AAS_MC_UPDATE_CLIENT_VFM') are correctly identified in the Job Monitor interface.",
      "Step 2: Refer to the interface as depicted in the image description for the job monitoring tool. Double-click the job and verify the status or completion logs.",
      "Step 3: Use VLOOKUP functions where necessary to match missing or incorrect job codes (cross-referencing image content from the job monitoring tool).",
      "Step 4: Investigate missing or invalid fund codes using any tables or fields described in the financial document (refer to descriptions from the financial document image)."
    ],
    "extracted": "Combined content from text and image descriptions for job monitoring, oversight, and financial review."
  }
]

---

### Handling Image Content:
- Ensure image details (e.g., UI components, financial documents, job monitors) are included as part of relevant procedural steps.
- Where image descriptions describe actions (e.g., double-clicking a job), place the actions in the respective steps.
- Use image-based instructions for visual cues to enhance or clarify actions.

Ensure each answer integrates both text and image content logically and provides comprehensive procedural guidance.
"""







PROCEDURAL PROMPT

You are a financial expert with expertise in corporate finance, investment strategies, and accounting. Questions and answers must be distinct and should not repeat.

Generate up to (num_questions) distinct procedural question-answer pairs by dynamically combining content from **pdf_text** (containing text content) and **image_text** (containing image descriptions). Match image descriptions to the corresponding pages by their **page_number** and integrate them seamlessly into the procedural steps. **Do not specify or mention page numbers in either the questions or the answers.**

---

### Key Instructions:
1. **Dynamic Linking by Page Number:** For each section of text in `pdf_text`, search for any corresponding images in `image_text` based on **page_number**. If matching images are found, combine the image descriptions with the text content.
2. **Text and Image Integration:** Integrate image descriptions naturally within the relevant procedural steps, ensuring the instructions remain cohesive and logical.
3. **Logical Flow and Conditions:** Maintain logical order by including conditions (e.g., VLOOKUP checks, status updates, investigation logs) and instructions for handling issues like missing fund codes or process failures.

---

### Content Requirements:
- **Combine Text and Image Content:** Seamlessly combine text content from `pdf_text` and relevant image descriptions from `image_text` to create detailed procedural instructions.
- **Include Specific Data:** Reference any specific tables, columns, portals, or tools directly where applicable.
- **Branching Logic:** Include instructions for handling errors, conditions, or branching logic as necessary.

---

### Handling Edge Cases:
- **If an image is found for a section:** Include its description within or after the relevant text-based instructions.
- **If no image is found for a section:** Base the instructions solely on the text content.
- **If an image exists without meaningful text:** Create image-based instructions independently.

---

### Output Format:
Generate a JSON array with each entry in the following format:
```json
[
    {
        "question": "What are the steps to complete this process?",
        "answer": [
            "Step 1: [Step description from the combined content].",
            "Step 2: [Next logical step, integrating text and images].",
            "Step n: [Subsequent steps, branching if necessary]."
        ],
        "extracted": "Combined content from text and image descriptions"
    }
]












PROCEDURAL PROMPT

You are a financial expert with expertise in corporate finance, investment strategies, and accounting. Questions and answers must be distinct and should not repeat.

Generate up to (num_questions) distinct procedural question-answer pairs by dynamically combining content from **pdf_text** (containing text content) and **image_text** (containing image descriptions). Match **image descriptions** to the corresponding pages by their **page_number** and integrate them into the procedural steps naturally.

---

### Key Instructions:
1. **Dynamic Linking by Page Number:** For each page in `pdf_text`, search for any corresponding images in `image_text` based on **page_number**. If matching images are found, combine the image descriptions with the text to generate comprehensive procedural questions and answers.
2. **Text and Image Integration:** Integrate image descriptions directly into the relevant text-based instructions. Ensure the image content complements the text logically and flows smoothly.
3. **Logical Flow and Conditions:** Maintain logical order by including conditions (e.g., VLOOKUP checks, status updates) and instructions for handling issues like missing fund codes, incorrect values, or process failures.

---

### Content Requirements:
- **Combine Text and Image Content:** Use text content from `pdf_text` and related image descriptions from `image_text` to create rich procedural instructions.
- **Include Specific Data:** If any specific tables, columns, tools, or portals are mentioned in the text or images, reference them directly.
- **Branching Logic:** Include instructions for handling issues such as missing or incorrect data when needed.

---

### Handling Cases:
- **If an image is found for a page:** Include its description after or within the relevant text instructions.
- **If no image is found for a page:** Base the instructions solely on the text content from that page.
- **If an image exists without meaningful text:** Create image-based instructions independently.

---

### Output Format:
Generate a JSON array with each entry in the following format:
```json
[
    {
        "question": "What are the key procedural steps for page X?",
        "answer": [
            "Step 1: [Step description from combined text and images].",
            "Step 2: [Next step, integrating any conditions or checks].",
            "Step n: [Subsequent steps]."
        ],
        "extracted": "Combined content from text and image descriptions"
    }
]












PROCEDURAL PROMPT

You are a financial expert with expertise in corporate finance, investment strategies, and accounting. Questions and answers must be distinct and should not repeat.

Generate up to (num_questions) distinct procedural question-answer pairs by dynamically combining content from **`text.json`** and **`image.json`**. Match image descriptions to the corresponding pages by their **`page_number`**. Integrate the matched image content with the text to form comprehensive questions and answers.

### Key Instructions for Dynamic Matching:
1. **Page Number Linking:** For each page in `text.json`, search for images in `image.json` with the same **`page_number`**. If matching images are found, incorporate their descriptions directly into the steps.
2. **Text and Image Integration:** When summarizing, combine the image descriptions with the corresponding page text. Place relevant image-based details after or within the related text instructions for context.
3. **Ensure Logical Flow:** Maintain logical order by interleaving text and image-based details naturally within the procedural steps.

### Content Requirements:
- **Combine Text and Image Data:** Use text content from `text.json` and related image descriptions from `image.json` to create rich procedural instructions.
- **Include Tables, Columns, and Tools:** If any specific tables, columns, tools, SWIFT codes, or portals are mentioned in the text or images, directly reference them.
- **Handle Conditions and Branching:** Include branching logic (e.g., VLOOKUP checks, status updates) when required, based on the combined content.

### Example Logic for Integration:
- For **`page_number` X**, include instructions derived from both text and image content.  
  - **Text:** Provide steps for the procedure based on the pages text content.  
  - **Image:** If an image on the same page is related to the text (e.g., a financial table, job monitoring interface), append its description to the corresponding step.

---

### Output Format:
Generate a JSON array with each entry in the following format:
```json
[
    {
        "question": "What are the steps to achieve or complete this process?",
        "answer": [
            "Step 1: [Integrate text from the page and image content if applicable].",
            "Step 2: [Next logical step, referencing text and image details as necessary].",
            "Step n: [Subsequent steps, incorporating any conditions or branching logic]."
        ],
        "extracted": "Combined content from text and image descriptions on the relevant pages"
    }
]






PROCEDURAL PROMPT

You are a financial expert with expertise in corporate finance, investment strategies, and accounting. Questions and answers must be distinct and should not repeat.

Generate up to (num_questions) distinct procedural question-answer pairs by dynamically combining content from **`text.json`** and **`image.json`**. Match image descriptions to the corresponding pages by their **`page_number`**. Integrate the matched image content with the text to form comprehensive questions and answers.

### Key Instructions for Dynamic Matching:
1. **Page Number Linking:** For each page in `text.json`, search for images in `image.json` with the same **`page_number`**. If matching images are found, incorporate their descriptions directly into the steps.
2. **Text and Image Integration:** When summarizing, combine the image descriptions with the corresponding page text. Place relevant image-based details after or within the related text instructions for context.
3. **Ensure Logical Flow:** Maintain logical order by interleaving text and image-based details naturally within the procedural steps.

### Content Requirements:
- **Combine Text and Image Data:** Use text content from `text.json` and related image descriptions from `image.json` to create rich procedural instructions.
- **Include Tables, Columns, and Tools:** If any specific tables, columns, tools, SWIFT codes, or portals are mentioned in the text or images, directly reference them.
- **Handle Conditions and Branching:** Include branching logic (e.g., VLOOKUP checks, status updates) when required, based on the combined content.

### Example Logic for Integration:
- For **`page_number` X**, include instructions derived from both text and image content.  
  - **Text:** Provide steps for the procedure based on the pages text content.  
  - **Image:** If an image on the same page is related to the text (e.g., a financial table, job monitoring interface), append its description to the corresponding step.

---

### Output Format:
Generate a JSON array with each entry in the following format:
```json
[
    {
        "question": "What are the steps to achieve or complete this process?",
        "answer": [
            "Step 1: [Integrate text from the page and image content if applicable].",
            "Step 2: [Next logical step, referencing text and image details as necessary].",
            "Step n: [Subsequent steps, incorporating any conditions or branching logic]."
        ],
        "extracted": "Combined content from text and image descriptions on the relevant pages"
    }
]











PROCEDURAL PROMPT

You are a financial expert with expertise in corporate finance, investment strategies, and accounting. Questions and answers must be distinct and should not repeat.

Generate up to (num_questions) distinct procedural question-answer pairs based on the input text and images. Match content from **image descriptions** to the relevant pages using the **page numbers** from both `text.json` and `image.json`. Integrate related text and image content seamlessly into the questions and answers.

Key Instructions:

1. For each page, if an image description is present, combine the textual content with the image description to provide enhanced context.
2. Summarize and extract necessary columns, tables, or data fields from both the text and image content on the corresponding page.
3. Maintain step-wise logical flow, including conditions such as VLOOKUP checks, status updates, missing fund codes, or investigation logs.
4. Ensure that each step clearly describes how to use the combined input, referencing any tables, columns, data points, conditions, or decision-making steps.
5. Use branching logic or conditions when necessary (e.g., what to do if a fund code is missing or labeled as 'CHECK FUND').

### Requirements:

- If specific details (e.g., columns, SWIFT codes, fund codes, case IDs, tabs) are provided in either the text or image content, include them directly in the appropriate steps.
- Include tables, columns, and data points exactly as described in the text or image content.
- Reference portals, URLs, or tools mentioned directly in the process.
- For each page, append relevant image descriptions to the corresponding text section when summarizing.

### Handling Images:
- If an image contains tables, tools, or specific fields, mention them explicitly in the relevant steps.
- Maintain logical flow by placing image-based instructions after their corresponding textual content.
  
### Specific Instructions:

1. Summarize the combined content from both the text and images logically.
2. Avoid redundancy or step repetition, and ensure that each step contributes meaningfully to the overall process.
3. For conditions such as VLOOKUP or identifying missing values, describe the check and the corresponding next step.
4. Include relevant tables, field names, column headers, tabs, or codes exactly as described in either input file.
5. Match image content to its corresponding page in the text and integrate both inputs seamlessly.

### Output Format:
Generate a JSON array with each entry in the following format:
```json
[
    {
        "question": "What are the steps to achieve or complete this process?",
        "answer": [
            "Step 1: [Description of first step, including text and image content if present].",
            "Step 2: [Next logical step in the process, referencing any relevant tables, fields, or conditions].",
            "Step n: [Subsequent steps, incorporating images and text as necessary]."
        ],
        "extracted": "Combined content from text and image descriptions on relevant pages"
    }
]









def extract_text_and_metadata_pagewise(file, output_dir="outputs_sdr"):
    pdf_data = {
        "metadata": {},
        "pages": []
    }

    # Ensure output directory exists
    os.makedirs(output_dir, exist_ok=True)

    # Open the PDF file and read metadata
    with open(file, 'rb') as pdf_file:
        reader = PyPDF2.PdfReader(pdf_file)
        pdf_data["metadata"] = {k[1:]: v for k, v in reader.metadata.items()} if reader.metadata else {}

        # Extract text page by page
        for page_index, page in enumerate(reader.pages):
            page_text = page.extract_text() if page.extract_text() else ""
            pdf_data["pages"].append({
                "page_number": page_index + 1,
                "text": page_text.strip()
            })
            print(f"[+] Extracted text from page {page_index + 1}")

    # Save the result to JSON
    save_json(output_dir, pdf_data)

    return pdf_data

def save_json(output_dir, pdf_data):
    json_file_path = os.path.join(output_dir, "text.json")
    with open(json_file_path, "w", encoding="utf-8") as json_file:
        json.dump(pdf_data, json_file, indent=4, ensure_ascii=False)
    print(f"[+] JSON saved to: {json_file_path}")

# Example pipeline usage
pdf_path = r"H:\Question and answer\Fund accounting\example.pdf"
output_folder = r"H:\Question and answer\Fund accounting"

pdf_text = extract_text_and_metadata_pagewise(pdf_path, output_folder)
print("Step 1 Extracted text from PDF completed\n")






# Function to process a single image
def process_image(pdf_file, page_index, image_index, img, output_dir):
    xref = img[0]
    base_image = pdf_file.extract_image(xref)
    image_bytes = base_image["image"]
    image_ext = base_image["ext"]

    # Save the image to the output directory
    image_name = f"image_page{page_index+1}_{image_index}.{image_ext}"
    image_path = os.path.join(output_dir, image_name)
    with open(image_path, "wb") as image_file:
        image_file.write(image_bytes)

    # Convert the image to Base64
    image_data = base64.b64encode(image_bytes).decode("utf-8")

    # Get image description
    description = img_description(image_data)

    # Return page number along with the image details
    return {
        "page_number": page_index + 1,
        "image_name": image_name,
        "description": description
    }



# Function to extract metadata from PDF
def extract_metadata(pdf_file):
    metadata = pdf_file.metadata
    # Clean up metadata (remove '/' from keys)
    return {key.strip('/'): value for key, value in metadata.items() if value}









import json
import PyPDF2
import os

# Function to save JSON data
def save_json(output_dir, pdf_data):
    json_file_path = os.path.join(output_dir, "text_metadata_sop.json")
    with open(json_file_path, "w", encoding="utf-8") as json_file:
        json.dump(pdf_data, json_file, indent=4, ensure_ascii=False)
    print(f"[+] JSON saved to: {json_file_path}")

# Function to extract text and metadata
def extract_text_and_metadata_pagewise(file, output_dir="outputs_sdr"):
    pdf_data = {
        "metadata": {},
        "pages": []
    }

    # Ensure output directory exists
    os.makedirs(output_dir, exist_ok=True)

    # Open the PDF file and read metadata
    with open(file, 'rb') as pdf_file:
        reader = PyPDF2.PdfReader(pdf_file)
        pdf_data["metadata"] = {k[1:]: v for k, v in reader.metadata.items()} if reader.metadata else {}

        # Extract text page by page
        for page_index, page in enumerate(reader.pages):
            page_text = page.extract_text() if page.extract_text() else ""
            pdf_data["pages"].append({
                "page_number": page_index + 1,
                "text": page_text.strip()
            })
            print(f"[+] Extracted text from page {page_index + 1}")

    # Save the result to JSON using the custom save_json function
    save_json(output_dir, pdf_data)

    return pdf_data

# Example usage
pdf_path = "example.pdf"
extract_text_and_metadata_pagewise(pdf_path)










import json
import PyPDF2
import os

def save_json(output_dir, data, json_filename):
    os.makedirs(output_dir, exist_ok=True)
    output_file = os.path.join(output_dir, json_filename)
    with open(output_file, 'w', encoding='utf-8') as json_file:
        json.dump(data, json_file, indent=4, ensure_ascii=False)
    print(f"[+] JSON saved to: {output_file}")

def extract_text_and_metadata_pagewise(file, output_dir="outputs_sdr"):
    pdf_data = {
        "metadata": {},
        "pages": []
    }

    # Open the PDF file and read metadata
    with open(file, 'rb') as pdf_file:
        reader = PyPDF2.PdfReader(pdf_file)
        pdf_data["metadata"] = {k[1:]: v for k, v in reader.metadata.items()} if reader.metadata else {}

        # Extract text page by page
        for page_index, page in enumerate(reader.pages):
            page_text = page.extract_text() if page.extract_text() else ""
            pdf_data["pages"].append({
                "page_number": page_index + 1,
                "text": page_text.strip()
            })
            print(f"[+] Extracted text from page {page_index + 1}")

    # Determine JSON filename based on PDF name
    base_name = os.path.splitext(os.path.basename(file))[0]
    json_filename = f"{base_name}.json"

    # Save the result to JSON
    save_json(output_dir, pdf_data, json_filename)

    return pdf_data

# Example usage
pdf_path = "example.pdf"
extract_text_and_metadata_pagewise(pdf_path)











import json
import PyPDF2

def extract_text_and_metadata_pagewise(pdf_path, json_output_path):
    pdf_data = {
        "metadata": {},
        "pages": []
    }

    # Open the PDF file
    with open(pdf_path, 'rb') as file:
        reader = PyPDF2.PdfReader(file)

        # Extract metadata
        metadata = reader.metadata
        pdf_data["metadata"] = {k[1:]: v for k, v in metadata.items()}  # Strip leading '/' from keys

        # Extract text page by page
        for page_number, page in enumerate(reader.pages):
            page_text = page.extract_text() if page.extract_text() else ""
            pdf_data["pages"].append({
                "page_number": page_number + 1,
                "text": page_text.strip()
            })

    # Write the result to a JSON file
    with open(json_output_path, 'w', encoding='utf-8') as json_file:
        json.dump(pdf_data, json_file, indent=4, ensure_ascii=False)

# Example usage:
pdf_path = "example.pdf"
json_output_path = "output_pagewise.json"
extract_text_and_metadata_pagewise(pdf_path, json_output_path)





import json
import PyPDF2

def extract_text_and_metadata_from_pdf(pdf_path, json_output_path):
    pdf_text = ""
    metadata = {}

    # Open the PDF file
    with open(pdf_path, 'rb') as file:
        reader = PyPDF2.PdfReader(file)

        # Extract text from all pages
        for page in reader.pages:
            pdf_text += page.extract_text() if page.extract_text() else ""

        # Extract metadata
        metadata = reader.metadata

    # Create a dictionary with text and metadata
    result = {
        "metadata": {k[1:]: v for k, v in metadata.items()},  # Strip leading '/' from keys
        "text": pdf_text
    }

    # Write the result to a JSON file
    with open(json_output_path, 'w', encoding='utf-8') as json_file:
        json.dump(result, json_file, indent=4, ensure_ascii=False)

# Example usage:
pdf_path = "example.pdf"
json_output_path = "output.json"
extract_text_and_metadata_from_pdf(pdf_path, json_output_path)










ChatGPT 4o

You said:
My prompt

Specific Instructions:

-Ensure that any tables, specific data references, or fields mentioned in the input (e.g., column names, codes, identifiers, etc.) are preserved directly in the relevant steps.

-If the input includes details about portals, storage, or tools, embed them directly into the steps.

-Avoid redundancy or step repetition.

-while answering look for image in the same page or next page from which page the text part is coming. If specific data, columns, tables, or conditions are mentioned in the image description, they must be directly included in the answer.

Replace "[specific process/task derived from the input]" with a task-specific description.

For example:

If the task involves updating transaction records, use "the transaction update process."

If related to SWIFT codes, use "the SWIFT code validation process."

Ensure to match the corresponding image with answer text.



"""My image input 
Example
image_description data

"image_name": "image3_1.png",

Street Corporation, specifically a "Browse Calendar File Detail" s End Date: 20190821, 20190731, 20190630\n **Valuation Status:**

{ "description": "The image appears to be a detailed financial document from State 31, 20200630\n**Prior:***\n -**Start Date: 20190821, 20190701, 20180701\n e disclaimers or terms and conditions at the bottom or in a separate section.\n- **Professional Appearance:** The document has a formal and professional appe

"image_name": "image5_2.png",

<

{ "description": "The image depicts a software interface, specifically a job monitoring system, which is divided into two main sections: "Job Status" E pattern, status, time zone, pool size, updated date, and the user who updated it. In The \"Status\" column shows that all jobs have \"succeeded," and th ed.\n The second row is highlighted with a red border, possibly indicating a selected or important entry.\n Similar to the "Job Status\" table, this t oring or scheduling software. \n- The use of colors is minimal, with light blue for headers and section dividers, and red for highlighting important, elements.
"" another in put 
We are providing whole text 
Can u change the specifuc instruction clearly

ChatGPT said:
ChatGPT
Revised Specific Instructions:
Preserve Critical Data: Maintain any tables, columns, data fields, codes, identifiers, or conditions mentioned in the input as they are. Ensure that all referenced details, such as column names, transaction records, or SWIFT codes, are directly embedded into the answer.

Image-Text Correlation: If the task refers to content from an image, ensure that the description and corresponding text from that image are accurately captured. Always match the image content to the relevant section in the answer.

Context-Specific Descriptions: Replace placeholders like "[specific process/task derived from the input]" with clear task descriptions. For example:

If updating records, mention "the record update process".
If related to validation, specify "the SWIFT code validation process".
When managing financial dates or reports, describe "the financial report review process".
Avoid Redundancy: Ensure the steps or instructions do not repeat unnecessarily unless required for clarity.

Multiple Images: If details are spread across multiple images, cross-reference text from the corresponding images on the same or next page. Ensure that any tables or sections found in images are integrated seamlessly into the explanation.

Professional Tone and Presentation: Maintain formal, clear, and concise writing. Ensure any disclaimers, terms, or descriptions from the input are appropriately included without altering their intended meaning.

Example Clarification:
If the input includes a table from a financial report or job monitoring interface, integrate details such as job status, start and end dates, or financial valuations in the answer as follows:

"The job status update process ensures that records reflecting jobs with 'succeeded' status are marked for verification before proceeding."
This should match the relevant image or table content exactly as described.






You said:
Give like as my for. At
ChatGPT said:
ChatGPT
Heres the revised version of the instructions following your preferred format:

Specific Instructions:
Preserve Critical Data:

Ensure any tables, columns, specific data fields, codes, identifiers, or conditions from the input are directly embedded in the answer without modifications.
Examples include transaction details, column names, financial dates, SWIFT codes, or valuation statuses.
Image-Text Matching:

Look for relevant images from the same or next page of the text reference.
Match and include tables, conditions, or fields from the image description into the answer where applicable.
Task-Specific Descriptions:

Replace placeholders like "[specific process/task derived from the input]" with clear task-based terms:
For updating transaction records, use "the transaction update process".
For validating SWIFT codes, use "the SWIFT code validation process".
For managing financial data, specify "the financial valuation process".
Avoid Redundancy:

Do not repeat steps unless necessary. Ensure concise and non-repetitive instructions.
Multiple Image References:

If the task spans multiple images, ensure proper cross-referencing and integration of data or tables.
Professional Tone:

Maintain formal and structured language. Include terms, conditions, and disclaimers from the input where necessary, keeping their original intent.
Example: If provided a table from a financial report or job monitoring system:

"The job status verification process ensures that jobs marked as 'succeeded' are reviewed for compliance, referencing data such as 'Updated Date' and 'User' from the corresponding image tables."










Search


ChatGPT can make mistakes. Check important info














ChatGPT 4o

You said:
PROCEDURAL PROMPT

You are a financial expert with expertise in corporate finance, investment strategies, and accounting. Questions and answers must be distinct and should not repeat.

Ensure that answers reference or describe relevant images within the image description. If an image contains text, diagrams or key visual elements, include a description of those elements in the answer. If an image supports the context of the answer,summarize its contents concisely and explain how it relates to the question.

Maintain clarity and completeness in response. Generate up to (num_questions) distinct procedural question-answer pairs based on the input text and image description data.

Key Instructions:

Do not treat as the image description data and text as separate, please be treated as a single input.

The image description data (provided as a dictionary) must be summarized,nd relevant details must be incorporated into the process steps where necessary.

Summarize and extracted necessary columns, tables, or data fields from the image content and integrate them naturally into the steps.

Maintain step-wise logical flow, including conditions vlookup check, status updates, missing fun codes, or investigation logs etc. Ensure that each step clearly describes how to use the combined input, referencing any tables, columns, data points, conditions, or

decision-making steps.

If specific details (e.g., columns, SWIFT codes, fund codes, case IDs, or tabs) are provided in either the image or text, they should be included directly in the appropriate steps. I

Use branching logic or conditions when necessary (e.g., what to do if a fund code is missing or labeled as 'CHECK FUND").

Instructions for Process Description:**

Replace "[specific process/task derived from the input]" with a task-specific description.

For example:

If the task involves updating transaction records, use "the transaction update process."

If related to SWIFT codes, use "the SWIFT code validation process."

Requirements:

Incorporate both the text and image content into the procedural steps. If specific data, columns, tables, or conditions are mentioned in the image description, they must be directly included in the answer.

Ensure that each step clearly describes how the data is used, any conditions (e.g., vlookup), and branching
decisions such as what to do when specific values (e..

CHECK FUND) are encountered. Give me the a complete answer which combined both text image summarization.

Preserve data references, column labels (A, C, etc.), tabs, SWIFT codes, fund codes, and case IDs exactly as they appear in the input.

portals, URLs, or specific tools are mentioned in the process, include them directly in the relevant steps. If Each step should logically follow the process of identifying, copying, checking, updating, and escalating tasks.

Preserve any references to columns (A, B, C, etc.), tabs (PD, globaluaxl), tables, fields, and codes exactly as provided in the input.

the process involves conditions (e.g., vlookup, identifying missing information), clearly describe the check and the corresponding next step.

If If decisions or branching logic exists, include clear instructions on what to do in each cases.

Use exact terminology provided in the input, and don't generalize steps unnecessarily.

Specific Instructions:

-Ensure that any tables, specific data references, or fields mentioned in the input (e.g., column names, codes, identifiers, etc.)

are preserved directly in the relevant steps.

-If the input includes details about portals, storage, or tools, embed them directly into the steps.

-Avoid redundancy or step repetition.

Input:

-Text: (paragraph)

-Image description data: The following images are provided in image description: {image_content)

Output format:

[

{{ "question": "What are the steps to achieve or complete this process?",

"answer": [

"Step 1: Access the data via portal_name at data_access_url. Ensure you have the correct credentials: authentication_details.",

"Step 2: Retrieve the relevant files stored at storage_location within database_name.",

"Step n: Process the data according to the required methodology."
]
"extracted":"paragraph, image_content or paragraph/image_content"

]

}},

Ensure the response is a valid JSON array.
"""
" you can instruct the prompt prepare the question combinedly both text and image content treated as single input file and also while preapring the question that corresponding answer if it available or not in image deacription u can check that image include in the answer also 
ChatGPT said:
ChatGPT
Understood! Here's a structured JSON output combining the procedural prompt's requirements with an integrated question-answer approach, derived from both the provided text and image descriptions:

[
    {
        "question": "What are the steps to validate and update SWIFT transactions with missing or incorrect codes?",
        "answer": [
            "Step 1: Access the portal at 'portal_name' using the provided link 'data_access_url' and ensure you have the necessary credentials.",
            "Step 2: Navigate to the 'Pending SWIFT Validation' tab, and retrieve the transaction file stored in 'Global_SWIFT_Transactions.xls'.",
            "Step 3: Open the file, and cross-check Column A (Transaction ID) and Column C (Fund Code) against the external master reference file using a VLOOKUP function.",
            "Step 4: If Column C displays 'CHECK FUND', escalate the record by logging it into the 'Error Log' sheet within the same file and tag it with the current date in Column D (Escalation Date).",
            "Step 5: For transactions with valid SWIFT codes, mark them as 'VALIDATED' in Column E, and save the changes.",
            "Step 6: Upload the updated file to the designated portal location 'Updated_SWIFT_Records'. Confirm successful upload by checking the system-generated status message.",
            "Step 7: Notify the respective team via email, including the updated SWIFT file and the logged error cases."
        ],
        "extracted": "Combined content from paragraph and image description."
    },
    {
        "question": "How should missing fund codes (displaying 'CHECK FUND') be handled within the validation process?",
        "answer": [
            "Step 1: Identify rows with 'CHECK FUND' in Column C of the transaction data.",
            "Step 2: Document these cases in the 'Error Log' tab, specifying the corresponding Transaction ID, Fund Code, and validation date.",
            "Step 3: Investigate the missing fund code using the 'Fund Reference Database', located in the 'globaluaxl' tab.",
            "Step 4: If the correct code is found, update the original SWIFT record and revalidate using VLOOKUP.",
            "Step 5: For unresolved cases, escalate by creating a case ID in the 'Fund Investigation Portal' and assign it to the Fund Review Team.",
            "Step 6: Monitor for status updates within the investigation log and ensure that any corrected cases are reprocessed promptly."
        ],
        "extracted": "Integrated from both input text and image description."
    },
    {
        "question": "What is the branching logic if errors are encountered during the SWIFT validation process?",
        "answer": [
            "Branch 1: If VLOOKUP identifies no errors, proceed to Step 6 and mark the record as 'VALIDATED'.",
            "Branch 2: If Column C indicates 'CHECK FUND', document the case in the 'Error Log' and follow the fund investigation steps.",
            "Branch 3: If a missing or mismatched SWIFT code is found, escalate it to the SWIFT Review Team using 'Case Tracker.xls'.",
            "Branch 4: For system-related upload errors, retry the upload using the backup file from 'Backup_SWIFT_Records'. If the issue persists, escalate to IT Support."
        ],
        "extracted": "Branching derived from both text and image references."
    }
]
This JSON ensures the integration of procedural steps, conditions, branching logic, and the necessary data extraction from both the text and image content as specified.






You said:
U can give me the prompt according to my requirements 
ChatGPT said:
ChatGPT
Heres the prompt tailored to meet your requirements perfectly:

Prompt:

You are a financial expert with expertise in corporate finance, investment strategies, and accounting. Questions and answers must be distinct and should not repeat.

Ensure that answers reference or describe relevant images within the image description. If an image contains text, diagrams, or key visual elements, include a description of those elements in the answer. If an image supports the context of the answer, summarize its contents concisely and explain how it relates to the question.

Maintain clarity and completeness in the response. Generate up to (num_questions) distinct procedural question-answer pairs based on the input text and image description data.

Key Instructions:

Treat the text and image description as a single input. Do not separate them during question-answer creation.
Summarize and extract necessary columns, tables, or data fields from the image content and integrate them naturally into the steps.
Maintain a logical, step-wise flow, including VLOOKUP checks, status updates, missing fund codes, or investigation logs. Ensure that each step clearly describes how to use the combined input, referencing any tables, columns, data points, conditions, or decision-making steps.
If specific details (e.g., columns, SWIFT codes, fund codes, case IDs, or tabs) are provided in either the text or image, they should be included directly in the steps.
Use branching logic or conditions when necessary (e.g., what to do if a fund code is missing or labeled as CHECK FUND).
Replace [specific process/task derived from the input] with task-specific descriptions:
For example:

If the task involves updating transaction records, use "the transaction update process."
If related to SWIFT codes, use "the SWIFT code validation process."
Procedural Steps Format:

Ensure data references (columns, tabs, codes) are preserved exactly as provided in the input.
If the process involves conditions (e.g., VLOOKUP, identifying missing information), describe checks and corresponding next steps clearly.
If decisions or branching logic exist, include detailed instructions on handling each case.
Embed any portals, URLs, or tools mentioned in the input directly into the steps.
Input Format:

Text: (paragraph)
Image description data: {image_content}
Output Format (JSON):

[
    {
        "question": "What are the steps to achieve or complete this process?",
        "answer": [
            "Step 1: [Access the relevant portal and navigate to specified location.]",
            "Step 2: [Retrieve files as indicated and perform validation checks using provided conditions.]",
            "Step n: [Document errors, update cases, and escalate issues when required.]"
        ],
        "extracted": "[paragraph, image_content, or paragraph/image_content]"
    }
]
Additional Notes:

Ensure that tables, fields, columns, and portals mentioned in the input are preserved exactly in the output.
Handle any specific conditions or missing values as described in the input text and image.
Provide distinct, non-repetitive questions with clear answers for every generated pair.











ChatGPT can make mistakes. Check important 







**Instructions for Process Description:**  
- Replace **"[specific process/task derived from the input]"** with a task-specific description. For example:  
  - If the task involves updating transaction records, use "the transaction update process."  
  - If related to SWIFT codes, use "the SWIFT code validation process."  







prompt_template = (
        "You are provided with descriptions of financial documents that may contain details such as company "
        "names, dates, transaction codes, tables, levels, cycle dates, and other structured information. "
        "Your task is to generate a comprehensive summary that highlights the following:\n"
        "- Key entities such as company names, transaction codes, and funds.\n"
        "- Important dates and timelines (start dates, end dates, cycle dates).\n"
        "- Any detailed levels and their corresponding statuses (BL, S1, S2, etc.).\n"
        "- Calculations, tables, or formulas related to financial transactions.\n"
        "- Additional metadata or structured information present in the descriptions.\n\n"
        "Descriptions:\n{descriptions}\n\n"
        "Summarize this information comprehensively while ensuring no key structured details are missed."
    )





import json
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.chat_models import AzureChatOpenAI

def generate_summary_from_json(json_data, output_file="summary_output.json"):
    # Step 1: Extract and concatenate descriptions
    descriptions = " ".join([entry["description"] for entry in json_data])

    # Step 2: Configure the Azure OpenAI Chat model
    llm = AzureChatOpenAI(
        temperature=0.5,
        api_version="azure_openai_api_version",  # Replace with your API version
        azure_openai_api_key="YOUR_AZURE_API_KEY",  # Replace with your API key
        azure_openai_base="azure_openai_endpoint",  # Replace with your Azure endpoint
        deployment_name="ssgpt-40"
    )

    # Step 3: Define the prompt template
    prompt_template = (
        "Summarize the following financial document descriptions into a concise summary "
        "highlighting key themes and recurring information:\n\n{descriptions}"
    )

    # Create the prompt template
    prompt = PromptTemplate(
        input_variables=["descriptions"],
        template=prompt_template
    )

    # Step 4: Create the LLM chain
    llm_chain = LLMChain(llm=llm, prompt=prompt)

    try:
        # Step 5: Generate the response using the LLM chain
        response = llm_chain.predict(descriptions=descriptions)

        # Format the output
        summary_data = {
            "Summary": response.strip()
        }

        # Step 6: Save to JSON file
        with open(output_file, "w") as outfile:
            json.dump(summary_data, outfile, indent=4)

        print(f"Summary successfully saved to {output_file}")

        # Return the output as a dictionary for optional use
        return summary_data
    
    except Exception as e:
        print(f"Error generating summary: {e}")
        return {"Error": str(e)}

# Sample JSON input
json_data = [
    {"image_name": "image1_1.png", "description": "The document in question appears to be a professional financial statement or bank statement."},
    {"image_name": "image3_1.png", "description": "The image depicts a professional financial document, likely a bank statement, with a structured format."},
    {"image_name": "image3_2.png", "description": "The image depicts a professional financial document, likely a bank statement or account summary."},
    {"image_name": "image4_1.png", "description": "The image depicts a professional document titled 'Global Transactions and Controls.'"},
    {"image_name": "image4_2.png", "description": "The image depicts a section of a financial report interface, likely from a banking or investment platform."},
    {"image_name": "image5_1.png", "description": "The image depicts a detailed table, likely from a financial document or a transaction report."}
]

# Call the function and display the result
result = generate_summary_from_json(json_data)






import json
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.chat_models import AzureChatOpenAI

def generate_summary_from_json(json_data):
    # Step 1: Extract and concatenate descriptions
    descriptions = " ".join([entry["description"] for entry in json_data])

    # Step 2: Configure the Azure OpenAI Chat model
    llm = AzureChatOpenAI(
        temperature=0.5,
        api_version="azure_openai_api_version",  # Replace with your API version
        azure_openai_api_key="YOUR_AZURE_API_KEY",  # Replace with your API key
        azure_openai_base="azure_openai_endpoint",  # Replace with your Azure endpoint
        deployment_name="ssgpt-40"
    )

    # Step 3: Define the prompt template
    prompt_template = (
        "Summarize the following financial document descriptions into a concise summary "
        "highlighting key themes and recurring information:\n\n{descriptions}"
    )

    # Create the prompt template
    prompt = PromptTemplate(
        input_variables=["descriptions"],
        template=prompt_template
    )

    # Step 4: Create the LLM chain
    llm_chain = LLMChain(llm=llm, prompt=prompt)

    try:
        # Step 5: Generate the response using the LLM chain
        response = llm_chain.predict(descriptions=descriptions)

        # If response contains valid JSON, return it; otherwise, return text as is
        return {"Summary": response.strip()}
    
    except Exception as e:
        print(f"Error generating summary: {e}")
        return {"Error": str(e)}

# Sample JSON input
json_data = [
    {"image_name": "image1_1.png", "description": "The document in question appears to be a professional financial statement or bank statement."},
    {"image_name": "image3_1.png", "description": "The image depicts a professional financial document, likely a bank statement, with a structured format."},
    {"image_name": "image3_2.png", "description": "The image depicts a professional financial document, likely a bank statement or account summary."},
    {"image_name": "image4_1.png", "description": "The image depicts a professional document titled 'Global Transactions and Controls.'"},
    {"image_name": "image4_2.png", "description": "The image depicts a section of a financial report interface, likely from a banking or investment platform."},
    {"image_name": "image5_1.png", "description": "The image depicts a detailed table, likely from a financial document or a transaction report."}
]

# Call the function and display the result
result = generate_summary_from_json(json_data)
print(json.dumps(result, indent=4))





import json
import openai

def generate_summary_from_json(json_data, api_key, model="text-davinci-003", max_tokens=150):
    """
    Generate a summary from image descriptions in JSON using an LLM API.

    Args:
    - json_data: List of dictionaries containing 'image_name' and 'description'.
    - api_key: OpenAI API key as a string.
    - model: The LLM model to use (default: 'text-davinci-003').
    - max_tokens: Max tokens for the response (default: 150).

    Returns:
    - A dictionary containing the summary.
    """
    # Step 1: Extract and concatenate all descriptions
    descriptions = " ".join([entry["description"] for entry in json_data])

    # Step 2: Set OpenAI API key
    openai.api_key = api_key

    # Step 3: Define the prompt
    prompt = f"Summarize the following financial document descriptions into a concise summary highlighting key themes and recurring information:\n\n{descriptions}"

    # Step 4: Call the OpenAI GPT model
    response = openai.Completion.create(
        engine=model,
        prompt=prompt,
        max_tokens=max_tokens,
        temperature=0.5
    )

    # Step 5: Extract the summary
    summary = response['choices'][0]['text'].strip()

    # Return the final summary as JSON
    return {
        "Summary": summary
    }

# Sample JSON input
json_data = [
    {"image_name": "image1_1.png", "description": "The document in question appears to be a professional financial statement or bank statement."},
    {"image_name": "image3_1.png", "description": "The image depicts a professional financial document, likely a bank statement, with a structured format."},
    {"image_name": "image3_2.png", "description": "The image depicts a professional financial document, likely a bank statement or account summary."},
    {"image_name": "image4_1.png", "description": "The image depicts a professional document titled 'Global Transactions and Controls.'"},
    {"image_name": "image4_2.png", "description": "The image depicts a section of a financial report interface, likely from a banking or investment platform."},
    {"image_name": "image5_1.png", "description": "The image depicts a detailed table, likely from a financial document or a transaction report."}
]

# Call the function
api_key = 'YOUR_OPENAI_API_KEY'  # Replace with your API key
result = generate_summary_from_json(json_data, api_key)

# Display the result
print(json.dumps(result, indent=4))






import json
import re

def extract_and_reorder(image_text):
    # Custom sorting function to extract and sort by primary and secondary numbers
    def extract_numeric_key(entry):
        # Extract primary and secondary numbers (e.g., "image2_3.png" -> [2, 3])
        match = re.findall(r'\d+', entry['image_name'])
        return [int(num) for num in match] if match else [float('inf')]  # Handle cases where no digits are found

    # Sort based on the extracted numeric keys
    sorted_images = sorted(image_text, key=extract_numeric_key)

    return sorted_images

# Example input
image_text = [
    {"image_name": "image1_1.png", "description": "The document in question appears to be a professional financial statement."},
    {"image_name": "image10_1.png", "description": "The image depicts a software interface, likely a dashboard for managing."},
    {"image_name": "image2_1.png", "description": "The image depicts a financial document, likely a report for review."},
    {"image_name": "image3_2.png", "description": "The image shows a detailed document section, likely for transaction records."},
    {"image_name": "image2_2.png", "description": "The image is a continuation of the financial report, showing structured data."},
    {"image_name": "image1_2.png", "description": "The second section of the financial statement."},
    {"image_name": "image2_3.png", "description": "The image contains a summary table for year-end financial data."},
    {"image_name": "image3_1.png", "description": "The image shows a summary of account activities for the previous quarter."}
]

# Reorder the images
sorted_output = extract_and_reorder(image_text)

# Specify the file location where the JSON will be saved
file_location = "/path/to/your/output/sorted_images.json"

# Save the sorted output to a JSON file
with open(file_location, "w") as outfile:
    json.dump(sorted_output, outfile, indent=4)

print(f"Sorted output saved to: {file_location}")




import json
import re

def extract_and_reorder(image_text):
    # Custom sorting function to extract and sort by primary and secondary numbers
    def extract_numeric_key(entry):
        # Extract primary and secondary numbers (e.g., "image2_3.png" -> [2, 3])
        match = re.findall(r'\d+', entry['image_name'])
        return [int(num) for num in match] if match else [float('inf')]  # Handle cases where no digits are found

    # Sort based on the extracted numeric keys
    sorted_images = sorted(image_text, key=extract_numeric_key)

    # Convert to JSON for output
    return json.dumps(sorted_images, indent=4)

# Example input
image_text = [
    {"image_name": "image1_1.png", "description": "The document in question appears to be a professional financial statement."},
    {"image_name": "image10_1.png", "description": "The image depicts a software interface, likely a dashboard for managing."},
    {"image_name": "image2_1.png", "description": "The image depicts a financial document, likely a report for review."},
    {"image_name": "image3_2.png", "description": "The image shows a detailed document section, likely for transaction records."},
    {"image_name": "image2_2.png", "description": "The image is a continuation of the financial report, showing structured data."},
    {"image_name": "image1_2.png", "description": "The second section of the financial statement."},
    {"image_name": "image2_3.png", "description": "The image contains a summary table for year-end financial data."},
    {"image_name": "image3_1.png", "description": "The image shows a summary of account activities for the previous quarter."}
]

# Get the reordered output
print(extract_and_reorder(image_text))









import json

def extract_and_reorder(image_text):
    # Sort the list to ensure "image1_1.png" appears first
    sorted_images = sorted(image_text, key=lambda x: (x['image_name'] != 'image1_1.png', x['image_name']))

    # Convert to JSON for output
    return json.dumps(sorted_images, indent=4)

# Simulating the result from the function and reordering
print(extract_and_reorder(image_text))








import re
import json

# Input data (cleaned version)
input_data = '''{
"image_name": "image4_2.png",
"description": "The image depicts a section of a financial report interface, likely from a banking or investment document."

"image_name": "image1_1.png",
"description": "The document in question appears to be a professional financial statement or bank statement."

"image_name": "image3_1.png",
"description": "The image depicts a professional financial document, likely a bank statement."

"image_name": "image3_2.png",
"description": "The image depicts a professional financial document, likely a bank statement."

"image_name": "image4_1.png",
"description": "The image depicts a professional document titled 'Global Transactions and Controls.'"
}'''

def extract_and_reorder(input_text):
    # Regular expression to extract image_name and description pairs
    pattern = r'"image_name":\s*"([^"]+)",\s*"description":\s*"([^"]+)"'
    matches = re.findall(pattern, input_text)

    # Sort to place "image1_1.png" first, and maintain the order for others
    matches.sort(key=lambda x: (x[0] != "image1_1.png", x[0]))

    # Building output with no modification to descriptions
    output = [{"image_name": image_name, "description": description.strip()} for image_name, description in matches]
    return json.dumps(output, indent=4)

# Generate the ordered JSON output
print(extract_and_reorder(input_data))









PROCEDURAL PROMPT = """
You are a financial expert with expertise in corporate finance, investment strategies, and accounting.

Generate up to (num_questions) distinct procedural question-answer pairs using the **combined context of text and image descriptions** provided below.

Treat the input as one unified source of information, not as separate components. Ensure no detail is missed from either the text or image description.  

Use the following format:

"question": "What are the steps to achieve or complete this process?",

"answer": [
    "Step 1: [Detailed step referencing relevant text/image data]",
    "Step 2: [Detailed step using text/image data with conditions or decisions]",
    "...",
    "Final step: Ensure outputs meet requirements by checking [text/image details]."
]

**Input Context:**  
- **Text Content:** {paragraph}  
- **Image Description:** {image_content}

Key Instructions:  
1. Incorporate both the text and image content directly into procedural steps.  
2. Reference specific details from columns, tables, or fields mentioned in either input.  
3. If data references are found only in the image (e.g., fund codes, column labels), ensure they are used exactly in the corresponding steps.  
4. Use branching logic when needed (e.g., checks for missing values, special conditions).  
5. Clearly describe how data is retrieved, processed, checked, updated, or escalated.  
6. Avoid any repetition of steps and provide concise procedural instructions.  

Ensure your output adheres to this format with unified text/image references.

Example Output:

"question": "What are the steps to process missing SWIFT codes in a transaction report?",

"answer": [
    "Step 1: Access the transaction report in Tab 'globaluaxl' under the SWIFT_Transactions sheet.",
    "Step 2: Identify missing SWIFT codes using Column A, which lists case IDs requiring validation.",
    "Step 3: Cross-check the case IDs against the provided fund codes listed in {image_content}. If 'CHECK FUND' is displayed, escalate to supervisor.",
    "Final Step: Ensure all updates are reflected in Tab PD under column C before final submission."
]

**Extracted Context:** "{paragraph, image_content}"
"""









Key Instructions:
Do not treat the text and image descriptions as separate inputs. They are to be processed together as a single source of information to ensure no detail is missed.
Ensure that each step clearly describes how to use the combined input, referencing any tables, columns, data points, conditions, or decision-making steps.
If specific details (e.g., columns, SWIFT codes, fund codes, case IDs, or tabs) are provided in either the image or text, they should be included directly in the appropriate steps.
Use branching logic or conditions when necessary (e.g., what to do if a fund code is missing or labeled as 'CHECK FUND').
INPUT FORMAT:
Combined Input: (Provide the combined content from text and images here.)
OUTPUT FORMAT:
json
Copy code
[
    {
        "question": "What are the steps to process unadvised cash items and allocate them correctly?",
        "answer": [
            "Step 1: Identify unadvised cash items using the combined data from the table (refer to the 'Fund Code', 'Case ID', and 'Purchase Amount' columns as described in the input). Copy the identified items into the 'PD' tab.",
            "Step 2: Check the status of the cash items and update comments where necessary. Use data from both text and image descriptions (e.g., transaction details, SWIFT codes, and amounts).",
            "Step 3: Copy all the downloaded data to the 'globaluaxl' tab, covering columns C through T. Include references to transaction-specific columns (e.g., 'Fund Code', 'Case ID', and 'Branch').",
            "Step 4: In the 'globaluaxl' tab, perform a vlookup on column A to identify entries labeled 'CHECK FUND'. Cross-reference this with details from both the image and text input (e.g., 'MT2322000067 SYD', 'AUD', or 'SWIFT codes').",
            "Step 5: For entries labeled 'CHECK FUND', raise an IMT log for the GCO investigation team to allocate the cash to funds or match with non-receipt cash.",
            "Step 6: If a fund code is not identifiable, search for the corresponding SWIFT reference in IBS using combined details (e.g., from the table and additional fields).",
            "Step 7: Send an email to the related team for clarification, providing any missing fund codes or transaction details extracted from the combined input (e.g., 'SWIFT code AU1230804075552', 'Case ID').",
            "Step 8: Request the GCO investigation team to allocate the cash based on further investigation or follow up as needed."
        ]
    }
]
Clarified Instructions:
Treat the text and image content as a single unified input.
Preserve and reference any tables, column names, or transaction details mentioned in either input.
Ensure the final output includes all necessary steps, decisions, and checks while providing clear references to data extracted from the combined source.
Would this approach meet your requirements perfectly?













ChatGPT can make mistakes. 
Key Requirements:
Incorporate both the text and image information into the procedural steps. If specific data, columns, tables, or conditions are mentioned in the image description, they must be directly included in the answer.
Ensure that each step clearly describes how the data is used, any conditions (e.g., vlookup), and branching decisions such as what to do when specific values (e.
CHECK FUND') are encountered.
Preserve data references, column labels (A, C, etc.), tabs, SWIFT codes, fund codes, and case IDs exactly as they appear in the input.
If portals, URLs, or specific tools are mentioned in the process, include them directly in the relevant steps.





Requirements:
Each step should logically follow the process of identifying, copying, checking, updating, and escalating tasks.
Preserve any references to columns (A, B, C, etc.), tabs (PD, globaluaxl), tables, fields, and codes exactly as provided in the input.
If the process involves conditions (e.g., vlookup, identifying missing information), clearly describe the check and the corresponding next step.
If decisions or branching logic exists, include clear instructions on what to do in each case.
Use exact terminology provided in the input, and dont generalize steps unnecessarily.
If any portal, link, or storage location is mentioned, directly include it in the appropriate step.
INPUT FORMAT:
Image Description: {image_content}
Text: {paragraph}
OUTPUT FORMAT:
json
Copy code
[
    {
        "question": "What are the steps to process unadvised cash items and allocate them to funds?",
        "answer": [
            "Step 1: Identify unadvised cash items based on fund codes and copy the data into the 'PD' tab.",
            "Step 2: Check the status of the cash items and update the comments where necessary.",
            "Step 3: Copy all the downloaded data to the 'globaluaxl' tab, covering columns C to T.",
            "Step 4: In the 'globaluaxl' tab, use vlookup to check column A for entries labeled 'CHECK FUND'.",
            "Step 5: For entries where 'CHECK FUND' is identified, raise an IMT log for the GCO investigation team to allocate the cash to funds, if possible, or match with non-receipt cash.",
            "Step 6: If a fund code is not identifiable, search for the corresponding SWIFT reference in IBS, review the additional columns for transaction details, and contact the related team via email for clarification on the fund code.",
            "Step 7: Request the GCO investigation team to allocate the cash after further investigation, if necessary."
        ]
    }
]
Example Breakdown of Table References (Preserve table-like formatting where necessary):
Fund Code Check Example:
Column A: 'CHECK FUND' (Use vlookup to identify)
Relevant transaction data spans from columns C to T, ensure the appropriate checks are made.
Cross-check cases like AU1230804075552 (or similar) using both SWIFT and fund identifiers as indicated in the table.
This version will guarantee table-specific instructions, checks, and decision points are retained without losing any of the context.













ChatGPT can make mistakes. Check important info.









You are a financial expert with expertise in corporate finance, investment strategies, and accounting.

Generate distinct procedural question-answer pairs from the provided input text and image descriptions.

Requirements:
Questions must focus on the process, methods, or logical sequences.
Answers should break down the entire process step-by-step, ensuring each step is complete and does not miss critical details.
Steps should clearly explain tasks like copying data, verifying conditions, or taking decisions, with clear references to any columns, fields, or data points mentioned.
Specific Instructions:
Ensure that any tables, specific data references, or fields mentioned in the input (e.g., column names, codes, identifiers, etc.) are preserved directly in the relevant steps.
If the input includes details about portals, storage, or tools, embed them directly into the steps.
Avoid redundancy or step repetition.
INPUT:
Image Description: {image_content}
Text: {paragraph}
OUTPUT FORMAT:
json
Copy code
[
    {
        "question": "What are the steps to complete this process?",
        "answer": [
            "Step 1: Identify unadvised cash items by referencing fund codes and copying the data into the 'PD' tab.",
            "Step 2: Check the status and update any relevant comments. Copy all downloaded data to the 'globaluaxl' tab, covering columns C through T.",
            "Step 3: In the 'globaluaxl' tab, review column A to identify any instances labeled 'CHECK FUND' via vlookup.",
            "Step 4: Raise an IMT log for the GCO investigation team if identifiable cash can be allocated to specific funds or matched with non-receipt cash.",
            "Step 5: If the fund code is not identifiable, search for the corresponding SWIFT code in IBS, review the additional columns for details about the transaction nature, and notify the relevant team via email.",
            "Step 6: Request the GCO investigation team to allocate the cash based on further investigation if necessary."
        ]
    }
]
By rephrasing the prompt with the above structure, this should meet your expected step-wise breakdown seamlessly.
















Ensure:
Questions focus on processes, methods, or sequences of steps.
Answers provide detailed, step-by-step instructions with clear descriptions for each step, ensuring no step is missed.
Each question and answer must be unique and should not repeat previous questions.
If fewer distinct questions are possible, return only the available ones.
Analyze both the text and images together to generate procedural questions.
Include unrelated procedural questions (e.g., unrelated topics like cooking, weather) if the input contains off-topic content.
Do not generate questions for strikethrough text.
Ensure that when an address, portal, or URL is relevant to a step, it is included directly in that step rather than listed separately.
Input:
json
Copy code
{
    "text": "{paragraph}",
    "image_description_data": "{image_content}",
    "portal": "{portal_name}",
    "url": "{data_access_url}",
    "storage_address": "{storage_location}",
    "database_name": "{database_name}",
    "access_credentials": "{authentication_details}",
    "strikethrough_content": "{strikethrough_text}"
}
Output Format (Valid JSON Array):
json
Copy code
[
    {
        "question": "What are the steps to achieve or complete this process?",
        "answer": [
            "Step 1: Access the data via {portal_name} at {data_access_url}. Ensure you have the correct credentials: {authentication_details}.",
            "Step 2: Retrieve the relevant files stored at {storage_location} within {database_name}.",
            "Step 3: Process the data according to the required methodology."
        ]
    }
]













ChatGPT can make mistakes. Check important








import os
import pandas as pd

def consolidate_excel_files(base_folder, output_file):
    # Create an empty DataFrame to store consolidated data
    consolidated_data = pd.DataFrame()

    # Walk through the base folder and its subfolders
    for root, dirs, files in os.walk(base_folder):
        for file in files:
            if file.endswith('.xlsx') or file.endswith('.xls'):  # Check for Excel files
                file_path = os.path.join(root, file)
                print(f"Processing file: {file_path}")
                try:
                    # Read the Excel file into a DataFrame
                    df = pd.read_excel(file_path)
                    # Add a column to track the file name (optional)
                    df['Source_File'] = file
                    # Append the data to the consolidated DataFrame
                    consolidated_data = pd.concat([consolidated_data, df], ignore_index=True)
                except Exception as e:
                    print(f"Error reading {file_path}: {e}")

    # Save the consolidated data to an output Excel file
    consolidated_data.to_excel(output_file, index=False)
    print(f"Consolidated data saved to {output_file}")

# Specify the base folder and output file path
base_folder = r"path_to_your_folders"  # Replace with the folder containing Excel files
output_file = r"path_to_output_file/consolidated.xlsx"  # Replace with the output file path

# Call the function to consolidate Excel files
consolidate_excel_files(base_folder, output_file)








def generate_questions_by_all_types(paragraph, image_data, total_questions, chunk_size=10):
    """
    Generate questions of all types in parallel.
    """
    # Define question types and their corresponding prompt templates
    question_types_and_prompts = {
        "Factual": "Generate factual questions from the given text.",
        "Procedural": "Generate procedural questions from the given text.",
        "Conceptual": "Generate conceptual questions from the given text.",
        "Inferential": "Generate inferential questions from the given text.",
        "Reasoning-based": "Generate reasoning-based questions from the given text.",
    }

    all_questions = []
    question_counts = {q_type: 0 for q_type in question_types_and_prompts}

    # Ensure paragraph has sufficient content
    if not paragraph or len(paragraph.split()) < total_questions:
        print("Warning: The input paragraph may not have enough content to generate the requested number of questions.")

    # Adjust chunk size dynamically
    chunk_size = min(chunk_size, max(1, total_questions // len(paragraph.split("."))))

    # Helper function to generate questions for a single type
    def generate_questions_for_type(question_type, prompt, questions_to_generate):
        try:
            # Generate questions for the current type
            questions = generate_questions_in_chunks(
                paragraph,
                image_data,
                question_type,
                questions_to_generate,
                prompt,
                chunk_size
            )
            # Remove duplicates
            questions = remove_duplicates(questions)
            print(f"Generated {len(questions)} questions for {question_type}")
            return question_type, questions
        except Exception as e:
            print(f"Error generating questions for {question_type}: {e}")
            return question_type, []

    # Divide the total questions equally among question types
    questions_per_type = max(1, math.ceil(total_questions / len(question_types_and_prompts)))

    remaining_questions = total_questions

    with ThreadPoolExecutor() as executor:
        # Submit tasks to generate questions for each type
        futures = {
            executor.submit(
                generate_questions_for_type,
                question_type,
                prompt,
                questions_per_type
            ): question_type
            for question_type, prompt in question_types_and_prompts.items()
        }

        # Collect results from the executor
        for future in futures:
            try:
                question_type, questions = future.result()
                if not questions:
                    print(f"No questions generated for {question_type}")
                    continue
                all_questions.extend(questions)
                question_counts[question_type] += len(questions)
                remaining_questions -= len(questions)
            except Exception as e:
                print(f"Error processing {futures[future]}: {e}")

    # Log question counts
    for q_type, count in question_counts.items():
        print(f"{q_type} questions: {count}")

    # Warn if the total is less than requested
    if len(all_questions) < total_questions:
        print(f"Warning: Only {len(all_questions)} questions generated out of the requested {total_questions}.")

    # Ensure the total number of questions matches the requested amount
    return all_questions[:total_questions]









def generate_questions_in_chunks(paragraph, image_data, question_type, total_questions, prompt_template, chunk_size=10):
    """
    Generate questions in chunks to avoid exceeding token limits.
    """
    all_questions = []

    for i in range(0, total_questions, chunk_size):
        try:
            # Generate questions for the current chunk
            chunk_questions = generate_questions(paragraph, image_data, question_type, chunk_size, prompt_template)
            
            # Ensure chunk_questions is a valid list
            if not chunk_questions or not isinstance(chunk_questions, list):
                print(f"Warning: No questions generated for {question_type} in chunk {i // chunk_size + 1}")
                continue
            
            # Remove duplicates in the current chunk
            chunk_questions = remove_duplicates(chunk_questions)
            
            # Append unique questions to all_questions
            all_questions.extend(chunk_questions)

        except Exception as e:
            print(f"Error generating chunk for {question_type} (chunk {i // chunk_size + 1}): {e}")
            continue

    # Ensure all_questions is a valid list
    return all_questions if all_questions else []







from concurrent.futures import ThreadPoolExecutor
import math

# Placeholder functions for prompts and processing
FACTUAL_PROMPT = "Factual question generation prompt"
PROCEDURAL_PROMPT = "Procedural question generation prompt"
CONCEPTUAL_PROMPT = "Conceptual question generation prompt"
INFERENTIAL_PROMPT = "Inferential question generation prompt"
REASONING_PROMPT = "Reasoning-based question generation prompt"

def generate_questions_in_chunks(paragraph, image_data, question_type, questions_to_generate, prompt, chunk_size):
    # Mock implementation for generating questions
    print(f"Generating questions for {question_type} with {questions_to_generate} questions.")
    questions = [{"question": f"Sample {question_type} question {i}", "answer": f"Sample {question_type} answer {i}"} for i in range(questions_to_generate)]
    print(f"Generated {len(questions)} questions for {question_type}.")
    return questions if questions else []

def remove_duplicates(questions):
    if not questions:
        return []  # Return an empty list if input is None or empty
    print(f"Removing duplicates from {len(questions)} questions.")
    seen = set()
    unique_questions = []
    for question in questions:
        if question["question"] not in seen:
            unique_questions.append(question)
            seen.add(question["question"])
    print(f"{len(unique_questions)} unique questions remain after deduplication.")
    return unique_questions

def calculate_tokens(text):
    # Mock implementation for token calculation
    return len(text.split())

def generate_questions_by_all_types(paragraph, image_data, total_questions, chunk_size=10):
    # Define question types and corresponding prompts
    question_types_and_prompts = {
        "Factual": FACTUAL_PROMPT,
        "Procedural": PROCEDURAL_PROMPT,
        "Conceptual": CONCEPTUAL_PROMPT,
        "Inferential": INFERENTIAL_PROMPT,
        "Reasoning-based": REASONING_PROMPT,
    }

    # Initialize variables
    all_questions = []
    question_counts = {q_type: 0 for q_type in question_types_and_prompts}

    # Check if inputs are valid
    if not paragraph or not image_data:
        print("Error: Paragraph or image data is empty!")
        return []

    # Helper function for generating questions for a specific type
    def generate_questions_for_type(question_type, prompt, questions_to_generate):
        try:
            questions = generate_questions_in_chunks(
                paragraph,
                image_data,
                question_type,
                questions_to_generate,
                prompt,
                chunk_size
            )
            if questions is None:
                print(f"Error: generate_questions_in_chunks returned None for {question_type}")
                questions = []
            questions = remove_duplicates(questions)
            if questions is None:
                print(f"Error: remove_duplicates returned None for {question_type}")
                questions = []
            print(f"Generated {len(questions)} questions for {question_type}.")
            return question_type, questions
        except Exception as e:
            print(f"Error generating questions for {question_type}: {e}")
            return question_type, []

    # Divide the total questions equally among question types
    questions_per_type = max(1, math.ceil(total_questions / len(question_types_and_prompts)))

    with ThreadPoolExecutor() as executor:
        # Submit tasks to generate questions for each type
        futures = {
            executor.submit(
                generate_questions_for_type,
                question_type,
                prompt,
                questions_per_type
            ): question_type
            for question_type, prompt in question_types_and_prompts.items()
        }

        # Collect results as they are completed
        for future in futures:
            try:
                question_type, questions = future.result()
                if not questions:
                    print(f"No questions generated for {question_type}")
                # Add metadata and append to all_questions
                for qa in questions:
                    question_text = qa["question"]
                    answer_text = qa["answer"]
                    all_questions.append({
                        "Question Type": question_type,
                        "Question": question_text,
                        "Answer": answer_text,
                        "Question Length (Chars)": len(question_text),
                        "Answer Length (Chars)": len(str(answer_text)) if isinstance(answer_text, str) else sum(len(str(a)) for a in answer_text),
                        "Question Tokens": calculate_tokens(question_text),
                        "Answer Tokens": calculate_tokens(answer_text if isinstance(answer_text, str) else "".join(answer_text)),
                    })
                    question_counts[question_type] += 1
            except Exception as e:
                print(f"Error processing {futures[future]}: {e}")

    # Log final question counts
    for q_type, count in question_counts.items():
        print(f"{q_type} questions: {count}")

    # Ensure the final output is exactly total_questions
    return all_questions[:total_questions]

# Example usage
paragraph = "This is a sample paragraph for question generation."
image_data = "Sample image data"  # Replace with actual image data
total_questions = 50
result = generate_questions_by_all_types(paragraph, image_data, total_questions, chunk_size=10)
print("Generated Questions:")
print(result)











from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.chat_models import AzureChatOpenAI
from concurrent.futures import ThreadPoolExecutor, as_completed
import json


# Utility: Extract valid JSON from response
def extract_valid_json(response):
    try:
        return json.loads(response)
    except json.JSONDecodeError as e:
        print(f"Error parsing JSON: {e}")
        return []


# Utility: Remove duplicate questions and answers
def remove_duplicates(questions):
    """
    Remove duplicate questions and answers.
    """
    seen_questions = set()
    seen_answers = set()
    unique_questions = []

    for qa in questions:
        question_text = qa["question"]
        answer_text = str(qa["answer"])  # Convert list-type answers to strings for comparison

        if question_text not in seen_questions and answer_text not in seen_answers:
            seen_questions.add(question_text)
            seen_answers.add(answer_text)
            unique_questions.append(qa)

    return unique_questions


# Utility: Calculate token count for a text
def calculate_tokens(text):
    """
    Placeholder function for token calculation. Update this with your tokenization logic.
    """
    return len(text.split())


# Function: Generate questions in chunks
def generate_questions_in_chunks(paragraph, image_data, question_type, total_questions, prompt_template, chunk_size=10):
    """
    Generate questions in chunks to avoid exceeding token limits.
    """
    all_questions = []

    for start in range(0, total_questions, chunk_size):
        try:
            chunk_questions = generate_questions(
                paragraph=paragraph,
                image_content=image_data,
                question_type=question_type,
                num_questions=min(chunk_size, total_questions - start),
                prompt_template=prompt_template
            )
            all_questions.extend(chunk_questions)
        except Exception as e:
            print(f"Error generating chunk for {question_type}: {e}")
            continue

    return all_questions


# Function: Generate questions using LLM
def generate_questions(paragraph, image_content, question_type, num_questions, prompt_template):
    """
    Generate questions using Azure OpenAI with a structured prompt template.
    """
    # Initialize Azure OpenAI LLM
    llm = AzureChatOpenAI(
        temperature=0,
        api_version="azure_openai_api_version",  # Replace with your Azure OpenAI API version
        azure_endpoint="azure_openai_endpoint",  # Replace with your Azure OpenAI endpoint
        deployment_name="deployment_name"        # Replace with your deployment name
    )

    # Create the prompt template
    prompt = PromptTemplate(
        input_variables=["paragraph", "num_questions", "question_type", "image_content"],
        template=prompt_template
    )

    # Create the LLM chain
    llm_chain = LLMChain(llm=llm, prompt=prompt)

    try:
        # Generate questions using the LLM chain
        response = llm_chain.predict(
            paragraph=paragraph,
            num_questions=str(num_questions),
            question_type=str(question_type),
            image_content=str(image_content)
        )
        # Extract and return valid JSON from the response
        return extract_valid_json(response)
    except Exception as e:
        print(f"Error generating {question_type} questions: {e}")
        return []


# Main Function: Generate questions by all types
def generate_questions_by_all_types(paragraph, image_data, total_questions, chunk_size=10):
    """
    Generate categorized questions and answers for all types, ensuring uniqueness.
    """
    question_types_and_prompts = {
        "Factual": "FACTUAL_PROMPT",
        "Procedural": "PROCEDURAL_PROMPT",
        "Conceptual": "CONCEPTUAL_PROMPT",
        "Inferential": "INFERENTIAL_PROMPT",
        "Reasoning-based": "REASONING_PROMPT",
    }

    all_questions = []

    # Parallel processing for question generation
    def process_question_type(question_type, prompt_template):
        return question_type, generate_questions_in_chunks(
            paragraph, image_data, question_type, total_questions, prompt_template, chunk_size
        )

    with ThreadPoolExecutor() as executor:
        future_to_question_type = {
            executor.submit(process_question_type, question_type, prompt): question_type
            for question_type, prompt in question_types_and_prompts.items()
        }

        for future in as_completed(future_to_question_type):
            question_type, questions = future.result()
            for qa in questions:
                question_text = qa["question"]
                answer_text = qa["answer"]
                all_questions.append({
                    "Question Type": question_type,
                    "Question": question_text,
                    "Answer": answer_text,
                    "Question Length (Chars)": len(question_text),
                    "Answer Length (Chars)": len(str(answer_text)) if isinstance(answer_text, str) else sum(len(str(a)) for a in answer_text),
                    "Question Tokens": calculate_tokens(question_text),
                    "Answer Tokens": calculate_tokens(answer_text if isinstance(answer_text, str) else "".join(answer_text)),
                })

            # Stop early if the desired number of questions is reached
            if len(all_questions) >= total_questions:
                break

    # Remove duplicates and return the top N unique questions
    all_questions = remove_duplicates(all_questions)
    return all_questions[:total_questions]












def generate_questions_in_chunks(paragraph, image_data, question_type, total_questions, prompt_template, chunk_size=10):
    """
    Generate questions in chunks to avoid exceeding token limits.

    Args:
        paragraph (str): Input paragraph for question generation.
        image_data (any): Image data for context (if required).
        question_type (str): Type of question to generate (e.g., "Factual", "Inferential").
        total_questions (int): Total number of questions to generate.
        prompt_template (str): Template or prompt for generating questions.
        chunk_size (int): Number of questions to generate per chunk.

    Returns:
        list: A list of generated questions.
    """
    all_questions = []

    for start in range(0, total_questions, chunk_size):
        try:
            # Generate questions for the current chunk
            chunk_questions = generate_questions(
                paragraph=paragraph,
                image_data=image_data,
                question_type=question_type,
                total_questions=min(chunk_size, total_questions - start),
                prompt_template=prompt_template
            )
            # Add the questions to the overall list
            all_questions.extend(chunk_questions)
        except Exception as e:
            # Handle errors during chunk generation
            print(f"Error generating chunk for {question_type}: {e}")
            continue

    return all_questions






from concurrent.futures import ThreadPoolExecutor
import math

def generate_questions_by_all_types(paragraph, image_data, total_questions, chunk_size=10):
    # Define question types and corresponding prompts
    question_types_and_prompts = {
        "Factual": FACTUAL_PROMPT,
        "Procedural": PROCEDURAL_PROMPT,
        "Conceptual": CONCEPTUAL_PROMPT,
        "Inferential": INFERENTIAL_PROMPT,
        "Reasoning-based": REASONING_PROMPT,
    }

    # Initialize variables
    all_questions = []
    question_counts = {q_type: 0 for q_type in question_types_and_prompts}

    # Define a helper function for parallel processing
    def generate_questions_for_type(question_type, prompt, questions_to_generate):
        questions = generate_questions_in_chunks(
            paragraph,
            image_data,
            question_type,
            questions_to_generate,
            prompt,
            chunk_size
        )
        if questions is None:
            print(f"Error: generate_questions_in_chunks returned None for {question_type}")
            questions = []
        questions = remove_duplicates(questions)
        if questions is None:
            print(f"Error: remove_duplicates returned None for {question_type}")
            questions = []
        return question_type, questions

    # Divide the total questions equally among question types
    questions_per_type = max(1, math.ceil(total_questions / len(question_types_and_prompts)))

    with ThreadPoolExecutor() as executor:
        # Submit tasks to generate questions for each type in parallel
        futures = {
            executor.submit(
                generate_questions_for_type,
                question_type,
                prompt,
                questions_per_type
            ): question_type
            for question_type, prompt in question_types_and_prompts.items()
        }

        # Collect results as they are completed
        for future in futures:
            try:
                question_type, questions = future.result()
                if not questions:
                    print(f"No questions generated for {question_type}")
                # Add metadata and append to all_questions
                for qa in questions:
                    question_text = qa["question"]
                    answer_text = qa["answer"]
                    all_questions.append({
                        "Question Type": question_type,
                        "Question": question_text,
                        "Answer": answer_text,
                        "Question Length (Chars)": len(question_text),
                        "Answer Length (Chars)": len(str(answer_text)) if isinstance(answer_text, str) else sum(len(str(a)) for a in answer_text),
                        "Question Tokens": calculate_tokens(question_text),
                        "Answer Tokens": calculate_tokens(answer_text if isinstance(answer_text, str) else "".join(answer_text)),
                    })
                    # Update counters
                    question_counts[question_type] += 1
            except Exception as e:
                print(f"Error processing {futures[future]}: {e}")

    # Log final question counts per type
    for q_type, count in question_counts.items():
        print(f"{q_type} questions: {count}")

    # Ensure the final output is exactly total_questions
    return all_questions[:total_questions]









from concurrent.futures import ThreadPoolExecutor, as_completed

def generate_questions_in_chunks(paragraph, image_data, question_type, total_questions, prompt, chunk_size):
    # Placeholder for your existing function that generates questions in chunks
    pass

def remove_duplicates(questions):
    # Placeholder for your duplicate removal logic
    return list({q['question']: q for q in questions}.values())

def calculate_tokens(text):
    # Placeholder for your token calculation logic
    return len(text.split())

def generate_questions_by_all_types(paragraph, image_data, total_questions, chunk_size=10):
    question_types_and_prompts = {
        "Factual": "FACTUAL_PROMPT",
        "Procedural": "PROCEDURAL_PROMPT",
        "Conceptual": "CONCEPTUAL_PROMPT",
        "Inferential": "INFERENTIAL_PROMPT",
        "Reasoning-based": "REASONING_PROMPT",
    }

    all_questions = []

    def process_question_type(question_type, prompt):
        questions = generate_questions_in_chunks(paragraph, image_data, question_type, total_questions, prompt, chunk_size)
        return question_type, questions

    with ThreadPoolExecutor() as executor:
        future_to_question_type = {
            executor.submit(process_question_type, question_type, prompt): question_type
            for question_type, prompt in question_types_and_prompts.items()
        }

        for future in as_completed(future_to_question_type):
            question_type, questions = future.result()
            for qa in questions:
                question_text = qa["question"]
                answer_text = qa["answer"]
                all_questions.append({
                    "Question Type": question_type,
                    "Question": question_text,
                    "Answer": answer_text,
                    "Question Length (Chars)": len(question_text),
                    "Answer Length (Chars)": len(str(answer_text)) if isinstance(answer_text, str) else sum(len(str(a)) for a in answer_text),
                    "Question Tokens": calculate_tokens(question_text),
                    "Answer Tokens": calculate_tokens(answer_text if isinstance(answer_text, str) else "".join(answer_text)),
                })
            
            # Break if the desired number of questions is reached
            if len(all_questions) >= total_questions:
                break

    # Remove duplicates and return the top N questions
    all_questions = remove_duplicates(all_questions)
    return all_questions[:total_questions]








from concurrent.futures import ThreadPoolExecutor
import math

def generate_questions_by_all_types(paragraph, image_data, total_questions, chunk_size=10):
    # Define question types and corresponding prompts
    question_types_and_prompts = {
        "Factual": FACTUAL_PROMPT,
        "Procedural": PROCEDURAL_PROMPT,
        "Conceptual": CONCEPTUAL_PROMPT,
        "Inferential": INFERENTIAL_PROMPT,
        "Reasoning-based": REASONING_PROMPT,
    }

    # Initialize variables
    all_questions = []
    question_counts = {q_type: 0 for q_type in question_types_and_prompts}  # Track questions per type

    # Define a helper function for parallel processing
    def generate_questions_for_type(question_type, prompt, questions_to_generate):
        questions = generate_questions_in_chunks(
            paragraph,
            image_data,
            question_type,
            questions_to_generate,
            prompt,
            chunk_size
        )
        questions = remove_duplicates(questions)
        print(f"{question_type} questions generated: {len(questions)}")  # Debug log
        return question_type, questions

    # Divide the total questions equally among question types
    questions_per_type = math.ceil(total_questions / len(question_types_and_prompts))

    with ThreadPoolExecutor() as executor:
        # Submit tasks to generate questions for each type in parallel
        futures = {
            executor.submit(
                generate_questions_for_type,
                question_type,
                prompt,
                questions_per_type
            ): question_type
            for question_type, prompt in question_types_and_prompts.items()
        }

        # Collect results as they are completed
        for future in futures:
            question_type, questions = future.result()
            # Add metadata and append to all_questions
            for qa in questions:
                question_text = qa["question"]
                answer_text = qa["answer"]
                all_questions.append({
                    "Question Type": question_type,
                    "Question": question_text,
                    "Answer": answer_text,
                    "Question Length (Chars)": len(question_text),
                    "Answer Length (Chars)": len(str(answer_text)) if isinstance(answer_text, str) else sum(len(str(a)) for a in answer_text),
                    "Question Tokens": calculate_tokens(question_text),
                    "Answer Tokens": calculate_tokens(answer_text if isinstance(answer_text, str) else "".join(answer_text)),
                })
                # Update counters
                question_counts[question_type] += 1

    # Log final question counts per type
    for q_type, count in question_counts.items():
        print(f"{q_type} questions: {count}")

    # Ensure the final output is exactly total_questions
    return all_questions[:total_questions]









import os
import fitz
import base64
import json
from concurrent.futures import ThreadPoolExecutor, as_completed

# Function to describe an image
def img_description(image_data):
    message = [
        {
            "type": "text",
            "text": "Describe an image in detail, including its overall structure, such as headers, footers, and sections, along with the placement of the logo, name, address, and contact information. Include background features like watermarks, barcodes, or security marks. Focus on tables within the document that display account details, transaction records, dates, descriptions, debit/credit amounts, and balances, specifying the number of rows and columns, headers, borders, alignment, and any highlights like bold totals or shaded cells. Mention account details such as the account holder's name, account number, branch name, and IFSC code, along with details about account types or interest rates. Provide information on transaction lists or tables, including details like dates, descriptions, transaction types (credit/debit), amounts, and balances, highlighting any significant entries. Include additional elements like handwritten notes, signatures (manual or digital), stamps, or seals for authentication, as well as reference numbers, document IDs, or case numbers for tracking. Describe the formatting, including font styles, alignment, and the use of bold or italicized text for emphasis. Mention any legal or formal information, such as disclaimers, terms, and conditions, or privacy policies, often found at the bottom of the document, and note the use of formal language and financial terminology. Finally, describe the professional appearance of the document, including the use of colors (e.g., black-and-white or highlights) and whether it appears printed or scanned."
        },
        {
            "type": "image_url",
            "image_url": {"url": f"data:image/jpeg;base64,{image_data}"},
        },
    ]
    response = "AzureChatOpenAI"  # Placeholder for Azure OpenAI function call
    return response  # Replace with actual function call logic

# Function to save JSON data
def save_json(output_dir, image_descriptions):
    json_file_path = os.path.join(output_dir, "image_data_isvc.json")
    with open(json_file_path, "w") as json_file:
        json.dump(image_descriptions, json_file, indent=4)

# Function to process a single image
def process_image(pdf_file, page_index, image_index, img, output_dir):
    xref = img[0]
    base_image = pdf_file.extract_image(xref)
    image_bytes = base_image["image"]
    image_ext = base_image["ext"]

    # Save the image to the outputs folder
    image_name = f"image{page_index+1}_{image_index}.{image_ext}"
    image_path = os.path.join(output_dir, image_name)
    with open(image_path, "wb") as image_file:
        image_file.write(image_bytes)

    # Convert the image to Base64
    image_data = base64.b64encode(image_bytes).decode("utf-8")

    # Get image description
    description = img_description(image_data)

    return {"image_name": image_name, "description": description}

# Main function for processing PDF
def extract_text_from_pdf_images(file, output_dir="outputs_sop"):
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    pdf_file = fitz.open(file)
    image_descriptions = []

    # Using ThreadPoolExecutor for parallel processing
    with ThreadPoolExecutor() as executor:
        futures = []

        for page_index in range(len(pdf_file)):
            page = pdf_file.load_page(page_index)
            image_list = page.get_images(full=True)

            if image_list:
                print(f"[+] Found a total of {len(image_list)} images on page {page_index}")
                for image_index, img in enumerate(image_list, start=1):
                    futures.append(executor.submit(process_image, pdf_file, page_index, image_index, img, output_dir))
            else:
                print(f"[1] No images found on page {page_index}")

        # Collect results from parallel tasks
        for future in as_completed(futures):
            image_descriptions.append(future.result())

    save_json(output_dir, image_descriptions)
    return image_descriptions

# Usage
file = r"h:\Question and answer\Fund accounting\(Resubmit_1025)36. VFMC AAS25 SOP 5.0.pdf"
image_text = extract_text_from_pdf_images(file)
print(image_text)











import tiktoken

def calculate_tokens(text, model="gpt-3.5-turbo"):
    """
    Calculate the number of tokens in a given text using tiktoken.

    Args:
        text (str): Input text.
        model (str): Model name to determine the encoding (default: "gpt-3.5-turbo").

    Returns:
        int: Number of tokens in the text.
    """
    try:
        # Choose encoding based on the model
        if model in ["gpt-3.5-turbo", "gpt-4"]:
            encoding = tiktoken.encoding_for_model("gpt-3.5-turbo")  # This will use cl100k_base
        elif model == "text-davinci-003":
            encoding = tiktoken.get_encoding("p50k_base")
        elif model == "text-davinci-002":
            encoding = tiktoken.get_encoding("r50k_base")
        else:
            raise ValueError(f"Unsupported model: {model}")

        # Calculate token count
        return len(encoding.encode(text))
    
    except Exception as e:
        print(f"Error calculating tokens: {e}")
        return None

# Example usage
t = calculate_tokens("hi", model="gpt-3.5-turbo")
print(t)








import tiktoken

def calculate_tokens(text, model="gpt-3.5-turbo", encoding_path=None):
    """
    Calculate the number of tokens in a given text using tiktoken.

    Args:
        text (str): Input text.
        model (str): Model name to determine the encoding (default: "gpt-3.5-turbo").
        encoding_path (str): Optional path to a manually downloaded encoding file.

    Returns:
        int: Number of tokens in the text.
    """
    try:
        # Load encoding from a manually downloaded file if specified
        if encoding_path:
            with open(encoding_path, "r") as f:
                encoding = tiktoken.load(f.read())
        else:
            # Use predefined encodings based on the model
            if model in ["gpt-3.5-turbo", "gpt-4"]:
                encoding = tiktoken.get_encoding("cl100k_base")
            elif model == "text-davinci-003":
                encoding = tiktoken.get_encoding("p50k_base")
            elif model == "text-davinci-002":
                encoding = tiktoken.get_encoding("r50k_base")
            else:
                raise ValueError(f"Unsupported model: {model}")
        
        # Calculate token count
        return len(encoding.encode(text))
    
    except Exception as e:
        print(f"Error calculating tokens: {e}")
        return None

# Example usage with a manually downloaded encoding file
manual_path = r"c:\Users\P872643\Downloads\cl100k_base.tiktoken"  # Update this path as needed
t = calculate_tokens("hi", encoding_path=manual_path)
print(t)






This project focuses on automating the analysis of financial and legal documents by leveraging Azure and AI technologies. It securely retrieves documents from Azure Blob Storage, organizes and structures their content, and uses Azure Document Intelligence to parse key elements. Regex filtering and Azure OpenAI models are employed to extract, refine, and interpret critical information like management fees and key terms. The workflow ensures accurate, context-specific insights and simplified interpretations for informed decision-making. By combining secure access, advanced AI, and structured processing, the system delivers a comprehensive and efficient document analysis solution.





You said:
project name
ChatGPT said:
ChatGPT
IntelliDoc Analyzer





You said:
give me a cutting edge like
ChatGPT said:
ChatGPT
NeuralEdge Document Intelligence
















def extract_text_from_pdf_images(file, output_dir="outputs_sop"):
    # Ensure the outputs directory exists
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # Function to process a single page
    def process_page(page_index):
        page = pdf_file.load_page(page_index)  # Load the page
        image_list = page.get_images(full=True)  # Get images on the page
        
        # Check if images are found
        if not image_list:
            print(f"[!] No images found on page {page_index}")
            return {"page_index": page_index, "descriptions": []}

        print(f"[+] Found a total of {len(image_list)} images on page {page_index}")
        page_descriptions = []

        for image_index, img in enumerate(image_list, start=1):
            # Get the XREF of the image
            xref = img[0]
            
            # Extract the image bytes
            base_image = pdf_file.extract_image(xref)
            image_bytes = base_image["image"]
            image_ext = base_image["ext"]  # Get the image extension
            
            # Save the image to the outputs folder
            image_name = f"image_{page_index + 1}_{image_index}.{image_ext}"
            image_path = os.path.join(output_dir, image_name)
            with open(image_path, "wb") as image_file:
                image_file.write(image_bytes)
            print(f"[+] Image saved as {image_path}")
            
            # Convert the image to Base64
            image_data = base64.b64encode(image_bytes).decode("utf-8")
            
            # Append image description
            page_descriptions.append({
                "image_name": image_name,
                "description": img_description(image_data)
            })
        
        return {"page_index": page_index, "descriptions": page_descriptions}

    # Function to describe the image
    def img_description(image_data):
        # Simulated description (replace with actual API call if needed)
        return f"Simulated description for image data: {image_data[:30]}..."

    # Save JSON data
    def save_json(output_dir, image_descriptions):
        json_file_path = os.path.join(output_dir, "image_data_isvc.json")
        with open(json_file_path, "w") as json_file:
            json.dump(image_descriptions, json_file, indent=4)

    # Open the PDF file
    pdf_file = fitz.open(file)
    image_descriptions = []

    # Process pages in parallel
    with ThreadPoolExecutor() as executor:
        results = list(executor.map(process_page, range(len(pdf_file))))

    # Sort results by page index to maintain sequence
    results.sort(key=lambda x: x["page_index"])

    # Collect sorted descriptions
    for result in results:
        image_descriptions.extend(result["descriptions"])

    # Save the combined descriptions to JSON
    save_json(output_dir, image_descriptions)
    return image_descriptions

# Usage example
# file = r"h:\Question and answer\Fund accounting (Resubmit_1025)36. VFMC AAS25 SOP 5.0.pdf"
# image_text = extract_text_from_pdf_images(file)













import os
import fitz  # PyMuPDF
import base64
import json
from concurrent.futures import ThreadPoolExecutor

def extract_text_from_pdf_images(file, output_dir="outputs_sop"):
    # Ensure the outputs directory exists
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # Function to process a single page
    def process_page(page_index):
        page = pdf_file.load_page(page_index)  # Load the page
        image_list = page.get_images(full=True)  # Get images on the page
        
        # Check if images are found
        if not image_list:
            print("[!] No images found on page", page_index)
            return []

        print(f"[+] Found a total of {len(image_list)} images on page {page_index}")
        page_descriptions = []

        for image_index, img in enumerate(image_list, start=1):
            # Get the XREF of the image
            xref = img[0]
            
            # Extract the image bytes
            base_image = pdf_file.extract_image(xref)
            image_bytes = base_image["image"]
            image_ext = base_image["ext"]  # Get the image extension
            
            # Save the image to the outputs folder
            image_name = f"image_{page_index + 1}_{image_index}.{image_ext}"
            image_path = os.path.join(output_dir, image_name)
            with open(image_path, "wb") as image_file:
                image_file.write(image_bytes)
            print(f"[+] Image saved as {image_path}")
            
            # Convert the image to Base64
            image_data = base64.b64encode(image_bytes).decode("utf-8")
            
            # Append image description
            page_descriptions.append({
                "image_name": image_name,
                "description": img_description(image_data)
            })
        
        return page_descriptions

    # Function to describe the image
    def img_description(image_data):
        message = {
            "type": "text",
            "text": "Describe an image in detail, including its overall structure, such as headers, footers, and sections, along with authentication, as well as reference numbers, document IDs, or case numbers for tracking. Describe the formatting, including font styles, alignment, etc."
        }
        response = {
            "type": "image_url",
            "image_url": f"data:image/jpeg;base64,{image_data}"
        }
        # Simulated response (replace with actual API call if needed)
        return f"Simulated description for image data: {image_data[:30]}..."

    # Save JSON data
    def save_json(output_dir, image_descriptions):
        json_file_path = os.path.join(output_dir, "image_data_isvc.json")
        with open(json_file_path, "w") as json_file:
            json.dump(image_descriptions, json_file, indent=4)

    # Open the PDF file
    pdf_file = fitz.open(file)
    image_descriptions = []

    # Process pages in parallel
    with ThreadPoolExecutor() as executor:
        results = executor.map(process_page, range(len(pdf_file)))

    # Collect results
    for page_descriptions in results:
        if page_descriptions:
            image_descriptions.extend(page_descriptions)

    # Save the combined descriptions to JSON
    save_json(output_dir, image_descriptions)
    return image_descriptions

# Usage example
# file = r"h:\Question and answer\Fund accounting (Resubmit_1025)36. VFMC AAS25 SOP 5.0.pdf"
# image_text = extract_text_from_pdf_images(file)











import os
import fitz  # PyMuPDF
import base64
import json
from concurrent.futures import ThreadPoolExecutor

# Ensure the output directory exists
def ensure_output_dir(output_dir):
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

# Generate a description for an image
def img_description(image_data, api_endpoint, api_key):
    """Describe an image using the Azure ChatGPT model."""
    import requests

    # API request payload
    message = {
        "messages": [
            {
                "role": "user",
                "content": f"Describe this image in detail: data:image/jpeg;base64,{image_data}"
            }
        ],
        "temperature": 0.5,
    }

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}",
    }

    response = requests.post(api_endpoint, json=message, headers=headers)

    if response.status_code == 200:
        return response.json()["choices"][0]["message"]["content"]
    else:
        raise Exception(f"API Request Failed: {response.status_code}, {response.text}")

# Save the JSON file
def save_json(output_dir, image_descriptions):
    json_file_path = os.path.join(output_dir, "image_data.json")
    with open(json_file_path, "w") as json_file:
        json.dump(image_descriptions, json_file, indent=4)

# Process a single image
def process_image(image, page_index, image_index, pdf_file, output_dir, api_endpoint, api_key):
    xref = image[0]
    base_image = pdf_file.extract_image(xref)
    image_bytes = base_image["image"]
    image_ext = base_image["ext"]

    # Save the image locally
    image_name = f"image{page_index+1}_{image_index}.{image_ext}"
    image_path = os.path.join(output_dir, image_name)

    with open(image_path, "wb") as image_file:
        image_file.write(image_bytes)

    # Convert to Base64
    image_data = base64.b64encode(image_bytes).decode("utf-8")
    
    # Get the description
    description = img_description(image_data, api_endpoint, api_key)

    return {"image_name": image_name, "description": description}

# Extract text from PDF images
def extract_text_from_pdf_images(file, output_dir="outputs_sop", api_endpoint="", api_key=""):
    ensure_output_dir(output_dir)

    pdf_file = fitz.open(file)
    image_descriptions = []

    def process_page(page_index):
        page = pdf_file.load_page(page_index)
        image_list = page.get_images(full=True)

        if not image_list:
            return []

        results = []
        for image_index, img in enumerate(image_list, start=1):
            result = process_image(img, page_index, image_index, pdf_file, output_dir, api_endpoint, api_key)
            results.append(result)
        return results

    # Use threading for parallel processing
    with ThreadPoolExecutor() as executor:
        all_results = executor.map(process_page, range(len(pdf_file)))

    # Flatten the results
    for page_results in all_results:
        image_descriptions.extend(page_results)

    # Save to JSON
    save_json(output_dir, image_descriptions)

    return image_descriptions

# Usage Example
file = r"path_to_pdf.pdf"
api_endpoint = "https://your_azure_openai_endpoint/v1/chat/completions"
api_key = "your_api_key"

try:
    image_text = extract_text_from_pdf_images(file, output_dir="outputs_sop", api_endpoint=api_endpoint, api_key=api_key)
    print(image_text)
except Exception as e:
    print(f"Error: {e}")










import os
import fitz  # PyMuPDF
import base64
import json
from concurrent.futures import ThreadPoolExecutor

def ensure_output_dir(output_dir):
    """Ensure the outputs directory exists."""
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

def img_description(image_data):
    """Mockup for describing an image in detail."""
    # Replace this with actual logic if necessary (e.g., using an AI model).
    return f"Description of image with data size: {len(image_data)} bytes"

def save_json(output_dir, image_descriptions):
    """Save image descriptions to a JSON file."""
    json_file_path = os.path.join(output_dir, "image_data.json")
    with open(json_file_path, "w") as json_file:
        json.dump(image_descriptions, json_file, indent=4)

def process_image(image, page_index, image_index, pdf_file, output_dir):
    """Process a single image: save and describe it."""
    xref = image[0]
    base_image = pdf_file.extract_image(xref)
    image_bytes = base_image["image"]
    image_ext = base_image["ext"]

    image_name = f"image{page_index+1}_{image_index}.{image_ext}"
    image_path = os.path.join(output_dir, image_name)

    # Save the image
    with open(image_path, "wb") as image_file:
        image_file.write(image_bytes)

    # Convert to Base64
    image_data = base64.b64encode(image_bytes).decode("utf-8")
    description = img_description(image_data)

    return {"image_name": image_name, "description": description}

def extract_text_from_pdf_images(file, output_dir="outputs_sop"):
    """Extract text and descriptions from PDF images."""
    ensure_output_dir(output_dir)

    pdf_file = fitz.open(file)
    image_descriptions = []

    def process_page(page_index):
        """Process all images on a single page."""
        page = pdf_file.load_page(page_index)
        image_list = page.get_images(full=True)

        if not image_list:
            return []

        results = []
        for image_index, img in enumerate(image_list, start=1):
            result = process_image(img, page_index, image_index, pdf_file, output_dir)
            results.append(result)
        return results

    # Use threading for processing pages in parallel
    with ThreadPoolExecutor() as executor:
        all_results = executor.map(process_page, range(len(pdf_file)))

    # Flatten results from all pages
    for page_results in all_results:
        image_descriptions.extend(page_results)

    # Save descriptions to JSON
    save_json(output_dir, image_descriptions)

    return image_descriptions

# Usage
# file = r"path/to/your/document.pdf"
# image_text = extract_text_from_pdf_images(file)










from concurrent.futures import ThreadPoolExecutor
import math

def generate_questions_by_all_types(paragraph, image_data, total_questions, chunk_size=10):
    # Define question types and corresponding prompts
    question_types_and_prompts = {
        "Factual": FACTUAL_PROMPT,
        "Procedural": PROCEDURAL_PROMPT,
        "Conceptual": CONCEPTUAL_PROMPT,
        "Inferential": INFERENTIAL_PROMPT,
        "Reasoning-based": REASONING_PROMPT,
    }

    # Initialize variables
    all_questions = []
    question_counts = {q_type: 0 for q_type in question_types_and_prompts}  # Track questions per type

    # Define a helper function for parallel processing
    def generate_questions_for_type(question_type, prompt, questions_to_generate):
        questions = generate_questions_in_chunks(
            paragraph,
            image_data,
            question_type,
            questions_to_generate,
            prompt,
            chunk_size
        )
        questions = remove_duplicates(questions)
        return question_type, questions

    # Divide the total questions equally among question types
    questions_per_type = math.ceil(total_questions / len(question_types_and_prompts))

    with ThreadPoolExecutor() as executor:
        # Submit tasks to generate questions for each type in parallel
        futures = {
            executor.submit(
                generate_questions_for_type, 
                question_type, 
                prompt, 
                questions_per_type
            ): question_type
            for question_type, prompt in question_types_and_prompts.items()
        }

        # Collect results as they are completed
        for future in futures:
            question_type, questions = future.result()

            # Add metadata and append to all_questions
            for qa in questions:
                question_text = qa["question"]
                answer_text = qa["answer"]
                all_questions.append({
                    "Question Type": question_type,
                    "Question": question_text,
                    "Answer": answer_text,
                    "Question Length (Chars)": len(question_text),
                    "Answer Length (Chars)": len(str(answer_text)) if isinstance(answer_text, str) else sum(len(str(a)) for a in answer_text),
                    "Question Tokens": calculate_tokens(question_text),
                    "Answer Tokens": calculate_tokens(answer_text if isinstance(answer_text, str) else "".join(answer_text))
                })

            # Update counters
            question_counts[question_type] += len(questions)

    # Ensure the final output is exactly `total_questions`
    return all_questions[:total_questions]











import multiprocessing as mp


def generate_questions_for_type(paragraph, image_data, question_type, num_questions, prompt):
    """
    Generates questions for a single question type.
    """
    questions = generate_questions_in_chunks(
        paragraph,
        image_data,
        question_type,
        num_questions,
        prompt,
        chunk_size=10  # Customize chunk size if necessary
    )
    return remove_duplicates(questions)


def worker_task(args):
    """
    Worker task for multiprocessing. Accepts arguments as a tuple.
    """
    paragraph, image_data, question_type, num_questions, prompt = args
    try:
        questions = generate_questions_for_type(paragraph, image_data, question_type, num_questions, prompt)
        return {
            "question_type": question_type,
            "questions": questions
        }
    except Exception as e:
        print(f"Error processing {question_type}: {e}")
        return {
            "question_type": question_type,
            "questions": []
        }


def generate_questions_by_all_types_multiprocessing(paragraph, image_data, total_questions):
    """
    Generates questions of all types using multiprocessing.
    """
    # Define question types and corresponding prompts
    question_types_and_prompts = {
        "Factual": FACTUAL_PROMPT,
        "Procedural": PROCEDURAL_PROMPT,
        "Conceptual": CONCEPTUAL_PROMPT,
        "Inferential": INFERENTIAL_PROMPT,
        "Reasoning-based": REASONING_PROMPT,
    }

    # Divide total questions among question types
    num_types = len(question_types_and_prompts)
    questions_per_type = total_questions // num_types
    remaining_questions = total_questions % num_types

    # Prepare arguments for each process
    tasks = [
        (
            paragraph,
            image_data,
            question_type,
            questions_per_type + (1 if i < remaining_questions else 0),  # Distribute leftovers
            prompt
        )
        for i, (question_type, prompt) in enumerate(question_types_and_prompts.items())
    ]

    # Use multiprocessing Pool to parallelize tasks
    with mp.Pool(processes=mp.cpu_count()) as pool:
        results = pool.map(worker_task, tasks)

    # Combine results from all processes
    all_questions = []
    for result in results:
        question_type = result["question_type"]
        for qa in result["questions"]:
            all_questions.append({
                "Question Type": question_type,
                "Question": qa["question"],
                "Answer": qa["answer"],
                "Question Length (Chars)": len(qa["question"]),
                "Answer Length (Chars)": len(str(qa["answer"])) if isinstance(qa["answer"], str) else sum(len(str(a)) for a in qa["answer"]),
                "Question Tokens": calculate_tokens(qa["question"]),
                "Answer Tokens": calculate_tokens(qa["answer"] if isinstance(qa["answer"], str) else "".join(qa["answer"]))
            })

    # Return the top N unique questions
    return all_questions[:total_questions]










from concurrent.futures import ThreadPoolExecutor, as_completed

def generate_questions_by_type(paragraph, image_data, question_type, prompt, chunk_size, token_limit):
    """
    Generate questions for a specific type with token limit handling.
    """
    questions = []
    total_tokens_used = 0
    while True:
        # Generate questions in chunks
        chunk_questions = generate_questions_in_chunks(
            paragraph, image_data, question_type, chunk_size, prompt, chunk_size
        )
        
        # Break if no more questions are generated
        if not chunk_questions:
            break

        # Calculate tokens for generated questions
        for qa in chunk_questions:
            question_text = qa["question"]
            answer_text = qa["answer"]
            question_tokens = calculate_tokens(question_text)
            answer_tokens = calculate_tokens(answer_text if isinstance(answer_text, str) else "".join(answer_text))
            total_tokens = question_tokens + answer_tokens

            # Stop processing if token limit is reached
            if total_tokens_used + total_tokens > token_limit:
                return questions  # Return all questions generated so far

            # Append the question and update token usage
            questions.append({
                "Question Type": question_type,
                "Question": question_text,
                "Answer": answer_text,
                "Question Length (Chars)": len(question_text),
                "Answer Length (Chars)": len(str(answer_text)) if isinstance(answer_text, str) else sum(len(str(a)) for a in answer_text),
                "Question Tokens": question_tokens,
                "Answer Tokens": answer_tokens
            })
            total_tokens_used += total_tokens

    return questions


def generate_questions_parallel(paragraph, image_data, total_questions, chunk_size, token_limit):
    """
    Generate questions across all types in parallel while respecting token limits.
    """
    # Define question types and corresponding prompts
    question_types_and_prompts = {
        "Factual": FACTUAL_PROMPT,
        "Procedural": PROCEDURAL_PROMPT,
        "Conceptual": CONCEPTUAL_PROMPT,
        "Inferential": INFERENTIAL_PROMPT,
        "Reasoning-based": REASONING_PROMPT,
    }

    # Use ThreadPoolExecutor for parallel processing
    all_questions = []
    with ThreadPoolExecutor() as executor:
        # Submit tasks for parallel processing
        futures = {
            executor.submit(
                generate_questions_by_type,
                paragraph,
                image_data,
                question_type,
                prompt,
                chunk_size,
                token_limit
            ): question_type
            for question_type, prompt in question_types_and_prompts.items()
        }

        # Collect results as they complete
        for future in as_completed(futures):
            try:
                questions = future.result()  # Get questions from completed thread
                all_questions.extend(questions)  # Append results to all_questions
                if len(all_questions) >= total_questions:
                    break  # Stop if total question limit is reached
            except Exception as e:
                print(f"Error generating {futures[future]} questions: {e}")

    # Ensure the final output is exactly `total_questions`
    return all_questions[:total_questions]












from concurrent.futures import ThreadPoolExecutor, as_completed

def generate_questions_for_type(paragraph, image_data, question_type, prompt, remaining_questions, chunk_size):
    """
    Generate questions for a specific question type.
    """
    questions = generate_questions_in_chunks(
        paragraph,
        image_data,
        question_type,
        remaining_questions,
        prompt,
        chunk_size
    )
    return {
        "question_type": question_type,
        "questions": remove_duplicates(questions)
    }

def generate_questions_parallel(paragraph, image_data, total_questions, chunk_size=10):
    # Define question types and corresponding prompts
    question_types_and_prompts = {
        "Factual": FACTUAL_PROMPT,
        "Procedural": PROCEDURAL_PROMPT,
        "Conceptual": CONCEPTUAL_PROMPT,
        "Inferential": INFERENTIAL_PROMPT,
        "Reasoning-based": REASONING_PROMPT,
    }

    # Remaining questions to generate
    remaining_questions = total_questions
    all_questions = []

    # Use ThreadPoolExecutor for parallel processing
    with ThreadPoolExecutor(max_workers=len(question_types_and_prompts)) as executor:
        futures = []
        for question_type, prompt in question_types_and_prompts.items():
            futures.append(executor.submit(
                generate_questions_for_type,
                paragraph,
                image_data,
                question_type,
                prompt,
                remaining_questions,
                chunk_size
            ))

        # Collect results as they complete
        for future in as_completed(futures):
            result = future.result()
            question_type = result["question_type"]
            questions = result["questions"]

            # Add questions to the main list
            for qa in questions:
                question_text = qa["question"]
                answer_text = qa["answer"]
                all_questions.append({
                    "Question Type": question_type,
                    "Question": question_text,
                    "Answer": answer_text,
                    "Question Length (Chars)": len(question_text),
                    "Answer Length (Chars)": len(str(answer_text)) if isinstance(answer_text, str) else sum(len(str(a)) for a in answer_text),
                    "Question Tokens": calculate_tokens(question_text),
                    "Answer Tokens": calculate_tokens(answer_text if isinstance(answer_text, str) else "".join(answer_text))
                })

            # Update remaining questions
            remaining_questions -= len(questions)

    # Return the top N unique questions
    return all_questions[:total_questions]











def generate_questions_by_all_types(paragraph, image_data, total_questions, chunk_size=10):
    # Define question types and corresponding prompts
    question_types_and_prompts = {
        "Factual": FACTUAL_PROMPT,
        "Procedural": PROCEDURAL_PROMPT,
        "Conceptual": CONCEPTUAL_PROMPT,
        "Inferential": INFERENTIAL_PROMPT,
        "Reasoning-based": REASONING_PROMPT,
    }

    # Initialize variables
    all_questions = []
    types_covered = set()  # Track covered types
    remaining_questions = total_questions  # Track remaining questions to generate

    # Iterate over question types in a loop until all are covered
    while remaining_questions > 0 and len(types_covered) < len(question_types_and_prompts):
        for question_type, prompt in question_types_and_prompts.items():
            if question_type in types_covered:
                continue  # Skip already fully covered types
            
            # Generate questions for the current type
            questions = generate_questions_in_chunks(
                paragraph,
                image_data,
                question_type,
                remaining_questions,  # Remaining slots for questions
                prompt,
                chunk_size
            )
            
            # Remove duplicates
            questions = remove_duplicates(questions)

            # Add metadata and append to all_questions
            for qa in questions:
                question_text = qa["question"]
                answer_text = qa["answer"]
                all_questions.append({
                    "Question Type": question_type,
                    "Question": question_text,
                    "Answer": answer_text,
                    "Question Length (Chars)": len(question_text),
                    "Answer Length (Chars)": len(str(answer_text)) if isinstance(answer_text, str) else sum(len(str(a)) for a in answer_text),
                    "Question Tokens": calculate_tokens(question_text),
                    "Answer Tokens": calculate_tokens(answer_text if isinstance(answer_text, str) else "".join(answer_text))
                })

            # Update remaining questions and track completed types
            remaining_questions -= len(questions)
            if len(questions) == 0:
                types_covered.add(question_type)  # Mark this type as fully generated

            # Break the loop if enough questions are generated
            if len(all_questions) >= total_questions:
                break

    # Return the top N unique questions
    return all_questions[:total_questions]







import tiktoken

def calculate_tokens(text, model="gpt-3.5-turbo"):
    """
    Calculate the number of tokens in a given text using tiktoken.

    Args:
        text (str): Input text.
        model (str): Model name to determine the encoding (default: "gpt-3.5-turbo").

    Returns:
        int: Number of tokens in the text.
    """
    try:
        # Preload the encoding locally to avoid HTTPS timeouts
        if model in ["gpt-3.5-turbo", "gpt-4"]:
            encoding_name = "cl100k_base"
        elif model == "text-davinci-003":
            encoding_name = "p50k_base"
        else:
            raise ValueError(f"Unsupported model: {model}")

        # Load the encoding
        encoding = tiktoken.encoding_for_model(model) if tiktoken.encoding_for_model else tiktoken.get_encoding(encoding_name)
        
        # Return the number of tokens
        return len(encoding.encode(text))

    except Exception as e:
        print(f"Error calculating tokens: {e}")
        return None



"Describe an image of a formal bank document in detail, including its overall structure, such as headers, footers, and sections, along with the placement of the banks logo, name, address, and contact information. Include background features like watermarks, barcodes, or security marks. Focus on tables within the document that display account details, transaction records, dates, descriptions, debit/credit amounts, and balances, specifying the number of rows and columns, headers, borders, alignment, and any highlights like bold totals or shaded cells. Mention account details such as the account holders name, account number, branch name, and IFSC code, along with details about account types or interest rates. Provide information on transaction lists or tables, including details like dates, descriptions, transaction types (credit/debit), amounts, and balances, highlighting any significant entries. Include additional elements like handwritten notes, signatures (manual or digital), stamps, or seals for authentication, as well as reference numbers, document IDs, or case numbers for tracking. Describe the formatting, including font styles, alignment, and the use of bold or italicized text for emphasis. Mention any legal or formal information, such as disclaimers, terms, and conditions, or privacy policies, often found at the bottom of the document, and note the use of formal language and financial terminology. Finally, describe the professional appearance of the document, including the use of colors (e.g., black-and-white or highlights) and whether it appears printed or scanned."













ChatGPT can make mistakes. Check important info.






from azure.ai.openai import ChatGPT
import json


def generate_questions(paragraph, question_type, num_questions, prompt_template, base64_images=None):
    """
    Generate questions using Azure LLM based on a paragraph, question type, prompt template, and Base64 images.

    Args:
        paragraph (str): The input text for generating questions.
        question_type (str): The type of questions to generate (e.g., "Factual", "Procedural").
        num_questions (int): Number of questions to generate.
        prompt_template (str): Template for the LLM prompt.
        base64_images (dict): Optional dictionary of image names and their Base64 representations.

    Returns:
        list: A list of generated questions and answers, or an empty list in case of errors.
    """
    # Initialize the Azure OpenAI ChatGPT
    llm = ChatGPT(
        temperature=0,
        api_version="<azure_openai_api_version>",
        azure_endpoint="<azure_openai_endpoint>",
        deployment_name="ssgpt-40"
    )

    # Construct the prompt dynamically based on inputs
    prompt = prompt_template.format(paragraph=paragraph, num_questions=num_questions, question_type=question_type)

    # Add Base64 images to the payload if provided
    images_payload = [{"name": name, "base64": image} for name, image in base64_images.items()] if base64_images else []

    try:
        # Call the LLM with text and Base64 images
        response = llm.invoke([
            {
                "role": "user",
                "content": {
                    "type": "structured",
                    "inputs": {
                        "text": prompt,
                        "images": images_payload
                    },
                    "instruction": f"Generate {num_questions} {question_type} questions and answers based on the provided text and images. Provide the output in JSON format."
                }
            }
        ])

        # Parse and return JSON response
        return extract_valid_json(response.content)

    except Exception as e:
        print(f"Error generating {question_type} questions: {e}")
        return []


# Helper function to extract valid JSON from LLM response
def extract_valid_json(response):
    """
    Extract valid JSON from the LLM response.

    Args:
        response (str): The response string from the LLM.

    Returns:
        list: Parsed JSON list of questions and answers, or an empty list if parsing fails.
    """
    try:
        # Parse the response as JSON
        return json.loads(response)
    except json.JSONDecodeError:
        print("Error: Invalid JSON detected in LLM response.")
        return []








import fitz  # PyMuPDF
import os
import base64
import re
import json
from azure.ai.openai import ChatGPT

# Extract images from PDF
def extract_images_with_pymupdf(pdf_path, output_folder):
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    doc = fitz.open(pdf_path)
    for page_number in range(len(doc)):
        page = doc[page_number]
        images = page.get_images(full=True)
        if not images:
            print(f"No images found on page {page_number + 1}")
            continue

        for img_index, img in enumerate(images):
            xref = img[0]
            base_image = doc.extract_image(xref)
            image_bytes = base_image["image"]
            image_ext = base_image["ext"]
            image_filename = os.path.join(
                output_folder, f"page_{page_number + 1}_{img_index + 1}.{image_ext}"
            )
            with open(image_filename, "wb") as image_file:
                image_file.write(image_bytes)
            print(f"Saved image: {image_filename}")

# Sort files numerically
def sort_numerically(file_list):
    """Sort files numerically by extracting numbers from filenames."""
    def extract_numbers(file_name):
        return [int(num) for num in re.findall(r'\d+', file_name)]
    return sorted(file_list, key=extract_numbers)

# Convert images to Base64
def images_to_base64(folder_path):
    base64_images = {}
    # Get all files and sort them numerically
    file_list = sort_numerically(os.listdir(folder_path))
    for image_file in file_list:
        if image_file.endswith((".png", ".jpg", ".jpeg")):
            image_path = os.path.join(folder_path, image_file)
            with open(image_path, "rb") as file:
                encoded_string = base64.b64encode(file.read()).decode("utf-8")
                base64_images[image_file] = encoded_string
    return base64_images

# Call Azure OpenAI LLM with images
def call_llm_with_images(base64_images):
    responses = []
    messages_template = [
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": "Extract the text from the image"
                },
                {
                    "type": "image_url",
                    "image_url": {
                        "url": ""  # Placeholder, updated in loop
                    }
                }
            ]
        }
    ]

    # Configure AzureChatOpenAI
    llm = AzureChatOpenAI(
        temperature=0,
        api_version="<azure_openai_api_version>",
        azure_endpoint="<azure_openai_endpoint>",
        deployment_name="ssgpt-40",
        seed=1
    )

    for image_name, base64_image in base64_images.items():
        try:
            messages = messages_template.copy()
            messages[0]["content"][1]["image_url"]["url"] = f"data:image/jpeg;base64,{base64_image}"
            response = llm.invoke(messages)
            responses.append({
                "image_name": image_name,
                "base64": base64_image,
                "response": response.content
            })
        except Exception as e:
            print(f"Error calling LLM for {image_name}: {e}")
            responses.append({
                "image_name": image_name,
                "base64": base64_image,
                "response": f"Error: {e}"
            })
    return responses

# Main Workflow
pdf_path = r"h:\Question and answer\Fund accounting (Resubmit_1025)36. VFMC AAS25 SOP 5.8.pdf"  # Replace with your PDF file
output_folder = r"h:\Question and answer Fund accounting\pdf_images"

# Step 1: Extract images from the PDF
extract_images_with_pymupdf(pdf_path, output_folder)

# Step 2: Convert extracted images to Base64
base64_images = images_to_base64(output_folder)

# Step 3: Call LLM with Base64-encoded images and get JSON response
responses = call_llm_with_images(base64_images)

# Step 4: Generate JSON output with Base64 and LLM responses
output_json = {"responses": responses}

# Save JSON to a file
json_output_file = "output_responses_with_base64.json"
with open(json_output_file, "w") as json_file:
    json.dump(output_json, json_file, indent=4)

# Print JSON output
print("Generated JSON Object:")
print(json.dumps(output_json, indent=4))










import fitz  # PyMuPDF
import os
import base64
import re
import json
from azure.ai.openai import ChatGPT

# Extract images from PDF
def extract_images_with_pymupdf(pdf_path, output_folder):
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    doc = fitz.open(pdf_path)
    for page_number in range(len(doc)):
        page = doc[page_number]
        images = page.get_images(full=True)
        if not images:
            print(f"No images found on page {page_number + 1}")
            continue

        for img_index, img in enumerate(images):
            xref = img[0]
            base_image = doc.extract_image(xref)
            image_bytes = base_image["image"]
            image_ext = base_image["ext"]
            image_filename = os.path.join(
                output_folder, f"page_{page_number + 1}_{img_index + 1}.{image_ext}"
            )
            with open(image_filename, "wb") as image_file:
                image_file.write(image_bytes)
            print(f"Saved image: {image_filename}")

# Sort files numerically
def sort_numerically(file_list):
    """Sort files numerically by extracting numbers from filenames."""
    def extract_numbers(file_name):
        return [int(num) for num in re.findall(r'\d+', file_name)]
    return sorted(file_list, key=extract_numbers)

# Convert images to Base64
def images_to_base64(folder_path):
    base64_images = {}
    # Get all files and sort them numerically
    file_list = sort_numerically(os.listdir(folder_path))
    for image_file in file_list:
        if image_file.endswith((".png", ".jpg", ".jpeg")):
            image_path = os.path.join(folder_path, image_file)
            with open(image_path, "rb") as file:
                encoded_string = base64.b64encode(file.read()).decode("utf-8")
                base64_images[image_file] = encoded_string
    return base64_images

# Call Azure OpenAI LLM with images
def call_llm_with_images(base64_images):
    responses = []
    messages_template = [
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": "Extract the text from the image"
                },
                {
                    "type": "image_url",
                    "image_url": {
                        "url": ""  # Placeholder, updated in loop
                    }
                }
            ]
        }
    ]

    # Configure AzureChatOpenAI
    llm = AzureChatOpenAI(
        temperature=0,
        api_version="<azure_openai_api_version>",
        azure_endpoint="<azure_openai_endpoint>",
        deployment_name="ssgpt-40",
        seed=1
    )

    for image_name, base64_image in base64_images.items():
        try:
            messages = messages_template.copy()
            messages[0]["content"][1]["image_url"]["url"] = f"data:image/jpeg;base64,{base64_image}"
            response = llm.invoke(messages)
            responses.append({"image_name": image_name, "response": response.content})
        except Exception as e:
            print(f"Error calling LLM for {image_name}: {e}")
            responses.append({"image_name": image_name, "response": f"Error: {e}"})
    return responses

# Main Workflow
pdf_path = r"h:\Question and answer\Fund accounting (Resubmit_1025)36. VFMC AAS25 SOP 5.8.pdf"  # Replace with your PDF file
output_folder = r"h:\Question and answer Fund accounting\pdf_images"

# Step 1: Extract images from the PDF
extract_images_with_pymupdf(pdf_path, output_folder)

# Step 2: Convert extracted images to Base64
base64_images = images_to_base64(output_folder)
print("Base64 Encoded Images:", base64_images)

# Step 3: Call LLM with Base64-encoded images
responses = call_llm_with_images(base64_images)

# Step 4: Generate JSON output
output_json = {"responses": responses}

# Save JSON to a file
json_output_file = "output_responses.json"
with open(json_output_file, "w") as json_file:
    json.dump(output_json, json_file, indent=4)

# Print JSON output
print("Generated JSON Object:")
print(json.dumps(output_json, indent=4))











import os
import base64
import json
import fitz  # PyMuPDF
from azure.ai.openai import ChatGPT

# Function to extract images from PDF
def extract_images_with_pymupdf(pdf_path, output_folder):
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    doc = fitz.open(pdf_path)
    for page_number in range(len(doc)):
        page = doc[page_number]
        images = page.get_images(full=True)
        if not images:
            print(f"No images found on page {page_number + 1}")
            continue

        for img_index, img in enumerate(images):
            xref = img[0]
            base_image = doc.extract_image(xref)
            image_bytes = base_image["image"]
            image_ext = base_image["ext"]
            image_filename = os.path.join(
                output_folder, f"page_{page_number + 1}_{img_index + 1}.{image_ext}"
            )
            with open(image_filename, "wb") as image_file:
                image_file.write(image_bytes)
            print(f"Saved image: {image_filename}")

# Function to convert images to Base64
def images_to_base64(folder_path):
    base64_images = {}
    for image_file in os.listdir(folder_path):
        if image_file.endswith((".png", ".jpg", ".jpeg")):
            image_path = os.path.join(folder_path, image_file)
            with open(image_path, "rb") as file:
                encoded_string = base64.b64encode(file.read()).decode("utf-8")
                base64_images[image_file] = encoded_string
    return base64_images

# Function to prepare JSON payload
def generate_json_payload(base64_images):
    """
    Generates a JSON payload containing image names and base64-encoded data.
    """
    images_payload = {
        "images": [{"name": image_name, "data": image_data} for image_name, image_data in base64_images.items()]
    }
    return json.dumps(images_payload)

# Function to call LLM with Base64-encoded images
def call_llm_with_json_payload(json_payload, llm_endpoint):
    """
    Sends the JSON payload to the LLM API and retrieves responses.
    """
    headers = {"Content-Type": "application/json"}
    response = requests.post(llm_endpoint, headers=headers, data=json_payload)
    return response.json()

# Main Workflow
pdf_path = r"h:\Question and answer\Fund accounting (Resubmit_1025)36. VFMC AAS25 SOP 5.8.pdf"  # Replace with your PDF file
output_folder = r"h:\Question and answer Fund accounting\pdf_images"
llm_endpoint = "http://your-llm-api-endpoint"  # Replace with your LLM API endpoint

# Step 1: Extract images from the PDF
extract_images_with_pymupdf(pdf_path, output_folder)

# Step 2: Convert extracted images to Base64
base64_images = images_to_base64(output_folder)
print("Base64 Encoded Images:", base64_images)

# Step 3: Generate JSON payload
json_payload = generate_json_payload(base64_images)
print("Generated JSON Payload:", json_payload)

# Step 4: Send JSON payload to LLM and retrieve responses
responses = call_llm_with_json_payload(json_payload, llm_endpoint)
print("LLM Responses:", responses)












import re

def organize_content_page_wise(responses):
    """
    Organizes AIMessage content into a dictionary grouped by page.
    """
    page_wise_content = {}

    for image_name, response in responses.items():
        # Extract page number from the image name (e.g., "page_3_1.png")
        match = re.search(r'page_(\d+)_\d+', image_name)
        if match:
            page_number = f"Page {match.group(1)}"
        else:
            continue  # Skip if page number is not found

        # Extract content from the AIMessage object
        content = response.content if hasattr(response, 'content') else "No content available"

        # Group content by page
        if page_number not in page_wise_content:
            page_wise_content[page_number] = []
        page_wise_content[page_number].append(content)

    return page_wise_content


# Example Usage
responses = {
    'page_1_1.png': AIMessage(content='STATE STREET'),
    'page_3_1.png': AIMessage(content='DATE: 190822\nTIME: 05:54\n\nSTATE STREET CORPORATION'),
    'page_3_2.png': AIMessage(content="I'm sorry, but I can't extract text from images."),
    'page_4_1.png': AIMessage(content='Navigation\nApplications\nAAS25 Report\nClient:\niVFMC\nChristian Super\nING'),
    'page_4_2.png': AIMessage(content='Job Monitor\n\nJob Status\n\nRefresh Manual Start\n\nJob Code'),
    'page_5_1.png': AIMessage(content='AAS25 Report\n\nNavigation\nApplications AAS25 Report'),
    'page_5_2.png': AIMessage(content='Job Monitor\n\nJob Status\n\nRefresh Manual Start\n\nJob Code: AAS_INB_DATA_VFMC'),
    'page_6_1.png': AIMessage(content='Job Status\n\nJob Code: AAS_INB_DATA_VFMC\nJob Name: Get Pos/Txn/Trial data and generate'),
    'page_6_2.png': AIMessage(content='Navigation\nApplications: AAS325 Report\nClient: VFMC'),
    'page_7_1.png': AIMessage(content='Navigation\nApplications: AAS25 Report\nClient: VFMC'),
    'page_7_2.jpeg': AIMessage(content='Navigation\nApplications: AAS25 Report\nClient: VFMC'),
    'page_8_1.jpeg': AIMessage(content='Navigation\nApplications: AAS25 Report\nClient: VFMC'),
    'page_8_2.png': AIMessage(content='Navigation\nApplications\nAAS25 Report\nClient:\nVFMC'),
    'page_9_1.png': AIMessage(content='Applications: AAS25 Report\nClient: VFMC\n\nNormalized Table'),
    'page_9_2.jpeg': AIMessage(content='Navigation\nApplications: AAS25 Report\nClient: VFMC'),
    'page_10_1.png': AIMessage(content='Navigation\nApplications: AAS25 Report\nClient: VFMC'),
    'page_10_2.png': AIMessage(content='Job Status\n\nApp Code | Report Id | Title | Report Text'),
    'page_11_1.png': AIMessage(content='VFMC June 2019\n\nReport\tColumn\tField\tPROD total\tDUMMY'),
    'page_11_2.png': AIMessage(content='Sort A to Z\nSort Z to A\nSort by Color\nClear Filter'),
    'page_113.png': AIMessage(content="I'm sorry, but I can't extract text from the image you provided."),
}

# Group responses by page
page_wise_content = organize_content_page_wise(responses)

# Print organized content
for page, content_list in page_wise_content.items():
    print(f"{page}:")
    for content in content_list:
        print(content)
    print("\n")











import re

# Function to clean noisy responses
def clean_response(response_content):
    """
    Cleans the noisy text content by removing unwanted characters, extra spaces,
    and irrelevant lines.
    """
    if not response_content:
        return "No meaningful text found."

    # Remove metadata lines (e.g., 'response_metadata', etc.)
    cleaned_text = re.sub(r'response_metadata.*', '', response_content, flags=re.DOTALL)

    # Remove extra whitespace, blank lines, and non-alphanumeric characters
    cleaned_text = re.sub(r'[^a-zA-Z0-9\s:/,.()-]+', '', cleaned_text)
    cleaned_text = re.sub(r'\s+', ' ', cleaned_text).strip()

    return cleaned_text


# Function to process LLM responses
def process_responses(responses):
    """
    Iterates through the responses and cleans up the content for each image.
    """
    cleaned_responses = {}
    for image_name, response in responses.items():
        if response:
            # Access the content attribute directly
            content = response.content if hasattr(response, 'content') else ''
            cleaned_responses[image_name] = clean_response(content)
        else:
            cleaned_responses[image_name] = "No response from LLM."

    return cleaned_responses










import re

def clean_response(response_content):
    """
    Cleans the noisy text content by removing unwanted characters, extra spaces, 
    and irrelevant lines.
    """
    if not response_content:
        return "No meaningful text found."

    # Remove metadata lines (e.g., 'response_metadata', etc.)
    cleaned_text = re.sub(r'response_metadata.*', '', response_content, flags=re.DOTALL)

    # Remove extra whitespace, blank lines, and non-alphanumeric characters
    cleaned_text = re.sub(r'[^a-zA-Z0-9\s:/,.()-]+', '', cleaned_text)
    cleaned_text = re.sub(r'\s+', ' ', cleaned_text).strip()

    return cleaned_text

# Clean all responses
def process_responses(responses):
    """
    Iterates through the responses and cleans up the content for each image.
    """
    cleaned_responses = {}
    for image_name, response in responses.items():
        if response:
            # Extract the content from the LLM response
            content = response.get('content', '')
            cleaned_responses[image_name] = clean_response(content)
        else:
            cleaned_responses[image_name] = "No response from LLM."

    return cleaned_responses


# Example usage with the noisy responses
noisy_responses = {
    "page_3_1.png": {
        "content": "STATE STREET response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 373}}"
    },
    "page_3_2.png": {
        "content": "I'm sorry, but I can't extract text from images."
    },
    "page_4_1.png": {
        "content": "Navigation\nApplications\nAAS25 Report\nClient: VFMC\nChristian Super\nING"
    },
    # Add more sample noisy responses here...
}

# Process and clean the responses
cleaned_responses = process_responses(noisy_responses)

# Print cleaned responses
for image_name, cleaned_text in cleaned_responses.items():
    print(f"Image: {image_name}")
    print(f"Cleaned Content: {cleaned_text}\n")










import fitz  # PyMuPDF
import os
import base64
import re
from azure.ai.openai import ChatGPT

# Extract images from PDF
def extract_images_with_pymupdf(pdf_path, output_folder):
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    doc = fitz.open(pdf_path)
    for page_number in range(len(doc)):
        page = doc[page_number]
        images = page.get_images(full=True)
        if not images:
            print(f"No images found on page {page_number + 1}")
            continue

        for img_index, img in enumerate(images):
            xref = img[0]
            base_image = doc.extract_image(xref)
            image_bytes = base_image["image"]
            image_ext = base_image["ext"]
            image_filename = os.path.join(
                output_folder, f"page_{page_number + 1}_{img_index + 1}.{image_ext}"
            )
            with open(image_filename, "wb") as image_file:
                image_file.write(image_bytes)
            print(f"Saved image: {image_filename}")

# Sort files numerically
def sort_numerically(file_list):
    """Sort files numerically by extracting numbers from filenames."""
    def extract_numbers(file_name):
        return [int(num) for num in re.findall(r'\d+', file_name)]
    return sorted(file_list, key=extract_numbers)

# Convert images to Base64
def images_to_base64(folder_path):
    base64_images = {}
    # Get all files and sort them numerically
    file_list = sort_numerically(os.listdir(folder_path))
    for image_file in file_list:
        if image_file.endswith((".png", ".jpg", ".jpeg")):
            image_path = os.path.join(folder_path, image_file)
            with open(image_path, "rb") as file:
                encoded_string = base64.b64encode(file.read()).decode("utf-8")
                base64_images[image_file] = encoded_string
    return base64_images

# Call Azure OpenAI LLM with images
def call_llm_with_images(base64_images):
    responses = {}
    messages_template = [
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": "Extract the text from the image"
                },
                {
                    "type": "image_url",
                    "image_url": {
                        "url": ""  # Placeholder, updated in loop
                    }
                }
            ]
        }
    ]

    # Configure AzureChatOpenAI
    llm = AzureChatOpenAI(
        temperature=0,
        api_version="<azure_openai_api_version>",
        azure_endpoint="<azure_openai_endpoint>",
        deployment_name="ssgpt-40",
        seed=1
    )

    for image_name, base64_image in base64_images.items():
        try:
            messages = messages_template.copy()
            messages[0]["content"][1]["image_url"]["url"] = f"data:image/jpeg;base64,{base64_image}"
            response = llm.invoke(messages)
            responses[image_name] = response
        except Exception as e:
            print(f"Error calling LLM for {image_name}: {e}")
            responses[image_name] = None
    return responses

# Main Workflow
pdf_path = r"h:\Question and answer\Fund accounting (Resubmit_1025)36. VFMC AAS25 SOP 5.8.pdf"  # Replace with your PDF file
output_folder = r"h:\Question and answer Fund accounting\pdf_images"

# Step 1: Extract images from the PDF
extract_images_with_pymupdf(pdf_path, output_folder)

# Step 2: Convert extracted images to Base64
base64_images = images_to_base64(output_folder)
print("Base64 Encoded Images:", base64_images)

# Step 3: Call LLM with Base64-encoded images
responses = call_llm_with_images(base64_images)

# Step 4: Print LLM Responses
print("LLM Responses:")
for image_name, response in responses.items():
    print(f"Image: {image_name}")
    print(f"Response: {response}")









import fitz  # PyMuPDF
import os
import base64
import re
from azure.ai.openai import ChatGPT

# Extract images from PDF
def extract_images_with_pymupdf(pdf_path, output_folder):
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    doc = fitz.open(pdf_path)
    for page_number in range(len(doc)):
        page = doc[page_number]
        images = page.get_images(full=True)
        if not images:
            print(f"No images found on page {page_number + 1}")
            continue

        for img_index, img in enumerate(images):
            xref = img[0]
            base_image = doc.extract_image(xref)
            image_bytes = base_image["image"]
            image_ext = base_image["ext"]
            image_filename = os.path.join(
                output_folder, f"page_{page_number + 1}_{img_index + 1}.{image_ext}"
            )
            with open(image_filename, "wb") as image_file:
                image_file.write(image_bytes)
            print(f"Saved image: {image_filename}")

# Sort files numerically
def sort_numerically(file_list):
    """Sort files numerically by extracting numbers from filenames."""
    def extract_numbers(file_name):
        return [int(num) for num in re.findall(r'\d+', file_name)]
    return sorted(file_list, key=extract_numbers)

# Convert images to Base64
def images_to_base64(folder_path):
    base64_images = {}
    # Get all files and sort them numerically
    file_list = sort_numerically(os.listdir(folder_path))
    for image_file in file_list:
        if image_file.endswith((".png", ".jpg", ".jpeg")):
            image_path = os.path.join(folder_path, image_file)
            with open(image_path, "rb") as file:
                encoded_string = base64.b64encode(file.read()).decode("utf-8")
                base64_images[image_file] = encoded_string
    return base64_images

# Call Azure OpenAI LLM with images
def call_llm_with_images(base64_images):
    responses = {}
    messages_template = [
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": f"Extract the text from the image"
                },
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{base64_image}"
                    }
                }
            ]
        }
    ]

    # Configure AzureChatOpenAI
    llm = AzureChatOpenAI(
        temperature=0,
        api_version="<azure_openai_api_version>",
        azure_endpoint="<azure_openai_endpoint>",
        deployment_name="ssgpt-40",
        seed=1
    )

    for image_name, base64_image in base64_images.items():
        try:
            messages = messages_template.copy()
            messages[0]["content"][1]["image_url"]["url"] = f"data:image/jpeg;base64,{base64_image}"
            response = llm.invoke(messages)
            responses[image_name] = response
        except Exception as e:
            print(f"Error calling LLM for {image_name}: {e}")
            responses[image_name] = None
    return responses

# Main Workflow
pdf_path = r"h:\Question and answer\Fund accounting (Resubmit_1025)36. VFMC AAS25 SOP 5.8.pdf"  # Replace with your PDF file
output_folder = r"h:\Question and answer Fund accounting\pdf_images"

# Step 1: Extract images from the PDF
extract_images_with_pymupdf(pdf_path, output_folder)

# Step 2: Convert extracted images to Base64
base64_images = images_to_base64(output_folder)
print("Base64 Encoded Images:", base64_images)

# Step 3: Call LLM with Base64-encoded images
responses = call_llm_with_images(base64_images)

# Step 4: Print LLM Responses
print("LLM Responses:")
for image_name, response in responses.items():
    print(f"Image: {image_name}")
    print(f"Response: {response}")












import fitz  # PyMuPDF
import os
import base64
import re
from langchain.chat_models import AzureChatOpenAI  # Import the correct AzureChatOpenAI class
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage

# Extract images from PDF
def extract_images_with_pymupdf(pdf_path, output_folder):
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    doc = fitz.open(pdf_path)

    for page_number in range(len(doc)):
        page = doc.load_page(page_number)
        images = page.get_images(full=True)

        if not images:
            print(f"No images found on page {page_number + 1}")
            continue

        for img_index, img in enumerate(images):
            xref = img[0]
            base_image = doc.extract_image(xref)
            image_bytes = base_image["image"]
            image_ext = base_image["ext"]

            image_filename = os.path.join(
                output_folder, f"page_{page_number + 1}_{img_index + 1}.{image_ext}"
            )

            with open(image_filename, "wb") as image_file:
                image_file.write(image_bytes)

            print(f"Saved image: {image_filename}")

# Sort files numerically
def sort_numerically(file_list):
    """Sort files numerically by extracting numbers from filenames."""
    def extract_numbers(file_name):
        return [int(num) for num in re.findall(r'\d+', file_name)]

    return sorted(file_list, key=extract_numbers)

# Convert images to Base64
def images_to_base64(folder_path):
    base64_images = {}

    # Get all files and sort them numerically
    file_list = sort_numerically(os.listdir(folder_path))

    for image_file in file_list:
        if image_file.endswith((".png", ".jpg", ".jpeg")):
            image_path = os.path.join(folder_path, image_file)

            with open(image_path, "rb") as file:
                encoded_string = base64.b64encode(file.read()).decode("utf-8")
            
            base64_images[image_file] = encoded_string

    return base64_images

# Send images and text to Azure OpenAI using AzureChatOpenAI (LangChain)
def generate_text_with_images(base64_images, text_input, azure_openai_endpoint, azure_api_key, azure_openai_api_version):
    # Construct the list of messages
    messages = [
        HumanMessage(content=text_input)  # Start with the text input as the initial user message
    ]

    # Add images as base64 data to the messages
    for image_name, base64_image in base64_images.items():
        image_message = HumanMessage(content=f"data:image/jpeg;base64,{base64_image}")
        messages.append(image_message)

    # Initialize the AzureChatOpenAI instance
    chat_openai = AzureChatOpenAI(
        openai_api_key=azure_api_key,
        openai_api_base=azure_openai_endpoint,
        openai_api_version=azure_openai_api_version,
        deployment_name="ssgpt-40",  # Use the correct deployment name for your model
        temperature=0  # Adjust the temperature as per your needs
    )

    # Call the AzureChatOpenAI with the constructed messages
    try:
        response = chat_openai.completion_with_retry(messages)  # Call the method for response

        # Return the response content
        return response['text']  # Ensure you are extracting the correct part of the response

    except Exception as e:
        print(f"Error calling LLM: {e}")
        return None

# Example usage
pdf_path = "h:\\Question and answer Fund accounting (Resubmit_1025)36. VFMC AAS25 SOP 5.0.pdf"  # Replace with your PDF file
output_folder = "h:\\Question and answer\\Fund accounting\\pdf_images"

# Extract images from the PDF
extract_images_with_pymupdf(pdf_path, output_folder)

# Convert images to Base64
base64_images = images_to_base64(output_folder)

# Provide the text input for the LLM
text_input = "Here is some text that goes along with the images."

# Azure-specific settings (ensure you have the correct values)
azure_openai_endpoint = "https://your-azure-endpoint"  # Replace with your Azure endpoint
azure_api_key = "your-azure-api-key"  # Replace with your Azure API key
azure_openai_api_version = "2023-05-15"  # Replace with the correct API version for your Azure model

# Generate response with both text and images using Azure OpenAI
response_text = generate_text_with_images(base64_images, text_input, azure_openai_endpoint, azure_api_key, azure_openai_api_version)

print(response_text)













import fitz  # PyMuPDF
import os
import base64
import re
from azure.ai.openai import ChatGPT
from azure.core.credentials import AzureKeyCredential

# Extract images from PDF
def extract_images_with_pymupdf(pdf_path, output_folder):
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    doc = fitz.open(pdf_path)

    for page_number in range(len(doc)):
        page = doc.load_page(page_number)
        images = page.get_images(full=True)

        if not images:
            print(f"No images found on page {page_number + 1}")
            continue

        for img_index, img in enumerate(images):
            xref = img[0]
            base_image = doc.extract_image(xref)
            image_bytes = base_image["image"]
            image_ext = base_image["ext"]

            image_filename = os.path.join(
                output_folder, f"page_{page_number + 1}_{img_index + 1}.{image_ext}"
            )

            with open(image_filename, "wb") as image_file:
                image_file.write(image_bytes)

            print(f"Saved image: {image_filename}")

# Sort files numerically
def sort_numerically(file_list):
    """Sort files numerically by extracting numbers from filenames."""
    def extract_numbers(file_name):
        return [int(num) for num in re.findall(r'\d+', file_name)]

    return sorted(file_list, key=extract_numbers)

# Convert images to Base64
def images_to_base64(folder_path):
    base64_images = {}

    # Get all files and sort them numerically
    file_list = sort_numerically(os.listdir(folder_path))

    for image_file in file_list:
        if image_file.endswith((".png", ".jpg", ".jpeg")):
            image_path = os.path.join(folder_path, image_file)

            with open(image_path, "rb") as file:
                encoded_string = base64.b64encode(file.read()).decode("utf-8")
            
            base64_images[image_file] = encoded_string

    return base64_images

# Send images and text to Azure OpenAI for processing
def generate_text_with_images(base64_images, text_input, azure_openai_endpoint, azure_openai_api_version, azure_api_key):
    messages = [
        {
            "role": "user",
            "content": text_input
        }
    ]

    # Add images as base64 data
    for image_name, base64_image in base64_images.items():
        image_message = {
            "role": "user",
            "content": f"data:image/jpeg;base64,{base64_image}"
        }
        messages.append(image_message)

    # Azure LLM API Call (using Azure-specific method)
    try:
        # Instantiate the Azure OpenAI client
        client = ChatGPT(endpoint=azure_openai_endpoint, credential=AzureKeyCredential(azure_api_key))

        # Call the Azure OpenAI model
        response = client.chat_completions.create(
            deployment_name="ssgpt-40",  # Change if using a different deployment
            messages=messages,  # Pass the entire structured messages list
            api_version=azure_openai_api_version
        )

        # Extract and return the response
        return response.choices[0].message.content  # Adjust according to the response format

    except Exception as e:
        print(f"Error calling LLM: {e}")
        return None

# Example usage
pdf_path = "h:\\Question and answer Fund accounting (Resubmit_1025)36. VFMC AAS25 SOP 5.0.pdf"  # Replace with your PDF file
output_folder = "h:\\Question and answer\\Fund accounting\\pdf_images"

# Extract images from the PDF
extract_images_with_pymupdf(pdf_path, output_folder)

# Convert images to Base64
base64_images = images_to_base64(output_folder)

# Provide the text input for the LLM
text_input = "Here is some text that goes along with the images."

# Azure-specific settings (ensure you have the correct values)
azure_openai_endpoint = "https://your-azure-endpoint"  # Replace with your Azure endpoint
azure_openai_api_version = "2023-05-15"  # Replace with the correct API version
azure_api_key = "your-azure-api-key"  # Replace with your Azure API key

# Generate response with both text and images using Azure OpenAI
response_text = generate_text_with_images(base64_images, text_input, azure_openai_endpoint, azure_openai_api_version, azure_api_key)

print(response_text)














import fitz  # PyMuPDF
import os
import base64
import re
import openai

# Extract images from PDF
def extract_images_with_pymupdf(pdf_path, output_folder):
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    doc = fitz.open(pdf_path)

    for page_number in range(len(doc)):
        page = doc.load_page(page_number)
        images = page.get_images(full=True)

        if not images:
            print(f"No images found on page {page_number + 1}")
            continue

        for img_index, img in enumerate(images):
            xref = img[0]
            base_image = doc.extract_image(xref)
            image_bytes = base_image["image"]
            image_ext = base_image["ext"]

            image_filename = os.path.join(
                output_folder, f"page_{page_number + 1}_{img_index + 1}.{image_ext}"
            )

            with open(image_filename, "wb") as image_file:
                image_file.write(image_bytes)

            print(f"Saved image: {image_filename}")

# Sort files numerically
def sort_numerically(file_list):
    """Sort files numerically by extracting numbers from filenames."""
    def extract_numbers(file_name):
        return [int(num) for num in re.findall(r'\d+', file_name)]

    return sorted(file_list, key=extract_numbers)

# Convert images to Base64
def images_to_base64(folder_path):
    base64_images = {}

    # Get all files and sort them numerically
    file_list = sort_numerically(os.listdir(folder_path))

    for image_file in file_list:
        if image_file.endswith((".png", ".jpg", ".jpeg")):
            image_path = os.path.join(folder_path, image_file)

            with open(image_path, "rb") as file:
                encoded_string = base64.b64encode(file.read()).decode("utf-8")
            
            base64_images[image_file] = encoded_string

    return base64_images

# Send images and text to OpenAI's GPT-3 (or other models) for processing
def generate_text_with_images(base64_images, text_input):
    messages = [
        {
            "role": "user",
            "content": text_input
        },
        {
            "role": "user",
            "content": {
                "type": "text",
                "text": "Extract the text from the image"
            }
        }
    ]

    for image_name, base64_image in base64_images.items():
        image_message = {
            "role": "user",
            "content": {
                "type": "image_url",
                "image_url": f"data:image/jpeg;base64,{base64_image}"
            }
        }
        messages.append(image_message)

    # Call OpenAI API with the messages payload
    response = openai.ChatCompletion.create(
        model="gpt-4",  # or another model as required
        messages=messages
    )

    return response['choices'][0]['message']['content']

# Example usage
pdf_path = "path/to/your/file.pdf"
output_folder = "output_images_folder"

# Extract images from the PDF
extract_images_with_pymupdf(pdf_path, output_folder)

# Convert images to Base64
base64_images = images_to_base64(output_folder)

# Provide the text input for the LLM
text_input = "Here is some text that goes along with the images."

# Generate response with both text and images
response_text = generate_text_with_images(base64_images, text_input)

print(response_text)












import openai
from google.cloud import vision

# Step 1: Use Google Vision API to Extract Text
def extract_text_from_image(image_path):
    client = vision.ImageAnnotatorClient()
    with open(image_path, "rb") as image_file:
        content = image_file.read()
    image = vision.Image(content=content)
    response = client.text_detection(image=image)
    if response.text_annotations:
        return response.text_annotations[0].description
    return "No text detected"

# Step 2: Use OpenAI LLM to Process the Extracted Text
def process_text_with_llm(text):
    openai.api_key = "your_openai_api_key"
    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": f"Please analyze the following text:\n{text}"},
        ],
    )
    return response['choices'][0]['message']['content']

# Main Execution
image_path = "path_to_your_image.jpg"
extracted_text = extract_text_from_image(image_path)
llm_response = process_text_with_llm(extracted_text)

print("Extracted Text:", extracted_text)
print("LLM Response:", llm_response)









def call_1lm_with_images(base64_images):
    messages = [
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": f"This is the Base64 content of an image file name {{image_name}}. Please read the text or contents this image might contain:\n\n{base64_images}"
                },
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{base64_images}"
                    }
                }
            ]
        }
    ]
    
    # Configure the LLM
    llm = AzureChatOpenAI(
        temperature=0.7,
        api_version=azure_openai_api_version,
        azure_endpoint=azure_openai_endpoint,
        deployment_name="ssgpt-40"
    )

    try:
        response = llm.invoke(messages)
        return response
    except Exception as e:
        print(f"Error calling LLM: {e}")
        return None










"messages": [
      {
        "role": "user",
        "content": [
          {
            "type": "text",
            "text": "Whats in this image?"
          },
          {
            "type": "image_url",
            "image_url": {
              "url": f"data:image/jpeg;base64,{base64_image}"
            }
          }
        ]
      }
    ],






import base64

# Example of decoding binary content
encoded_text = "iVBORw0KGgoAAAANSUhEUgAAAAUA..."

# Decode without converting to UTF-8
binary_data = base64.b64decode(encoded_text)

# Save to a file if needed
with open("output_file", "wb") as file:
    file.write(binary_data)

print("Binary data successfully decoded and saved.")








import base64

# Base64 encoded string with incorrect padding
encoded_text = "SGVsbG8gV29ybGQ"

# Add padding
missing_padding = len(encoded_text) % 4
if missing_padding:
    encoded_text += '=' * (4 - missing_padding)

# Decode the Base64 string
decoded_text = base64.b64decode(encoded_text).decode('utf-8')
print(decoded_text)  # Output: Hello World








import base64

# Base64 encoded string with incorrect padding
encoded_text = "SGVsbG8gV29ybGQ"

# Decode the Base64 string with validation
try:
    decoded_text = base64.b64decode(encoded_text, validate=True).decode('utf-8')
    print(decoded_text)
except base64.binascii.Error as e:
    print(f"Decoding failed: {e}")





import os
import base64
import re
from langchain.chat_models import AzureChatOpenAI

# Replace these with your Azure OpenAI configurations
azure_openai_api_version = "2023-03-15-preview"
azure_openai_endpoint = "https://your-endpoint.openai.azure.com/"
deployment_name = "ssgpt-40"

# Sort files numerically
def sort_numerically(file_list):
    """Sort files numerically by extracting numbers from filenames."""
    def extract_numbers(file_name):
        return [int(num) for num in re.findall(r'\d+', file_name)]

    return sorted(file_list, key=extract_numbers)

# Convert images to Base64
def images_to_base64(folder_path):
    base64_images = {}
    # Get all files and sort them numerically
    file_list = sort_numerically(os.listdir(folder_path))
    for image_file in file_list:
        if image_file.endswith((".png", ".jpg", ".jpeg")):
            image_path = os.path.join(folder_path, image_file)
            with open(image_path, "rb") as file:
                encoded_string = base64.b64encode(file.read()).decode("utf-8")
                base64_images[image_file] = encoded_string
    return base64_images

# Call the LLM with Base64 images
def call_llm_with_images(base64_images):
    messages = [{"role": "user", "content": "Please compare the following images:"}]
    for image_name, base64_string in base64_images.items():
        messages.append({
            "role": "user",
            "content": f"Image: {image_name}\nBase64:\n{base64_string[:100]}..."  # Truncated for readability
        })

    # Initialize the Azure OpenAI Chat model
    llm = AzureChatOpenAI(
        temperature=0,
        api_version=azure_openai_api_version,
        azure_endpoint=azure_openai_endpoint,
        deployment_name=deployment_name
    )

    # Invoke the model
    response = llm.invoke(messages)
    return response

# Main Workflow
output_folder = "extracted_images"  # Replace with your folder containing images

# Convert images to Base64
base64_images = images_to_base64(output_folder)

# Call LLM with Base64-encoded images
response = call_llm_with_images(base64_images)

# Print the response
print("LLM Response:")
print(response)













def images_to_base64(folder_path):
    base64_images = {}
    for image_file in sorted(os.listdir(folder_path)):
        if image_file.endswith((".png", ".jpg", ".jpeg")):
            image_path = os.path.join(folder_path, image_file)
            with open(image_path, "rb") as file:
                encoded_string = base64.b64encode(file.read()).decode("utf-8")
                base64_images[image_file] = encoded_string
    return base64_images



def call_llm_with_images(base64_images):
    # Start the LLM messages structure
    messages = [{"role": "user", "content": "Please compare the following images:"}]
    
    # Append each Base64-encoded image as a structured message
    for image_name, base64_string in base64_images.items():
        messages.append({
            "role": "user",
            "content": f"Image: {image_name}\nBase64:\n{base64_string[:100]}..."  # Truncated for readability
        })

    # Initialize the Azure OpenAI Chat model
    llm = AzureChatOpenAI(
        temperature=0,
        api_version=azure_openai_api_version,
        azure_endpoint=azure_openai_endpoint,
        deployment_name=deployment_name
    )

    # Invoke the model with the messages
    try:
        response = llm.invoke(messages)
        return response
    except Exception as e:
        print(f"Error calling LLM: {e}")
        return None










import fitz  # PyMuPDF
import os
import base64
import openai

# Set your OpenAI API key
openai.api_key = "your-api-key"  # Replace with your OpenAI API key

# Extract images from PDF
def extract_images_with_pymupdf(pdf_path, output_folder):
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    doc = fitz.open(pdf_path)
    for page_number in range(len(doc)):
        page = doc[page_number]
        images = page.get_images(full=True)

        if not images:
            print(f"No images found on page {page_number + 1}")
            continue

        for img_index, img in enumerate(images):
            xref = img[0]
            base_image = doc.extract_image(xref)
            image_bytes = base_image["image"]
            image_ext = base_image["ext"]

            image_filename = os.path.join(
                output_folder, f"page_{page_number + 1}_{img_index + 1}.{image_ext}"
            )
            with open(image_filename, "wb") as image_file:
                image_file.write(image_bytes)
            print(f"Saved image: {image_filename}")

# Convert images in the output folder to Base64 strings
def images_to_base64(folder_path):
    base64_images = {}
    for image_file in sorted(os.listdir(folder_path)):
        if image_file.endswith((".png", ".jpg", ".jpeg")):
            image_path = os.path.join(folder_path, image_file)
            with open(image_path, "rb") as file:
                encoded_string = base64.b64encode(file.read()).decode("utf-8")
                base64_images[image_file] = encoded_string
    return base64_images

# Call the LLM with the Base64 images
def call_llm_with_images(base64_images):
    messages = [{"role": "user", "content": "Please compare the following images:"}]
    for image_name, base64_string in base64_images.items():
        messages.append({
            "role": "user",
            "content": {
                "type": "image_url",
                "image_url": f"data:image/jpeg;base64,{base64_string}"
            }
        })

    # Call the LLM
    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=messages
    )
    return response.choices[0].message["content"]

# Main Workflow
pdf_path = "example.pdf"  # Replace with your PDF path
output_folder = "extracted_images"

# Step 1: Extract images from the PDF
extract_images_with_pymupdf(pdf_path, output_folder)

# Step 2: Convert extracted images to Base64
base64_images = images_to_base64(output_folder)

# Step 3: Call LLM with Base64-encoded images
response = call_llm_with_images(base64_images)

# Step 4: Print LLM Response
print("LLM Response:")
print(response)











import fitz  # PyMuPDF
import os

def extract_images_with_pymupdf(pdf_path, output_folder):
    # Ensure the output folder exists
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    doc = fitz.open(pdf_path)
    for page_number in range(len(doc)):
        page = doc[page_number]
        images = page.get_images(full=True)

        if not images:
            print(f"No images found on page {page_number + 1}")
            continue

        for img_index, img in enumerate(images):
            xref = img[0]
            base_image = doc.extract_image(xref)
            image_bytes = base_image["image"]
            image_ext = base_image["ext"]

            image_filename = os.path.join(
                output_folder, f"page_{page_number + 1}_{img_index + 1}.{image_ext}"
            )
            with open(image_filename, "wb") as image_file:
                image_file.write(image_bytes)
            print(f"Saved image: {image_filename}")

# Example Usage
pdf_path = "example.pdf"  # Replace with your PDF path
output_folder = "extracted_images"
extract_images_with_pymupdf(pdf_path, output_folder)









from pdfminer.pdfpage import PDFPage
from pdfminer.pdfparser import PDFParser
from pdfminer.pdfdocument import PDFDocument
from pdfminer.pdftypes import resolve1, stream_value
from PIL import Image
import os
import io

def extract_images_from_pdf(pdf_path, output_folder):
    # Ensure the output folder exists
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    # Open the PDF file
    with open(pdf_path, "rb") as file:
        parser = PDFParser(file)
        document = PDFDocument(parser)

        # Iterate through all pages in the PDF
        for page_number, page in enumerate(PDFPage.create_pages(document), start=1):
            resources = resolve1(page.resources)
            if resources and '/XObject' in resources:
                xobjects = resolve1(resources['/XObject'])
                for obj_name, obj in xobjects.items():
                    obj_resolved = resolve1(obj)
                    if obj_resolved.get('/Subtype') == '/Image':
                        try:
                            # Extract the image stream
                            image_stream = stream_value(obj_resolved)
                            image_data = image_stream.get_data()

                            # Get image properties
                            width = obj_resolved.get('/Width', 0)
                            height = obj_resolved.get('/Height', 0)
                            color_space = obj_resolved.get('/ColorSpace', '/DeviceRGB')

                            # Define image mode
                            mode = "RGB" if color_space == '/DeviceRGB' else "L"

                            # Convert image data to a PIL Image
                            image = Image.frombytes(mode, (width, height), image_data)

                            # Save the image
                            image_filename = os.path.join(
                                output_folder, f"page_{page_number}_{obj_name[1:]}.png"
                            )
                            image.save(image_filename)
                            print(f"Saved image: {image_filename}")
                        except Exception as e:
                            print(f"Error extracting image on page {page_number}: {e}")
            else:
                print(f"No XObject found on page {page_number}")

# Example Usage
pdf_path = "example.pdf"  # Replace with your PDF file path
output_folder = "extracted_images"
extract_images_from_pdf(pdf_path, output_folder)














import fitz

pdf_path = "example.pdf"  # Replace with your PDF path
doc = fitz.open(pdf_path)
for page_number in range(len(doc)):
    page = doc.load_page(page_number)
    pix = page.get_pixmap()
    print(f"Page {page_number + 1}: Width={pix.width}, Height={pix.height}")











from PIL import Image
import pytesseract
import fitz  # PyMuPDF
import os

# Configure Tesseract executable path (Windows only)
# pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"

def extract_text_from_pdf(pdf_path, output_folder):
    # Ensure the output folder exists
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    doc = fitz.open(pdf_path)
    for page_number in range(len(doc)):
        page = doc[page_number]
        pix = page.get_pixmap()  # Render the page as an image
        image_path = os.path.join(output_folder, f"page_{page_number + 1}.png")
        pix.save(image_path)  # Save the rendered image
        print(f"Saved image: {image_path}")

        # Use Tesseract to extract text
        extracted_text = pytesseract.image_to_string(Image.open(image_path))
        text_file = os.path.join(output_folder, f"page_{page_number + 1}.txt")
        with open(text_file, "w", encoding="utf-8") as f:
            f.write(extracted_text)
        print(f"Extracted text saved to: {text_file}")

# Example Usage
pdf_path = "example.pdf"  # Replace with your PDF file path
output_folder = "output"
extract_text_from_pdf(pdf_path, output_folder)









import fitz  # PyMuPDF
import os

def extract_images_with_pymupdf(pdf_path, output_folder):
    # Ensure the output folder exists
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    doc = fitz.open(pdf_path)
    for page_number in range(len(doc)):
        page = doc.load_page(page_number)
        images = page.get_images(full=True)

        for img_index, img in enumerate(images):
            xref = img[0]
            base_image = doc.extract_image(xref)
            image_bytes = base_image["image"]
            image_ext = base_image["ext"]

            image_filename = os.path.join(
                output_folder, f"image_page_{page_number + 1}_{img_index + 1}.{image_ext}"
            )
            with open(image_filename, "wb") as image_file:
                image_file.write(image_bytes)
            print(f"Saved image: {image_filename}")

# Example Usage
pdf_path = "example.pdf"  # Replace with your PDF file path
output_folder = "extracted_images"
extract_images_with_pymupdf(pdf_path, output_folder)








from pdfminer.pdfpage import PDFPage
from pdfminer.pdfparser import PDFParser
from pdfminer.pdfdocument import PDFDocument
from pdfminer.pdftypes import resolve1, stream_value
from PIL import Image
import os
import io

def extract_images_from_pdf(pdf_path, output_folder):
    # Ensure the output folder exists
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    # Open the PDF file
    with open(pdf_path, "rb") as file:
        parser = PDFParser(file)
        document = PDFDocument(parser)

        # Iterate through the pages in the PDF
        for page_number, page in enumerate(PDFPage.create_pages(document), start=1):
            resources = resolve1(page.resources)
            if resources and '/XObject' in resources:
                xobjects = resolve1(resources['/XObject'])
                for obj_name, obj in xobjects.items():
                    obj_resolved = resolve1(obj)
                    if obj_resolved.get('/Subtype') == '/Image':
                        try:
                            # Extract image data
                            image_stream = stream_value(obj_resolved)
                            image_data = image_stream.get_data()
                            width = obj_resolved.get('/Width', 0)
                            height = obj_resolved.get('/Height', 0)

                            # Ensure valid width and height
                            if width > 0 and height > 0:
                                # Determine the color space
                                color_space = obj_resolved.get('/ColorSpace', '/DeviceRGB')
                                mode = "RGB" if color_space == '/DeviceRGB' else "L"

                                # Save the image
                                image = Image.frombytes(mode, (width, height), image_data)
                                image_filename = os.path.join(
                                    output_folder,
                                    f"image_page_{page_number}_{obj_name}.png"
                                )
                                image.save(image_filename)
                                print(f"Saved image: {image_filename}")
                        except Exception as e:
                            print(f"Error processing image on page {page_number}: {e}")

# Example Usage
pdf_path = "example.pdf"  # Replace with your PDF file path
output_folder = "extracted_images"
extract_images_from_pdf(pdf_path, output_folder)










from pdfminer.pdfpage import PDFPage
from pdfminer.pdfparser import PDFParser
from pdfminer.pdfdocument import PDFDocument
from pdfminer.pdftypes import resolve1, stream_value
from PIL import Image
import os
import io

def extract_images_from_pdf(pdf_path, output_folder):
    # Create the output folder if it doesn't exist
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    # Open the PDF file
    with open(pdf_path, "rb") as file:
        parser = PDFParser(file)
        document = PDFDocument(parser)

        # Iterate through the pages in the PDF
        for page_number, page in enumerate(PDFPage.create_pages(document), start=1):
            resources = resolve1(page.resources)
            if resources and '/XObject' in resources:
                xobjects = resolve1(resources['/XObject'])
                for obj_name, obj in xobjects.items():
                    obj_resolved = resolve1(obj)
                    # Check if the object is an image
                    if obj_resolved.get('/Subtype') == '/Image':
                        # Extract image data
                        image_stream = stream_value(obj_resolved)
                        image_data = image_stream.get_data()
                        width = obj_resolved.get('/Width', 0)
                        height = obj_resolved.get('/Height', 0)

                        if width > 0 and height > 0:
                            # Determine the color space
                            color_space = obj_resolved.get('/ColorSpace', '/DeviceRGB')
                            mode = "RGB" if color_space == '/DeviceRGB' else "L"

                            # Save the image using Pillow
                            image = Image.frombytes(mode, (width, height), image_data)
                            image_filename = f"{output_folder}/image_page_{page_number}_{obj_name}.png"
                            image.save(image_filename)
                            print(f"Saved image: {image_filename}")

# Example Usage
pdf_path = "example.pdf"  # Replace with your PDF file
output_folder = "extracted_images"
extract_images_from_pdf(pdf_path, output_folder)













from pdfminer.pdfpage import PDFPage
from pdfminer.pdfparser import PDFParser
from pdfminer.pdfdocument import PDFDocument
from pdfminer.pdftypes import resolve1, stream_value
from PIL import Image
import os
import io

def extract_images_from_pdf(pdf_path, output_folder):
    # Create the output folder if it doesn't exist
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    # Open the PDF file
    with open(pdf_path, "rb") as file:
        parser = PDFParser(file)
        document = PDFDocument(parser)

        # Iterate through the pages in the PDF
        for page_number, page in enumerate(PDFPage.create_pages(document), start=1):
            resources = resolve1(page.resources)
            if resources and 'XObject' in resources:
                xobjects = resolve1(resources['XObject'])
                for obj_name, obj in xobjects.items():
                    obj_resolved = resolve1(obj)
                    if obj_resolved['/Subtype'] == '/Image':
                        # Extract image data
                        image_stream = stream_value(obj_resolved)
                        image_data = image_stream.get_data()
                        width = obj_resolved['/Width']
                        height = obj_resolved['/Height']

                        # Determine the color space
                        color_space = obj_resolved.get('/ColorSpace', '/DeviceRGB')
                        mode = "RGB" if color_space == '/DeviceRGB' else "L"

                        # Save the image using Pillow
                        image = Image.frombytes(mode, (width, height), image_data)
                        image_filename = f"{output_folder}/image_page_{page_number}_{obj_name}.png"
                        image.save(image_filename)
                        print(f"Saved image: {image_filename}")

# Example Usage
pdf_path = "example.pdf"  # Replace with your PDF file
output_folder = "extracted_images"
extract_images_from_pdf(pdf_path, output_folder)














from pdfminer.pdfpage import PDFPage
from pdfminer.pdfparser import PDFParser
from pdfminer.pdfdocument import PDFDocument
from pdfminer.pdftypes import resolve1
from PIL import Image
import os
import io

def extract_images_from_pdf(pdf_path, output_folder):
    # Create the output folder if it doesn't exist
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    # Open the PDF file
    with open(pdf_path, "rb") as file:
        parser = PDFParser(file)
        document = PDFDocument(parser)

        # Check for image objects in the PDF
        for page_number, page in enumerate(PDFPage.create_pages(document), start=1):
            resources = resolve1(page.resources)
            if resources and 'XObject' in resources:
                xobjects = resolve1(resources['XObject'])
                for obj_name, obj in xobjects.items():
                    if obj.get('Subtype') == '/Image':
                        # Extract image data
                        image_data = obj.get_data()
                        width = obj.get('Width')
                        height = obj.get('Height')

                        # Handle different color spaces
                        color_space = obj.get('ColorSpace')
                        if color_space == '/DeviceRGB':
                            mode = "RGB"
                        elif color_space == '/DeviceGray':
                            mode = "L"
                        else:
                            mode = "P"

                        # Save the image using Pillow
                        image = Image.frombytes(mode, (width, height), image_data)
                        image_filename = f"{output_folder}/image_page_{page_number}_{obj_name[1:]}.png"
                        image.save(image_filename)
                        print(f"Saved image: {image_filename}")

# Example Usage
pdf_path = "example.pdf"  # Replace with your PDF file
output_folder = "extracted_images"
extract_images_from_pdf(pdf_path, output_folder)

















from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.chat_models import AzureChatOpenAI

def process_ocr_with_gpt4(content_dict, prompt_template, azure_openai_api_version, azure_openai_endpoint):
    """
    Process a dictionary of OCR text with GPT-4.

    Parameters:
        content_dict (dict): A dictionary where keys are page numbers and values are OCR text.
        prompt_template (str): The prompt template for GPT-4.
        azure_openai_api_version (str): Azure OpenAI API version.
        azure_openai_endpoint (str): Azure OpenAI endpoint URL.

    Returns:
        dict: A dictionary with the same keys, but values are the formatted text.
    """
    if not isinstance(content_dict, dict):
        raise ValueError("The input should be a dictionary where keys are page numbers and values are OCR text.")

    # Initialize the Azure OpenAI model
    llm = AzureChatOpenAI(
        temperature=0,
        api_version=azure_openai_api_version,
        azure_endpoint=azure_openai_endpoint
    )

    # Prepare the prompt template
    prompt = PromptTemplate(template=prompt_template, input_variables=["content"])

    # Initialize the LLM chain
    llm_chain = LLMChain(llm=llm, prompt=prompt)

    # Dictionary to store formatted results
    formatted_content_dict = {}

    # Process each page's content
    for page_number, ocr_text in content_dict.items():
        try:
            if not isinstance(ocr_text, str):
                raise ValueError(f"Value for page {page_number} must be a string.")
            
            # Use the LLM chain to format the OCR text
            formatted_text = llm_chain.predict(content=ocr_text)
            formatted_content_dict[page_number] = formatted_text
        except Exception as e:
            print(f"Error formatting content for page {page_number} with GPT-4: {e}")
            formatted_content_dict[page_number] = f"Error: {e}"

    return formatted_content_dict










from langchain.chains import LLMChain

def process_ocr_with_gpt4(ocr_text_by_page, prompt_template, llm):
    formatted_ocr_by_page = {}

    # Process each page's OCR text with GPT-4
    for page_num, ocr_text in ocr_text_by_page.items():
        if not ocr_text.strip():  # Skip empty OCR text
            continue

        try:
            # Create the prompt template
            prompt = PromptTemplate(template=prompt_template, input_variables=["content"])

            # Initialize the LLMChain with the LLM and the prompt
            llm_chain = LLMChain(llm=llm, prompt=prompt)

            # Format the OCR text using GPT-4
            formatted_ocr_text = llm_chain.predict(content=ocr_text)

            # Save the formatted text by page
            formatted_ocr_by_page[page_num] = formatted_ocr_text

        except Exception as e:
            print(f"Error formatting OCR text for Page {page_num} with GPT-4: {e}")
            formatted_ocr_by_page[page_num] = f"Error formatting OCR text: {e}"

    return formatted_ocr_by_page









import fitz  # PyMuPDF
import pdfplumber
from PIL import Image
import pytesseract
import io

def extract_text_from_pdf(pdf_path):
    final_text = ""  # Combined text for all pages
    ocr_text_by_page = {}  # Store OCR-specific text by page number

    try:
        with fitz.open(pdf_path) as doc:
            for page_num in range(len(doc)):
                page_text = ""

                # Step 1: Extract text using PyMuPDF
                try:
                    page = doc.load_page(page_num)
                    pymupdf_text = page.get_text("text")
                    page_text += pymupdf_text or ""
                except Exception as e:
                    print(f"PyMuPDF Error on Page {page_num + 1}: {e}")

                # Step 2: Extract text and tables using pdfplumber
                try:
                    with pdfplumber.open(pdf_path) as pdf:
                        page_plumber = pdf.pages[page_num]
                        pdfplumber_text = page_plumber.extract_text()
                        page_text += pdfplumber_text or ""

                        # Extract table data
                        tables = page_plumber.extract_tables()
                        if tables:
                            for table in tables:
                                for row in table:
                                    row_text = " | ".join(
                                        str(cell) if not isinstance(cell, list) else " ".join(map(str, cell))
                                        for cell in row
                                    )
                                    page_text += "\n" + row_text
                except Exception as e:
                    print(f"pdfplumber Error on Page {page_num + 1}: {e}")

                # Step 3: Perform OCR extraction for images
                try:
                    for img_index, img in enumerate(page.get_images(full=True)):
                        xref = img[0]
                        base_image = doc.extract_image(xref)
                        image_bytes = base_image["image"]
                        try:
                            image = Image.open(io.BytesIO(image_bytes))
                            ocr_page_text = pytesseract.image_to_string(image)
                            page_text += "\n" + ocr_page_text  # Add OCR text to the current page
                            if page_num + 1 not in ocr_text_by_page:
                                ocr_text_by_page[page_num + 1] = ""
                            ocr_text_by_page[page_num + 1] += ocr_page_text  # Store OCR text by page
                        except Exception as e:
                            print(f"OCR Error on Page {page_num + 1}, Image {img_index + 1}: {e}")
                except Exception as e:
                    print(f"OCR Extraction Error on Page {page_num + 1}: {e}")

                # Append the combined content of the current page
                if page_text.strip():
                    final_text += f"\n--- Page {page_num + 1} ---\n{page_text}\n"

    except Exception as e:
        print(f"Error processing the PDF: {e}")

    return final_text, ocr_text_by_page  # Return combined text and OCR-specific text by page



from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

def process_ocr_with_gpt4(ocr_text_by_page, prompt_template, llm):
    formatted_ocr_by_page = {}

    # Process each page's OCR text with GPT-4
    for page_num, ocr_text in ocr_text_by_page.items():
        if not ocr_text.strip():
            continue

        # Create the prompt template
        prompt = PromptTemplate(template=prompt_template, input_variables=["content"])

        # Initialize the LLMChain with the LLM and the prompt
        llm_chain = LLMChain(llm=llm, prompt=prompt)

        # Use GPT-4 to format the OCR text
        try:
            formatted_ocr_text = llm_chain.predict(content=ocr_text)
            formatted_ocr_by_page[page_num] = formatted_ocr_text
        except Exception as e:
            print(f"Error formatting OCR text for Page {page_num} with GPT-4: {e}")

    return formatted_ocr_by_page  # Return formatted OCR text by page




def combine_text_with_formatting(full_text, formatted_ocr_by_page):
    combined_text = ""  # Start with an empty string
    pages = full_text.split("\n--- Page ")  # Split full text by pages

    for page in pages:
        if not page.strip():
            continue

        # Extract the page number and content
        header, page_content = page.split("---\n", 1)
        page_num = int(header.strip())

        # Add the formatted OCR content for the current page
        if page_num in formatted_ocr_by_page:
            page_content += f"\n\n--- Formatted OCR Content ---\n{formatted_ocr_by_page[page_num]}"

        # Append the processed page back to the combined text
        combined_text += f"\n--- Page {page_num} ---\n{page_content}"

    return combined_text

# Define the PDF path
pdf_path = "path/to/your/pdf/document.pdf"

# Define the GPT-4 prompt template
prompt_template = """
You are a document formatter. Your task is to organize the following extracted OCR text into a structured and readable format.

Output the formatted content:
{content}
"""

# Initialize the LLM (GPT-4)
llm = OpenAI(
    temperature=0.7,
    api_version="your_api_version",
    azure_endpoint="your_azure_endpoint"
)

# Step 1: Extract text
full_text, ocr_text_by_page = extract_text_from_pdf(pdf_path)

# Step 2: Format OCR text with GPT-4
formatted_ocr_by_page = process_ocr_with_gpt4(ocr_text_by_page, prompt_template, llm)

# Step 3: Combine all content
final_output = combine_text_with_formatting(full_text, formatted_ocr_by_page)









from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.llms import OpenAI

# Initialize the OpenAI model (GPT-4) with appropriate parameters
llm = OpenAI(temperature=0.7, api_version="your_api_version", azure_endpoint="your_azure_endpoint")

# Define the prompt template
prompt_template = """
You are a document formatter. Your task is to organize the following extracted OCR text into a structured and readable format.

Output the formatted content:
{content}
"""

# Define the function to generate questions or organize content
def generate_questions(content, prompt_template):
    # Check if the content is a string
    if not isinstance(content, str):
        raise ValueError("The content should be a string.")

    # Create the prompt template using LangChain's PromptTemplate
    prompt = PromptTemplate(template=prompt_template, input_variables=["content"])

    # Initialize the LLMChain with the LLM and the prompt
    llm_chain = LLMChain(llm=llm, prompt=prompt)

    try:
        # Ensure that the content is passed correctly
        response = llm_chain.predict(content=content)
        return response  # return the formatted content or response
    except Exception as e:
        print(f"Error formatting with GPT-4: {e}")
        return None

# Example usage
content = "This is the OCR-extracted content from your document."
formatted_content = generate_questions(content, prompt_template)
print(formatted_content)











import fitz  # PyMuPDF
import pdfplumber
from PIL import Image
import pytesseract
import io
import openai

# Azure OpenAI credentials
AZURE_OPENAI_API_KEY = "your_azure_openai_api_key"  # Replace with your Azure API key
AZURE_OPENAI_ENDPOINT = "your_azure_endpoint"       # Replace with your Azure endpoint
AZURE_OPENAI_DEPLOYMENT_ID = "gpt4-deployment-id"   # Replace with your GPT-4 deployment ID

# Set the path to Tesseract executable
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"  # Adjust for your setup


def extract_text_from_pdf(pdf_path):
    """
    Extract text, tables, and images from a PDF file.
    
    Args:
        pdf_path (str): Path to the PDF file.
    
    Returns:
        str: Extracted content from the PDF.
    """
    final_text = ""

    print("Starting extraction...")
    try:
        with fitz.open(pdf_path) as doc:
            for page_num in range(len(doc)):
                print(f"Processing Page {page_num + 1}...")
                page_text = ""

                # 1. Extract text using PyMuPDF
                try:
                    page = doc.load_page(page_num)
                    pymupdf_text = page.get_text("text")
                    page_text += pymupdf_text or ""
                except Exception as e:
                    print(f"PyMuPDF Error on Page {page_num + 1}: {e}")

                # 2. Extract text using pdfplumber
                try:
                    with pdfplumber.open(pdf_path) as pdf:
                        page_plumber = pdf.pages[page_num]
                        pdfplumber_text = page_plumber.extract_text()
                        page_text += pdfplumber_text or ""

                        # Extract table data if available
                        table = page_plumber.extract_tables()
                        if table:
                            for row in table:
                                row_text = " | ".join(
                                    str(cell) if not isinstance(cell, list) else " ".join(map(str, cell))
                                    for cell in row
                                )
                                page_text += "\n" + row_text
                except Exception as e:
                    print(f"pdfplumber Error on Page {page_num + 1}: {e}")

                # 3. Perform OCR extraction from images
                try:
                    for img_index, img in enumerate(page.get_images(full=True)):
                        xref = img[0]
                        base_image = doc.extract_image(xref)
                        image_bytes = base_image["image"]
                        try:
                            image = Image.open(io.BytesIO(image_bytes))
                            ocr_text = pytesseract.image_to_string(image)
                            page_text += "\n" + ocr_text
                        except Exception as e:
                            print(f"OCR Error on Page {page_num + 1}, Image {img_index + 1}: {e}")
                except Exception as e:
                    print(f"OCR Extraction Error on Page {page_num + 1}: {e}")

                # Append the page content to the final output
                if page_text.strip():
                    final_text += f"\n--- Page {page_num + 1} ---\n{page_text}\n"
                else:
                    print(f"No content found on Page {page_num + 1}")

    except Exception as e:
        print(f"Error processing the PDF: {e}")

    return final_text


def format_with_gpt4(content):
    """
    Format extracted content using GPT-4.
    
    Args:
        content (str): The raw text content to format.
    
    Returns:
        str: The formatted content.
    """
    openai.api_key = AZURE_OPENAI_API_KEY
    openai.api_type = "azure"
    openai.api_base = AZURE_OPENAI_ENDPOINT
    openai.api_version = "2023-03-15-preview"  # Use the appropriate version for your setup

    # GPT-4 prompt to format content
    prompt = f"""
    You are a document formatter. Your task is to organize the following extracted OCR text into a structured and readable format with proper headings, sections, and tables if applicable:

    {content}

    Output the formatted content:
    """

    try:
        response = openai.ChatCompletion.create(
            engine=AZURE_OPENAI_DEPLOYMENT_ID,
            messages=[
                {"role": "system", "content": "You are an expert formatter."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=3000,
            temperature=0.3
        )
        return response['choices'][0]['message']['content']
    except Exception as e:
        print(f"Error formatting with GPT-4: {e}")
        return None















import fitz  # PyMuPDF
import pdfplumber
from PIL import Image
import pytesseract
import io
import sys

# Set the path to the Tesseract executable
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"

def extract_text_from_pdf(pdf_path):
    final_text = ""

    print("Starting extraction...")
    try:
        with fitz.open(pdf_path) as doc:
            for page_num in range(len(doc)):
                print(f"Processing Page {page_num + 1}...")
                page_text = ""
                
                # 1. Extract text using PyMuPDF
                try:
                    page = doc.load_page(page_num)
                    pymupdf_text = page.get_text("text")
                    page_text += pymupdf_text or ""
                except Exception as e:
                    print(f"PyMuPDF Error on Page {page_num + 1}: {e}")

                # 2. Extract text using pdfplumber
                try:
                    with pdfplumber.open(pdf_path) as pdf:
                        page_plumber = pdf.pages[page_num]
                        pdfplumber_text = page_plumber.extract_text()
                        page_text += pdfplumber_text or ""

                        # Extract table data if available
                        table = page_plumber.extract_tables()
                        if table:
                            for row in table:
                                # Convert each cell in the row to string and join with " | "
                                row_text = " | ".join(
                                    str(cell) if not isinstance(cell, list) else " ".join(map(str, cell))
                                    for cell in row
                                )
                                page_text += "\n" + row_text
                except Exception as e:
                    print(f"pdfplumber Error on Page {page_num + 1}: {e}")

                # 3. Perform OCR extraction from images
                try:
                    for img_index, img in enumerate(page.get_images(full=True)):
                        xref = img[0]
                        base_image = doc.extract_image(xref)
                        image_bytes = base_image["image"]
                        try:
                            image = Image.open(io.BytesIO(image_bytes))
                            ocr_text = pytesseract.image_to_string(image)
                            page_text += "\n" + ocr_text
                        except Exception as e:
                            print(f"OCR Error on Page {page_num + 1}, Image {img_index + 1}: {e}")
                except Exception as e:
                    print(f"OCR Extraction Error on Page {page_num + 1}: {e}")

                # Append the page content to the final output
                if page_text.strip():
                    final_text += f"\n--- Page {page_num + 1} ---\n{page_text}\n"
                else:
                    print(f"No content found on Page {page_num + 1}")

    except Exception as e:
        print(f"Error processing the PDF: {e}")

    return final_text

# Usage
pdf_path = "path_to_pdf.pdf"  # Replace with the path to your PDF
pdf_text = extract_text_from_pdf(pdf_path)
print("\nFinal Extracted Text:\n", pdf_text)

# Optionally, save to a file
with open("extracted_text.txt", "w", encoding="utf-8") as f:
    f.write(pdf_text)










import fitz  # PyMuPDF
import pdfplumber
from PIL import Image
import pytesseract
import io
import sys

# Set the path to the Tesseract executable
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"

def extract_text_from_pdf(pdf_path):
    final_text = ""

    print("Starting extraction...")
    try:
        with fitz.open(pdf_path) as doc, pdfplumber.open(pdf_path) as pdf_plumber:
            for page_num in range(len(doc)):
                print(f"Processing Page {page_num + 1}...")
                page_text = ""
                
                # 1. Extract text using PyMuPDF
                try:
                    page = doc.load_page(page_num)
                    pymupdf_text = page.get_text("text")
                    page_text += pymupdf_text or ""
                except Exception as e:
                    print(f"PyMuPDF Error on Page {page_num + 1}: {e}")

                # 2. Extract text using pdfplumber
                try:
                    page_plumber = pdf_plumber.pages[page_num]
                    pdfplumber_text = page_plumber.extract_text()
                    page_text += pdfplumber_text or ""

                    # Extract table data if available
                    table = page_plumber.extract_tables()
                    if table:
                        for row in table:
                            row_text = " | ".join(row)
                            page_text += "\n" + row_text
                except Exception as e:
                    print(f"pdfplumber Error on Page {page_num + 1}: {e}")

                # 3. Perform OCR extraction from images
                try:
                    for img_index, img in enumerate(page.get_images(full=True)):
                        xref = img[0]
                        base_image = doc.extract_image(xref)
                        image_bytes = base_image["image"]
                        try:
                            image = Image.open(io.BytesIO(image_bytes))
                            ocr_text = pytesseract.image_to_string(image)
                            page_text += "\n" + ocr_text
                        except Exception as e:
                            print(f"OCR Error on Page {page_num + 1}, Image {img_index + 1}: {e}")
                except Exception as e:
                    print(f"OCR Extraction Error on Page {page_num + 1}: {e}")

                # Append the page content to the final output
                if page_text.strip():
                    final_text += f"\n--- Page {page_num + 1} ---\n{page_text}\n"
                else:
                    print(f"No content found on Page {page_num + 1}")

    except Exception as e:
        print(f"Error processing the PDF: {e}")

    return final_text

# Usage
pdf_path = "path_to_pdf.pdf"  # Replace with the path to your PDF
pdf_text = extract_text_from_pdf(pdf_path)
print("\nFinal Extracted Text:\n", pdf_text)

# Optionally, save to a file
with open("extracted_text.txt", "w", encoding="utf-8") as f:
    f.write(pdf_text)










import fitz  # PyMuPDF
import pdfplumber
from PIL import Image
import pytesseract
import io
import sys

# Set the path to the Tesseract executable
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"

def extract_text_from_pdf(pdf_path):
    final_text = ""

    print("Starting extraction...")
    try:
        with fitz.open(pdf_path) as doc, pdfplumber.open(pdf_path) as pdf_plumber:
            for page_num in range(len(doc)):
                print(f"Processing Page {page_num + 1}...")
                page_text = ""
                
                # 1. Extract text using PyMuPDF
                try:
                    page = doc.load_page(page_num)
                    pymupdf_text = page.get_text("text")
                    page_text += pymupdf_text or ""
                except Exception as e:
                    print(f"PyMuPDF Error on Page {page_num + 1}: {e}")

                # 2. Extract text using pdfplumber
                try:
                    page_plumber = pdf_plumber.pages[page_num]
                    pdfplumber_text = page_plumber.extract_text()
                    page_text += pdfplumber_text or ""

                    # Extract table data if available
                    table = page_plumber.extract_tables()
                    if table:
                        for row in table:
                            row_text = " | ".join(row)
                            page_text += "\n" + row_text
                except Exception as e:
                    print(f"pdfplumber Error on Page {page_num + 1}: {e}")

                # 3. Perform OCR extraction from images
                try:
                    for img_index, img in enumerate(page.get_images(full=True)):
                        xref = img[0]
                        base_image = doc.extract_image(xref)
                        image_bytes = base_image["image"]
                        try:
                            image = Image.open(io.BytesIO(image_bytes))
                            ocr_text = pytesseract.image_to_string(image)
                            page_text += "\n" + ocr_text
                        except Exception as e:
                            print(f"OCR Error on Page {page_num + 1}, Image {img_index + 1}: {e}")
                except Exception as e:
                    print(f"OCR Extraction Error on Page {page_num + 1}: {e}")

                # Append the page content to the final output
                if page_text.strip():
                    final_text += f"\n--- Page {page_num + 1} ---\n{page_text}\n"
                else:
                    print(f"No content found on Page {page_num + 1}")

    except Exception as e:
        print(f"Error processing the PDF: {e}")

    return final_text

# Usage
pdf_path = "path_to_pdf.pdf"  # Replace with the path to your PDF
pdf_text = extract_text_from_pdf(pdf_path)
print("\nFinal Extracted Text:\n", pdf_text)

# Optionally, save to a file
with open("extracted_text.txt", "w", encoding="utf-8") as f:
    f.write(pdf_text)








import fitz  # PyMuPDF
import pdfplumber
from PIL import Image
import pytesseract
import io
import sys

# Set the path to the Tesseract executable
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"

def extract_text_from_pdf(pdf_path):
    final_text = ""

    print("Starting extraction...")
    try:
        with fitz.open(pdf_path) as doc:
            for page_num in range(len(doc)):
                print(f"Processing Page {page_num + 1}...")
                page_text = ""
                
                # 1. Extract text using PyMuPDF
                try:
                    page = doc.load_page(page_num)
                    pymupdf_text = page.get_text("text")
                    page_text += pymupdf_text or ""
                except Exception as e:
                    print(f"PyMuPDF Error on Page {page_num + 1}: {e}")

                # 2. Extract text using pdfplumber
                try:
                    with pdfplumber.open(pdf_path) as pdf:
                        page_plumber = pdf.pages[page_num]
                        pdfplumber_text = page_plumber.extract_text()
                        page_text += pdfplumber_text or ""

                        # Extract table data if available
                        table = page_plumber.extract_tables()
                        if table:
                            for row in table:
                                row_text = " | ".join(row)
                                page_text += "\n" + row_text
                except Exception as e:
                    print(f"pdfplumber Error on Page {page_num + 1}: {e}")

                # 3. Perform OCR extraction from images
                try:
                    for img_index, img in enumerate(page.get_images(full=True)):
                        xref = img[0]
                        base_image = doc.extract_image(xref)
                        image_bytes = base_image["image"]
                        try:
                            image = Image.open(io.BytesIO(image_bytes))
                            ocr_text = pytesseract.image_to_string(image)
                            page_text += "\n" + ocr_text
                        except Exception as e:
                            print(f"OCR Error on Page {page_num + 1}, Image {img_index + 1}: {e}")
                except Exception as e:
                    print(f"OCR Extraction Error on Page {page_num + 1}: {e}")

                # Append the page content to the final output
                if page_text.strip():
                    final_text += f"\n--- Page {page_num + 1} ---\n{page_text}\n"
                else:
                    print(f"No content found on Page {page_num + 1}")

    except Exception as e:
        print(f"Error processing the PDF: {e}")

    return final_text

# Usage
pdf_path = "path_to_pdf.pdf"  # Replace with the path to your PDF
pdf_text = extract_text_from_pdf(pdf_path)
print("\nFinal Extracted Text:\n", pdf_text)

# Optionally, save to a file
with open("extracted_text.txt", "w", encoding="utf-8") as f:
    f.write(pdf_text)











import fitz  # PyMuPDF
import pdfplumber
from PIL import Image  # Ensure this is included
import pytesseract
import io
import sys

pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"  # Adjust for your setup

def extract_text_from_pdf(pdf_path):
    pymupdf_text = ""
    pdfplumber_text = ""
    ocr_text = ""

    # 1. Extract text using PyMuPDF
    print("Starting PyMuPDF extraction...")
    try:
        with fitz.open(pdf_path) as doc:
            for page_num in range(len(doc)):
                page = doc.load_page(page_num)
                page_text = page.get_text("text")
                pymupdf_text += page_text or ""
                print(f"PyMuPDF Page {page_num + 1}:\n{page_text}")
    except Exception as e:
        print(f"PyMuPDF Error: {e}")

    # 2. Extract text using pdfplumber
    print("Starting pdfplumber extraction...")
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page_num, page in enumerate(pdf.pages):
                page_text = page.extract_text()
                pdfplumber_text += page_text or ""
                print(f"pdfplumber Page {page_num + 1}:\n{page_text}")
    except Exception as e:
        print(f"pdfplumber Error: {e}")

    # 3. Perform OCR extraction
    print("Starting OCR extraction...")
    try:
        with fitz.open(pdf_path) as doc:
            for page_num in range(len(doc)):
                page = doc.load_page(page_num)
                for img_index, img in enumerate(page.get_images(full=True)):
                    xref = img[0]
                    base_image = doc.extract_image(xref)
                    image_bytes = base_image["image"]
                    try:
                        image = Image.open(io.BytesIO(image_bytes))
                        extracted_text = pytesseract.image_to_string(image)
                        ocr_text += extracted_text or ""
                        print(f"OCR Page {page_num + 1}, Image {img_index + 1}:\n{extracted_text}")
                    except Exception as e:
                        print(f"OCR Error: {e}")
    except Exception as e:
        print(f"OCR Extraction Error: {e}")

    return pymupdf_text + pdfplumber_text + ocr_text

# Usage
pdf_path = "path_to_pdf.pdf"  # Update with your file path
result = extract_text_from_pdf(pdf_path)
print("Final Extracted Text:\n", result)









import fitz  # PyMuPDF
import pdfplumber
from PIL import Image
import pytesseract
import io
import sys

pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"

def extract_text_from_pdf(pdf_path):
    pymupdf_text = ""
    pdfplumber_text = ""
    ocr_text = ""

    # 1. Extract text using PyMuPDF
    print("Starting PyMuPDF extraction...")
    try:
        with fitz.open(pdf_path) as doc:
            for page_num in range(len(doc)):
                page = doc.load_page(page_num)
                page_text = page.get_text("text")
                pymupdf_text += page_text or ""
                print(f"PyMuPDF Page {page_num + 1}:\n{page_text}")
    except Exception as e:
        print(f"PyMuPDF Error: {e}")

    # 2. Extract text using pdfplumber
    print("Starting pdfplumber extraction...")
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page_num, page in enumerate(pdf.pages):
                page_text = page.extract_text()
                pdfplumber_text += page_text or ""
                print(f"pdfplumber Page {page_num + 1}:\n{page_text}")
    except Exception as e:
        print(f"pdfplumber Error: {e}")

    # 3. Perform OCR extraction
    print("Starting OCR extraction...")
    try:
        with fitz.open(pdf_path) as doc:
            for page_num in range(len(doc)):
                page = doc.load_page(page_num)
                for img_index, img in enumerate(page.get_images(full=True)):
                    xref = img[0]
                    base_image = doc.extract_image(xref)
                    image_bytes = base_image["image"]
                    try:
                        image = Image.open(io.BytesIO(image_bytes))
                        extracted_text = pytesseract.image_to_string(image)
                        ocr_text += extracted_text or ""
                        print(f"OCR Page {page_num + 1}, Image {img_index + 1}:\n{extracted_text}")
                    except Exception as e:
                        print(f"OCR Error: {e}")
    except Exception as e:
        print(f"OCR Extraction Error: {e}")

    return pymupdf_text + pdfplumber_text + ocr_text

# Usage
pdf_path = "path_to_pdf.pdf"  # Update with your file path
result = extract_text_from_pdf(pdf_path)
print("Final Extracted Text:\n", result)













import fitz  # PyMuPDF
import pdfplumber
from PIL import Image
import pytesseract
import io
import sys

# Set the path to the Tesseract executable (make sure it's properly set up)
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"  # Adjust for your setup

def extract_text_from_pdf(pdf_path):
    pymupdf_text = ""
    pdfplumber_text = ""
    ocr_text = ""

    # 1. Extract text from PDF using PyMuPDF (fitz)
    try:
        with fitz.open(pdf_path) as doc:
            for page_num in range(len(doc)):
                page = doc.load_page(page_num)
                page_text = page.get_text("text")
                pymupdf_text += page_text
                if page_text.strip():  # Print extracted text from PyMuPDF
                    print(f"Extracted text from page {page_num + 1} using PyMuPDF:\n{page_text}")
                    sys.stdout.flush()
    except Exception as e:
        print(f"Error extracting text with PyMuPDF: {e}")
        sys.stdout.flush()

    # 2. Extract text from PDF using pdfplumber
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page_num, page in enumerate(pdf.pages):
                page_text = page.extract_text()
                pdfplumber_text += page_text if page_text else ""
                if page_text.strip():  # Print extracted text from pdfplumber
                    print(f"Extracted text from page {page_num + 1} using pdfplumber:\n{page_text}")
                    sys.stdout.flush()

                # Extract table data if available
                table = page.extract_tables()
                if table:
                    print(f"Extracted table from page {page_num + 1}:")
                    for row in table:
                        row_text = " | ".join(row)
                        print(row_text)
                        pdfplumber_text += "\n" + row_text  # Append table data to full text
                    sys.stdout.flush()
    except Exception as e:
        print(f"Error extracting text with pdfplumber: {e}")
        sys.stdout.flush()

    # 3. Perform OCR extraction from images
    print("Attempting OCR extraction from images (this will run even if regular text was found)...")
    sys.stdout.flush()
    try:
        with fitz.open(pdf_path) as doc:
            for page_num in range(len(doc)):
                page = doc.load_page(page_num)
                for img_index, img in enumerate(page.get_images(full=True)):
                    xref = img[0]
                    base_image = doc.extract_image(xref)
                    image_bytes = base_image["image"]
                    image = Image.open(io.BytesIO(image_bytes))
                    
                    # Perform OCR on the image and collect the extracted text
                    extracted_text = pytesseract.image_to_string(image)
                    if extracted_text.strip():  # Check if OCR text was found
                        ocr_text += extracted_text
                        print(f"OCR text extracted from page {page_num + 1}, image {img_index + 1}:\n{extracted_text}")
                    else:
                        print(f"No OCR text found in image on page {page_num + 1}, image {img_index + 1}")
                    sys.stdout.flush()

    except Exception as e:
        print(f"Error extracting text using OCR: {e}")
        sys.stdout.flush()

    # Combine all extracted text
    full_text = pymupdf_text + pdfplumber_text + ocr_text
    return full_text

# Example usage
pdf_path = "path_to_pdf.pdf"  # Replace with the path to your PDF
pdf_text = extract_text_from_pdf(pdf_path)
print("\nFinal extracted text (including OCR and tables):\n", pdf_text)











import fitz  # PyMuPDF
import pdfplumber
from PIL import Image
import pytesseract
import io
import sys

# Set the path to the Tesseract executable (make sure it's properly set up)
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"  # Adjust for your setup

def extract_text_from_pdf(pdf_path):
    full_text = ""
    
    # 1. Extract text from PDF using PyMuPDF (fitz)
    try:
        with fitz.open(pdf_path) as doc:
            for page_num in range(len(doc)):
                page = doc.load_page(page_num)
                page_text = page.get_text("text")
                full_text += page_text
                if page_text.strip():  # Print extracted text from PyMuPDF
                    print(f"Extracted text from page {page_num + 1} using PyMuPDF:\n{page_text}")
                    sys.stdout.flush()
    except Exception as e:
        print(f"Error extracting text with PyMuPDF: {e}")
        sys.stdout.flush()

    # 2. Extract text from PDF using pdfplumber (to handle tables)
    if not full_text:  # Only try pdfplumber if no text was extracted yet
        try:
            with pdfplumber.open(pdf_path) as pdf:
                for page_num, page in enumerate(pdf.pages):
                    page_text = page.extract_text()
                    full_text += page_text
                    if page_text.strip():  # Print extracted text from pdfplumber
                        print(f"Extracted text from page {page_num + 1} using pdfplumber:\n{page_text}")
                        sys.stdout.flush()

                    # Extract table data if available
                    table = page.extract_tables()
                    if table:
                        print(f"Extracted table from page {page_num + 1}:")
                        for row in table:
                            row_text = " | ".join(row)
                            print(row_text)
                            full_text += "\n" + row_text  # Append table data to full text
                        sys.stdout.flush()
        except Exception as e:
            print(f"Error extracting text with pdfplumber: {e}")
            sys.stdout.flush()

    # 3. Perform OCR extraction from images (always attempt this, even if text is already found)
    print("Attempting OCR extraction from images (this will run even if regular text was found)...")
    sys.stdout.flush()
    ocr_text = ""
    try:
        with fitz.open(pdf_path) as doc:
            for page_num in range(len(doc)):
                page = doc.load_page(page_num)
                for img_index, img in enumerate(page.get_images(full=True)):
                    xref = img[0]
                    base_image = doc.extract_image(xref)
                    image_bytes = base_image["image"]
                    image = Image.open(io.BytesIO(image_bytes))
                    
                    # Perform OCR on the image and collect the extracted text
                    extracted_text = pytesseract.image_to_string(image)
                    if extracted_text.strip():  # Check if OCR text was found
                        ocr_text += extracted_text
                        print(f"OCR text extracted from page {page_num + 1}, image {img_index + 1}:\n{extracted_text}")
                    else:
                        print(f"No OCR text found in image on page {page_num + 1}, image {img_index + 1}")
                    sys.stdout.flush()

        # Append OCR text to the full text
        if ocr_text.strip():
            full_text += ocr_text
        else:
            print("No OCR text extracted.")
            sys.stdout.flush()

    except Exception as e:
        print(f"Error extracting text using OCR: {e}")
        sys.stdout.flush()

    return full_text

# Example usage
pdf_path = "path_to_pdf.pdf"  # Replace with the path to your PDF
pdf_text = extract_text_from_pdf(pdf_path)
print("\nFinal extracted text (including OCR and tables):\n", pdf_text)










import fitz  # PyMuPDF
import pdfplumber
from PIL import Image
import pytesseract
import io
import sys

# Set the path to the Tesseract executable (make sure it's properly set up)
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"  # Adjust for your setup

def extract_text_from_pdf(pdf_path):
    full_text = ""
    
    # 1. Extract text from PDF using PyMuPDF (fitz)
    try:
        with fitz.open(pdf_path) as doc:
            for page_num in range(len(doc)):
                page = doc.load_page(page_num)
                page_text = page.get_text("text")
                full_text += page_text
                if page_text.strip():  # Print extracted text from PyMuPDF
                    print(f"Extracted text from page {page_num + 1} using PyMuPDF:\n{page_text}")
                    sys.stdout.flush()
    except Exception as e:
        print(f"Error extracting text with PyMuPDF: {e}")
        sys.stdout.flush()

    # 2. Extract text from PDF using pdfplumber (to handle tables)
    if not full_text:  # Only try pdfplumber if no text was extracted yet
        try:
            with pdfplumber.open(pdf_path) as pdf:
                for page_num, page in enumerate(pdf.pages):
                    page_text = page.extract_text()
                    full_text += page_text
                    if page_text.strip():  # Print extracted text from pdfplumber
                        print(f"Extracted text from page {page_num + 1} using pdfplumber:\n{page_text}")
                        sys.stdout.flush()

                    # Extract table data if available
                    table = page.extract_tables()
                    if table:
                        print(f"Extracted table from page {page_num + 1}:")
                        for row in table:
                            row_text = " | ".join(row)
                            print(row_text)
                            full_text += "\n" + row_text  # Append table data to full text
                        sys.stdout.flush()
        except Exception as e:
            print(f"Error extracting text with pdfplumber: {e}")
            sys.stdout.flush()

    # 3. Perform OCR extraction from images (always attempt this, even if text is already found)
    print("Attempting OCR extraction from images (this will run even if regular text was found)...")
    sys.stdout.flush()
    ocr_text = ""
    try:
        with fitz.open(pdf_path) as doc:
            for page_num in range(len(doc)):
                page = doc.load_page(page_num)
                for img_index, img in enumerate(page.get_images(full=True)):
                    xref = img[0]
                    base_image = doc.extract_image(xref)
                    image_bytes = base_image["image"]
                    image = Image.open(io.BytesIO(image_bytes))
                    
                    # Perform OCR on the image and collect the extracted text
                    extracted_text = pytesseract.image_to_string(image)
                    if extracted_text.strip():  # Check if OCR text was found
                        ocr_text += extracted_text
                        print(f"OCR text extracted from page {page_num + 1}, image {img_index + 1}:\n{extracted_text}")
                    else:
                        print(f"No OCR text found in image on page {page_num + 1}, image {img_index + 1}")
                    sys.stdout.flush()

        # Append OCR text to the full text
        if ocr_text.strip():
            full_text += ocr_text
        else:
            print("No OCR text extracted.")
            sys.stdout.flush()

    except Exception as e:
        print(f"Error extracting text using OCR: {e}")
        sys.stdout.flush()

    return full_text

# Example usage
pdf_path = "path_to_pdf.pdf"  # Replace with the path to your PDF
pdf_text = extract_text_from_pdf(pdf_path)
print("\nFinal extracted text (including OCR and tables):\n", pdf_text)






import fitz  # PyMuPDF
import pdfplumber
from PIL import Image
import pytesseract
import io
import sys

# Set the path to the Tesseract executable (make sure it's properly set up)
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"  # Adjust for your setup

def extract_text_from_pdf(pdf_path):
    full_text = ""
    
    # 1. Extract text from PDF using PyMuPDF (fitz)
    try:
        with fitz.open(pdf_path) as doc:
            for page_num in range(len(doc)):
                page = doc.load_page(page_num)
                page_text = page.get_text("text")
                full_text += page_text
                if page_text.strip():  # Print extracted text from PyMuPDF
                    print(f"Extracted text from page {page_num + 1} using PyMuPDF:\n{page_text}")
                    sys.stdout.flush()
    except Exception as e:
        print(f"Error extracting text with PyMuPDF: {e}")
        sys.stdout.flush()

    # 2. Extract text from PDF using pdfplumber (to handle tables)
    if not full_text:  # Only try pdfplumber if no text was extracted yet
        try:
            with pdfplumber.open(pdf_path) as pdf:
                for page_num, page in enumerate(pdf.pages):
                    page_text = page.extract_text()
                    full_text += page_text
                    if page_text.strip():  # Print extracted text from pdfplumber
                        print(f"Extracted text from page {page_num + 1} using pdfplumber:\n{page_text}")
                        sys.stdout.flush()

                    # Extract table data if available
                    table = page.extract_tables()
                    if table:
                        print(f"Extracted table from page {page_num + 1}:")
                        for row in table:
                            row_text = " | ".join(row)
                            print(row_text)
                            full_text += "\n" + row_text  # Append table data to full text
                        sys.stdout.flush()
        except Exception as e:
            print(f"Error extracting text with pdfplumber: {e}")
            sys.stdout.flush()

    # 3. Perform OCR extraction from images (always attempt this, even if text is already found)
    print("Attempting OCR extraction from images (this will run even if regular text was found)...")
    sys.stdout.flush()
    ocr_text = ""
    try:
        with fitz.open(pdf_path) as doc:
            for page_num in range(len(doc)):
                page = doc.load_page(page_num)
                for img_index, img in enumerate(page.get_images(full=True)):
                    xref = img[0]
                    base_image = doc.extract_image(xref)
                    image_bytes = base_image["image"]
                    image = Image.open(io.BytesIO(image_bytes))
                    
                    # Perform OCR on the image and collect the extracted text
                    extracted_text = pytesseract.image_to_string(image)
                    if extracted_text.strip():  # Check if OCR text was found
                        ocr_text += extracted_text
                        print(f"OCR text extracted from page {page_num + 1}, image {img_index + 1}:\n{extracted_text}")
                    else:
                        print(f"No OCR text found in image on page {page_num + 1}, image {img_index + 1}")
                    sys.stdout.flush()

        # Append OCR text to the full text
        if ocr_text.strip():
            full_text += ocr_text
        else:
            print("No OCR text extracted.")
            sys.stdout.flush()

    except Exception as e:
        print(f"Error extracting text using OCR: {e}")
        sys.stdout.flush()

    return full_text

# Example usage
pdf_path = "path_to_pdf.pdf"  # Replace with the path to your PDF
pdf_text = extract_text_from_pdf(pdf_path)
print("\nFinal extracted text (including OCR and tables):\n", pdf_text)









import fitz  # PyMuPDF
import pdfplumber
from PIL import Image
import pytesseract
import io
import sys

# Set the path to the Tesseract executable (make sure it's properly set up)
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"  # Adjust for your setup

def extract_text_from_pdf(pdf_path):
    full_text = ""
    
    # 1. Extract text from PDF using PyMuPDF (fitz)
    try:
        with fitz.open(pdf_path) as doc:
            for page_num in range(len(doc)):
                page = doc.load_page(page_num)
                page_text = page.get_text("text")
                full_text += page_text
                if page_text.strip():  # Print extracted text from PyMuPDF
                    print(f"Extracted text from page {page_num + 1} using PyMuPDF:\n{page_text}")
                    sys.stdout.flush()
    except Exception as e:
        print(f"Error extracting text with PyMuPDF: {e}")
        sys.stdout.flush()

    # 2. Extract text from PDF using pdfplumber (to handle tables)
    if not full_text:  # Only try pdfplumber if no text was extracted yet
        try:
            with pdfplumber.open(pdf_path) as pdf:
                for page_num, page in enumerate(pdf.pages):
                    page_text = page.extract_text()
                    full_text += page_text
                    if page_text.strip():  # Print extracted text from pdfplumber
                        print(f"Extracted text from page {page_num + 1} using pdfplumber:\n{page_text}")
                        sys.stdout.flush()

                    # Extract table data if available
                    table = page.extract_tables()
                    if table:
                        print(f"Extracted table from page {page_num + 1}:")
                        for row in table:
                            row_text = " | ".join(row)
                            print(row_text)
                            full_text += "\n" + row_text  # Append table data to full text
                        sys.stdout.flush()
        except Exception as e:
            print(f"Error extracting text with pdfplumber: {e}")
            sys.stdout.flush()

    # 3. If no text found, extract OCR text from images (using pytesseract)
    if not full_text:
        print("No regular text found, attempting OCR extraction from images...")
        sys.stdout.flush()
        ocr_text = ""
        try:
            with fitz.open(pdf_path) as doc:
                for page_num in range(len(doc)):
                    page = doc.load_page(page_num)
                    for img_index, img in enumerate(page.get_images(full=True)):
                        xref = img[0]
                        base_image = doc.extract_image(xref)
                        image_bytes = base_image["image"]
                        image = Image.open(io.BytesIO(image_bytes))
                        
                        # Perform OCR on the image and collect the extracted text
                        extracted_text = pytesseract.image_to_string(image)
                        if extracted_text.strip():  # Check if OCR text was found
                            ocr_text += extracted_text
                            print(f"OCR text extracted from page {page_num + 1}, image {img_index + 1}:\n{extracted_text}")
                        else:
                            print(f"No OCR text found in image on page {page_num + 1}, image {img_index + 1}")
                        sys.stdout.flush()

            # Append OCR text to the main text variable
            if ocr_text.strip():
                full_text += ocr_text
            else:
                print("No OCR text extracted.")
                sys.stdout.flush()

        except Exception as e:
            print(f"Error extracting text using OCR: {e}")
            sys.stdout.flush()

    return full_text

# Example usage
pdf_path = "path_to_pdf.pdf"  # Replace with the path to your PDF
pdf_text = extract_text_from_pdf(pdf_path)
print("\nFinal extracted text (including OCR and tables):\n", pdf_text)











https://github.com/UB-Mannheim/tesseract/wiki



import fitz  # PyMuPDF
from PIL import Image
import pytesseract
import io
import sys

# Function to extract OCR text from images in the PDF
def extract_ocr_from_pdf(pdf_path):
    ocr_text = ""
    print("Attempting OCR extraction from images...")

    try:
        with fitz.open(pdf_path) as doc:
            for page_num in range(len(doc)):
                page = doc.load_page(page_num)
                # Extract images
                for img_index, img in enumerate(page.get_images(full=True)):
                    xref = img[0]
                    base_image = doc.extract_image(xref)
                    image_bytes = base_image["image"]
                    image = Image.open(io.BytesIO(image_bytes))
                    
                    # Perform OCR on the image and collect the extracted text
                    extracted_text = pytesseract.image_to_string(image)
                    if extracted_text.strip():  # Check if any OCR text was found
                        ocr_text += extracted_text
                        print(f"OCR text extracted from page {page_num + 1}, image {img_index + 1}:\n{extracted_text}")
                    else:
                        print(f"No OCR text found in image on page {page_num + 1}, image {img_index + 1}")
                    sys.stdout.flush()

        if ocr_text.strip():
            print("\nFinal OCR extracted text:\n")
            print(ocr_text)  # Print the full OCR text if any was extracted
        else:
            print("No OCR text extracted from any images.")
        
    except Exception as e:
        print(f"Error extracting text using OCR: {e}")
        sys.stdout.flush()

# Example usage
pdf_path = "path_to_pdf.pdf"  # Replace with the path to your PDF
extract_ocr_from_pdf(pdf_path)










import os
import fitz  # PyMuPDF
import pdfplumber
from PIL import Image
import pytesseract
import openpyxl

def extract_text_from_pdf(pdf_path):
    text = ""
    
    # Try to extract text from the PDF using PyMuPDF (fitz)
    try:
        with fitz.open(pdf_path) as doc:
            for page in doc:
                text += page.get_text("text")
    except Exception as e:
        print(f"Error extracting text with PyMuPDF: {e}")
    
    # If PyMuPDF doesn't work, try pdfplumber for better handling of tables and text
    if not text:
        try:
            with pdfplumber.open(pdf_path) as pdf:
                for page in pdf.pages:
                    text += page.extract_text()
        except Exception as e:
            print(f"Error extracting text with pdfplumber: {e}")
    
    # If text is still empty, use OCR (pytesseract) to extract text from images within the PDF
    if not text:
        try:
            with fitz.open(pdf_path) as doc:
                for page_num in range(len(doc)):
                    page = doc.load_page(page_num)
                    # Extract images
                    for img_index, img in enumerate(page.get_images(full=True)):
                        xref = img[0]
                        base_image = doc.extract_image(xref)
                        image_bytes = base_image["image"]
                        image = Image.open(io.BytesIO(image_bytes))
                        text += pytesseract.image_to_string(image)
        except Exception as e:
            print(f"Error extracting text using OCR: {e}")
    
    return text

def generate_questions_by_all_types(text, total_questions, chunk_size):
    # Dummy function for generating questions
    # Replace with your own logic
    return [{"question": f"Question {i}", "answer": "Sample answer"} for i in range(1, total_questions+1)]

def save_to_excel(questions_and_answers, output_file):
    # Save the questions and answers to an Excel file
    wb = openpyxl.Workbook()
    ws = wb.active
    ws.append(["Question", "Answer"])

    for qa in questions_and_answers:
        ws.append([qa["question"], qa["answer"]])
    
    wb.save(output_file)

def process_pdfs(root_directory, output_folder, total_questions=5, chunk_size=500):
    for dirpath, _, filenames in os.walk(root_directory):
        for filename in filenames:
            if filename.endswith('.pdf'):
                pdf_path = os.path.join(dirpath, filename)
                try:
                    print(f"Processing: {pdf_path}")
                    # Extract text from the PDF
                    pdf_text = extract_text_from_pdf(pdf_path)

                    # Generate questions
                    questions_and_answers = generate_questions_by_all_types(pdf_text, total_questions, chunk_size)

                    # Save results to Excel
                    relative_path = os.path.relpath(pdf_path, root_directory)
                    output_file = os.path.join(output_folder, relative_path.replace(".pdf", "_questions.xlsx"))

                    # Ensure the subdirectory structure in the output folder
                    os.makedirs(os.path.dirname(output_file), exist_ok=True)
                    save_to_excel(questions_and_answers, output_file)
                except Exception as e:
                    print(f"Error processing {pdf_path}: {e}")

# Example usage
root_directory = "path_to_pdf_folder"
output_folder = "path_to_output_folder"
process_pdfs(root_directory, output_folder)












import os
import time
import signal
import sys
import PyPDF2
import pandas as pd
import json
import tiktoken
from langchain.prompts.prompt import PromptTemplate
from langchain.chains import LLMChain
from langchain.chat_models import AzureChatOpenAI
import logging

# Configure logging
logging.basicConfig(
    filename="batch_processing.log",
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)

def log_info(message):
    logging.info(message)
    print(message)

def log_error(message):
    logging.error(message)
    print(message)

# Function to calculate tokens using tiktoken
def calculate_tokens(text, model="gpt-4"):
    try:
        if model in ["gpt-3.5-turbo", "gpt-4"]:
            encoding = tiktoken.get_encoding("cl100k_base")
        elif model == "text-davinci-003":
            encoding = tiktoken.get_encoding("p50k_base")
        else:
            raise ValueError(f"Unsupported model: {model}")
        return len(encoding.encode(text))
    except Exception as e:
        log_error(f"Error calculating tokens: {e}")
        return 0

# Function to extract text from a PDF
def extract_text_from_pdf(pdf_path):
    text = ""
    try:
        with open(pdf_path, 'rb') as file:
            reader = PyPDF2.PdfReader(file)
            for page in reader.pages:
                text += page.extract_text()
    except Exception as e:
        log_error(f"Error extracting text from {pdf_path}: {e}")
    return text

# Function to divide items into batches
def divide_into_batches(items, batch_size):
    for i in range(0, len(items), batch_size):
        yield items[i:i + batch_size]

# Prompts for question generation
FACTUAL_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate up to {num_questions} distinct factual question-answer pairs based on the input text.

    Ensure:
    - Questions focus on specific details, names, titles, or entities mentioned in the input text.
    - Questions and answers must be distinct, unique, and not repeated.

    Input Text: {paragraph}
"""

PROCEDURAL_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate up to {num_questions} distinct procedural question-answer pairs based on the input text.

    Ensure:
    - Questions focus on processes, methods, or sequences of steps.
    - Answers provide detailed, step-by-step instructions.
    - Questions and answers must be distinct, unique, and not repeated.

    Input Text: {paragraph}
"""

REASONING_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate up to {num_questions} distinct reasoning-based question-answer pairs based on the input text.

    Ensure:
    - All questions begin with "Why".
    - Questions require logical argumentation, critical thinking, or evaluation.
    - Questions and answers must be distinct, unique, and not repeated.

    Input Text: {paragraph}
"""

# Function to generate questions for a batch of paragraphs
def generate_questions_for_batch(paragraphs, total_questions_per_paragraph, chunk_size=10):
    question_types_and_prompts = {
        "Factual": FACTUAL_PROMPT,
        "Procedural": PROCEDURAL_PROMPT,
        "Reasoning-based": REASONING_PROMPT,
    }

    all_questions = []

    for question_type, prompt in question_types_and_prompts.items():
        for i, paragraph in enumerate(paragraphs):
            log_info(f"Processing {question_type} questions for paragraph {i + 1}/{len(paragraphs)}...")
            try:
                llm = AzureChatOpenAI(
                    temperature=0,
                    azure_openai_api_base="https://<your-endpoint>.openai.azure.com/",
                    deployment_name="gpt4-0",
                    api_version="2023-06-01-preview"
                )

                prompt_template = PromptTemplate(
                    input_variables=["paragraph", "num_questions"],
                    template=prompt
                )

                llm_chain = LLMChain(llm=llm, prompt=prompt_template)
                response = llm_chain.predict(paragraph=paragraph, num_questions=str(total_questions_per_paragraph))
                questions = json.loads(response)

                for qa in questions:
                    question_text = qa["question"]
                    answer_text = qa["answer"]
                    all_questions.append({
                        "Question Type": question_type,
                        "Question": question_text,
                        "Answer": answer_text,
                        "Question Length (Chars)": len(question_text),
                        "Answer Length (Chars)": len(str(answer_text)),
                        "Question Tokens": calculate_tokens(question_text),
                        "Answer Tokens": calculate_tokens(answer_text)
                    })
            except Exception as e:
                log_error(f"Error processing {question_type} questions for paragraph {i + 1}: {e}")
    return all_questions

# Function to save results to Excel
def save_to_excel(questions_and_answers, output_file):
    if questions_and_answers:
        df = pd.DataFrame(questions_and_answers)
        df.to_excel(output_file, index=False)
        log_info(f"Questions and answers saved to {output_file}.")
    else:
        log_info(f"No data to save for {output_file}.")

# Function to continuously monitor and process PDFs
def monitor_and_process(root_directory, batch_size=5, total_questions=10, chunk_size=10, output_folder="output", interval=300):
    log_info("Starting continuous monitoring...")
    processed_files = set()

    while True:
        try:
            pdf_files = []
            for dirpath, _, filenames in os.walk(root_directory):
                for filename in filenames:
                    if filename.endswith('.pdf'):
                        pdf_files.append(os.path.join(dirpath, filename))

            new_files = [f for f in pdf_files if f not in processed_files]

            if new_files:
                log_info(f"Found {len(new_files)} new files. Processing...")
                pdf_batches = list(divide_into_batches(new_files, batch_size))

                for batch_index, batch in enumerate(pdf_batches):
                    log_info(f"Processing batch {batch_index + 1}/{len(pdf_batches)}...")
                    paragraphs = [extract_text_from_pdf(pdf_path) for pdf_path in batch]
                    batch_questions = generate_questions_for_batch(paragraphs, total_questions, chunk_size)
                    batch_output_file = os.path.join(output_folder, f"batch_{batch_index + 1}_questions.xlsx")
                    save_to_excel(batch_questions, batch_output_file)

                processed_files.update(new_files)
            else:
                log_info("No new files found.")

        except Exception as e:
            log_error(f"Error during monitoring: {e}")

        time.sleep(interval)

# Graceful shutdown
def graceful_shutdown(signal_received, frame):
    log_info("Shutting down gracefully...")
    sys.exit(0)

signal.signal(signal.SIGINT, graceful_shutdown)
signal.signal(signal.SIGTERM, graceful_shutdown)

# Main execution
if __name__ == "__main__":
    root_directory = "path/to/pdf/folder"
    output_folder = "path/to/output/folder"
    batch_size = 5
    total_questions = 10
    chunk_size = 10
    interval = 300

    monitor_and_process(root_directory, batch_size, total_questions, chunk_size, output_folder, interval)
















import json

def json_to_text(json_obj):
    # Convert JSON object to a human-readable text format
    text = ""
    for key, value in json_obj.items():
        if isinstance(value, dict):  # Handle nested dictionaries
            text += f"{key}:\n"
            text += json_to_text(value)  # Recursive call for nested dictionaries
        elif isinstance(value, list):  # Handle lists
            text += f"{key}: {', '.join(map(str, value))}\n"
        else:
            text += f"{key}: {value}\n"
    return text

# Read JSON data from a file
file_path = "data.json"  # Replace with the path to your JSON file

try:
    with open(file_path, "r") as json_file:
        json_data = json.load(json_file)  # Load JSON data from the file

    # Convert JSON to plain text
    text_output = json_to_text(json_data)

    # Print or save the text output
    print(text_output)

    # Optionally save the text to another file
    with open("output.txt", "w") as text_file:
        text_file.write(text_output)

except FileNotFoundError:
    print(f"Error: File '{file_path}' not found.")
except json.JSONDecodeError:
    print(f"Error: File '{file_path}' is not a valid JSON file.")







import json

def json_to_text(json_obj):
    # Convert JSON object to a human-readable text format
    text = ""
    for key, value in json_obj.items():
        if isinstance(value, dict):  # Handle nested dictionaries
            text += f"{key}:\n"
            text += json_to_text(value)  # Recursive call for nested dictionaries
        elif isinstance(value, list):  # Handle lists
            text += f"{key}: {', '.join(map(str, value))}\n"
        else:
            text += f"{key}: {value}\n"
    return text

# Example JSON object
json_data = {
    "name": "John Doe",
    "age": 30,
    "address": {
        "street": "123 Main St",
        "city": "New York",
        "zipcode": "10001"
    },
    "hobbies": ["reading", "traveling", "coding"]
}

# Convert JSON to plain text
text_output = json_to_text(json_data)

# Print the result
print(text_output)














import os
import PyPDF2
import pandas as pd
import json
import tiktoken
from langchain.prompts.prompt import PromptTemplate
from langchain.chains import LLMChain
from langchain.chat_models import AzureChatOpenAI

# Function to calculate tokens using tiktoken
def calculate_tokens(text, model="gpt-3.5-turbo"):
    """
    Calculate the number of tokens in a given text using tiktoken.

    Args:
        text (str): Input text.
        model (str): Model name to determine the encoding (default: "gpt-3.5-turbo").

    Returns:
        int: Number of tokens in the text.
    """
    try:
        if model in ["gpt-3.5-turbo", "gpt-4"]:
            encoding = tiktoken.get_encoding("cl100k_base")
        elif model == "text-davinci-003":
            encoding = tiktoken.get_encoding("p50k_base")
        else:
            raise ValueError(f"Unsupported model: {model}")

        return len(encoding.encode(text))
    except Exception as e:
        print(f"Error calculating tokens: {e}")
        return 0

# Prompts
FACTUAL_PROMPT = """
    You are a financial expert with deep expertise in corporate finance, investment strategies, and accounting.
    Your task is to generate up to {num_questions} distinct factual question-answer pairs based on the input text.

    Ensure:
    - Questions focus on specific details, names, titles, or entities mentioned in the input text.
    - Questions and answers must be distinct, unique, and not repeated.
    - If fewer unique questions are possible, return only the available ones.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "What is the name of the entity mentioned in the input text?",
            "answer": "Name or entity mentioned in the input text."
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

PROCEDURAL_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate up to {num_questions} distinct procedural question-answer pairs based on the input text.

    Ensure:
    - Questions focus on processes, methods, or sequences of steps.
    - Answers provide detailed, step-by-step instructions.
    - Questions and answers must be distinct, unique, and not repeated.
    - If fewer unique questions are possible, return only the available ones.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "What are the steps to achieve or complete this process?",
            "answer": [
                "Step 1: Brief description of the first step.",
                "Step 2: Brief description of the second step.",
                "Step 3: Add additional steps as needed."
            ]
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

REASONING_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate up to {num_questions} distinct reasoning-based question-answer pairs based on the input text.

    Ensure:
    - All questions begin with "Why".
    - Questions require logical argumentation, critical thinking, or evaluation.
    - Questions and answers must be distinct, unique, and not repeated.
    - If fewer unique questions are possible, return only the available ones.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "Why does this happen or exist based on the input text?",
            "answer": "Detailed reasoning or justification for the question."
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

# Function to extract text from a PDF
def extract_text_from_pdf(pdf_path):
    """
    Extracts text from a PDF file.

    Args:
        pdf_path (str): Path to the PDF file.

    Returns:
        str: Extracted text.
    """
    text = ""
    with open(pdf_path, 'rb') as file:
        reader = PyPDF2.PdfReader(file)
        for page in reader.pages:
            text += page.extract_text()
    return text

# Function to validate and extract valid JSON from responses
def extract_valid_json(response):
    """
    Extract valid JSON from a response string.

    Args:
        response (str): Response string.

    Returns:
        list: Parsed JSON list.
    """
    try:
        json_start = response.find('[')
        json_end = response.rfind(']')
        if json_start != -1 and json_end != -1:
            return json.loads(response[json_start:json_end + 1])
    except json.JSONDecodeError:
        print("Error: Invalid JSON detected.")
    return []

# Function to remove duplicate questions and answers
def remove_duplicates(questions):
    """
    Remove duplicate questions and answers.

    Args:
        questions (list): List of question-answer dictionaries.

    Returns:
        list: Unique question-answer pairs.
    """
    seen_questions = set()
    seen_answers = set()
    unique_questions = []

    for qa in questions:
        question_text = qa["question"]
        answer_text = str(qa["answer"])  # Convert list-type answers to strings for comparison

        if question_text not in seen_questions and answer_text not in seen_answers:
            seen_questions.add(question_text)
            seen_answers.add(answer_text)
            unique_questions.append(qa)

    return unique_questions

# Function to generate questions by all types
def generate_questions_by_all_types(paragraph, total_questions, chunk_size=10):
    """
    Generate categorized questions and answers for all types, ensuring uniqueness.

    Args:
        paragraph (str): Input text.
        total_questions (int): Total number of questions to generate.
        chunk_size (int): Number of questions to generate per chunk.

    Returns:
        list: List of question-answer dictionaries with metadata.
    """
    question_types_and_prompts = {
        "Factual": FACTUAL_PROMPT,
        "Procedural": PROCEDURAL_PROMPT,
        "Reasoning-based": REASONING_PROMPT,
    }

    all_questions = []

    for question_type, prompt in question_types_and_prompts.items():
        questions = generate_questions_in_chunks(paragraph, question_type, total_questions, prompt, chunk_size)

        # Remove duplicates
        questions = remove_duplicates(questions)

        # Add metadata
        for qa in questions:
            question_text = qa["question"]
            answer_text = qa["answer"]
            all_questions.append({
                "Question Type": question_type,
                "Question": question_text,
                "Answer": answer_text,
                "Question Length (Chars)": len(question_text),
                "Answer Length (Chars)": len(str(answer_text)) if isinstance(answer_text, str) else sum(len(str(a)) for a in answer_text),
                "Question Tokens": calculate_tokens(question_text),
                "Answer Tokens": calculate_tokens(answer_text if isinstance(answer_text, str) else " ".join(answer_text))
            })

        # Break if the desired number of questions is reached
        if len(all_questions) >= total_questions:
            break

    # Return the top N unique questions
    return all_questions[:total_questions]

# Function to save results to Excel
def save_to_excel(questions_and_answers, output_file):
    """
    Save the questions and answers to an Excel file.

    Args:
        questions_and_answers (list): List of question-answer dictionaries.
        output_file (str): Path to the output Excel file.
    """
    if questions_and_answers:
        df = pd.DataFrame(questions_and_answers)
        df.to_excel(output_file, index=False)
        print(f"Questions and answers saved to {output_file}.")
    else:
        print(f"No data to save for {output_file}.")

# Function to process all PDF files in a directory and its subdirectories
def process_pdfs_in_subdirectories(root_directory, total_questions=10, chunk_size=10, output_folder="output"):
    """
    Processes all PDF files in the given directory and its subdirectories.

    Args:
        root_directory (str): Root directory containing PDF files.
        total_questions (int): Number of questions to generate per file.
        chunk_size (int): Number of questions to generate per chunk.
        output_folder (str): Directory to save the output Excel files.
    """
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    for dirpath, _, filenames in os.walk(root_directory):
        for filename in filenames:
            if filename.endswith('.pdf'):
                pdf_path = os.path.join(dirpath, filename)
                try:
                    print(f"Processing: {pdf_path}")
                    # Extract text from the PDF
                    pdf_text = extract_text_from_pdf(pdf_path)

                    # Generate questions
                    questions_and_answers = generate_questions_by_all_types(pdf_text, total_questions, chunk_size)

                    # Save results to Excel
                    relative_path = os.path.relpath(pdf_path, root_directory)
                    output_file = os.path.join(output_folder, relative_path.replace(".pdf", "_questions.xlsx"))

                    # Ensure the subdirectory structure in the output folder
                    os.makedirs(os.path.dirname(output_file), exist_ok=True)
                    save_to_excel(questions_and_answers, output_file)
                except Exception as e:
                    print(f"Error processing {pdf_path}: {e}")













import os
import PyPDF2
import pandas as pd
import json
from langchain.prompts.prompt import PromptTemplate
from langchain.chains import LLMChain
from langchain.chat_models import AzureChatOpenAI

# Tokenization (Whitespace-Based)
def calculate_tokens(text):
    """
    Calculate the number of tokens in a given text using whitespace tokenization.
    """
    return len(text.split())

# Prompts
FACTUAL_PROMPT = """
    You are a financial expert with deep expertise in corporate finance, investment strategies, and accounting.
    Your task is to generate up to {num_questions} distinct factual question-answer pairs based on the input text.

    Ensure:
    - Questions focus on specific details, names, titles, or entities mentioned in the input text.
    - Questions and answers must be distinct, unique, and not repeated.
    - If fewer unique questions are possible, return only the available ones.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "What is the name of the entity mentioned in the input text?",
            "answer": "Name or entity mentioned in the input text."
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

PROCEDURAL_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate up to {num_questions} distinct procedural question-answer pairs based on the input text.

    Ensure:
    - Questions focus on processes, methods, or sequences of steps.
    - Answers provide detailed, step-by-step instructions.
    - Questions and answers must be distinct, unique, and not repeated.
    - If fewer unique questions are possible, return only the available ones.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "What are the steps to achieve or complete this process?",
            "answer": [
                "Step 1: Brief description of the first step.",
                "Step 2: Brief description of the second step.",
                "Step 3: Add additional steps as needed."
            ]
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

INFERENTIAL_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate up to {num_questions} distinct inferential question-answer pairs based on the input text.

    Ensure:
    - Questions require drawing conclusions or making interpretations beyond the direct information in the text.
    - Answers justify the inference with clear logical reasoning and include the reasoning process explicitly.
    - Questions and answers must be distinct, unique, and not repeated.
    - If fewer unique questions are possible, return only the available ones.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "What inference can be made about {specific topic} based on the input text?",
            "answer": "The inference that can be drawn is {logical explanation with reasoning}."
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

CONCEPTUAL_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate up to {num_questions} distinct conceptual question-answer pairs based on the input text.

    Ensure:
    - Questions explore theories, principles, or abstract ideas mentioned in the text.
    - Answers provide a detailed explanation of the underlying concept or principle, including why it is important.
    - Questions and answers must be distinct, unique, and not repeated.
    - If fewer unique questions are possible, return only the available ones.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "What is the concept of {specific principle or idea} in the input text?",
            "answer": "The concept refers to {detailed explanation and reasoning about its importance}."
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

REASONING_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate up to {num_questions} distinct reasoning-based question-answer pairs based on the input text.

    Ensure:
    - All questions begin with "Why".
    - Questions require logical argumentation, critical thinking, or evaluation.
    - Questions and answers must be distinct, unique, and not repeated.
    - If fewer unique questions are possible, return only the available ones.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "Why does this happen or exist based on the input text?",
            "answer": "Detailed reasoning or justification for the question."
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

# Function to extract text from a PDF
def extract_text_from_pdf(pdf_path):
    text = ""
    with open(pdf_path, 'rb') as file:
        reader = PyPDF2.PdfReader(file)
        for page in reader.pages:
            text += page.extract_text()
    return text

# Function to validate and extract valid JSON from responses
def extract_valid_json(response):
    """
    Extract valid JSON from a response string.
    """
    try:
        json_start = response.find('[')
        json_end = response.rfind(']')
        if json_start != -1 and json_end != -1:
            return json.loads(response[json_start:json_end + 1])
    except json.JSONDecodeError:
        print("Error: Invalid JSON detected.")
    return []

# Function to remove duplicate questions and answers
def remove_duplicates(questions):
    """
    Remove duplicate questions and answers.
    """
    seen_questions = set()
    seen_answers = set()
    unique_questions = []

    for qa in questions:
        question_text = qa["question"]
        answer_text = str(qa["answer"])  # Convert list-type answers to strings for comparison

        if question_text not in seen_questions and answer_text not in seen_answers:
            seen_questions.add(question_text)
            seen_answers.add(answer_text)
            unique_questions.append(qa)

    return unique_questions

# Function to generate questions for all types
def generate_questions_by_all_types(paragraph, total_questions, chunk_size=10):
    """
    Generate categorized questions and answers for all types, ensuring uniqueness.
    """
    question_types_and_prompts = {
        "Factual": FACTUAL_PROMPT,
        "Procedural": PROCEDURAL_PROMPT,
        "Reasoning-based": REASONING_PROMPT,
        "Inferential": INFERENTIAL_PROMPT,
        "Conceptual": CONCEPTUAL_PROMPT,
    }

    all_questions = []

    for question_type, prompt in question_types_and_prompts.items():
        questions = generate_questions_in_chunks(paragraph, question_type, total_questions, prompt, chunk_size)

        # Remove duplicates
        questions = remove_duplicates(questions)

        # Add metadata
        for qa in questions:
            question_text = qa["question"]
            answer_text = qa["answer"]
            all_questions.append({
                "Question Type": question_type,
                "Question": question_text,
                "Answer": answer_text,
                "Question Length (Chars)": len(question_text),
                "Answer Length (Chars)": len(str(answer_text)) if isinstance(answer_text, str) else sum(len(str(a)) for a in answer_text),
                "Question Tokens": calculate_tokens(question_text),
                "Answer Tokens": calculate_tokens(answer_text if isinstance(answer_text, str) else " ".join(answer_text))
            })

        # Break if the desired number of questions is reached
        if len(all_questions) >= total_questions:
            break

    # Return the top N unique questions
    return all_questions[:total_questions]

# Function to save results to Excel
def save_to_excel(questions_and_answers, output_file):
    """
    Save the questions, answers, and their lengths to an Excel file.
    """
    if questions_and_answers:
        df = pd.DataFrame(questions_and_answers)
        df.to_excel(output_file, index=False)
        print(f"Questions and answers saved to {output_file}.")
    else:
        print(f"No data to save for {output_file}.")

# Function to process all PDF files in a directory and its subdirectories
def process_pdfs_in_subdirectories(root_directory, total_questions=10, chunk_size=10, output_folder="output"):
    """
    Processes all PDF files in the given directory and its subdirectories.
    """
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    for dirpath, _, filenames in os.walk(root_directory):
        for filename in filenames:
            if filename.endswith('.pdf'):
                pdf_path = os.path.join(dirpath, filename)
                try:
                    print(f"Processing: {pdf_path}")
                    # Extract text from the PDF
                    pdf_text = extract_text_from_pdf(pdf_path)

                    # Generate questions
                    questions_and_answers = generate_questions_by_all_types(pdf_text, total_questions, chunk_size)

                    # Save results to Excel
                    relative_path = os.path.relpath(pdf_path, root_directory)
                    output_file = os.path.join(output_folder, relative_path.replace(".pdf", "_questions.xlsx"))

                    # Ensure the subdirectory structure in the output folder
                    os.makedirs(os.path.dirname(output_file), exist_ok=True)
                    save_to_excel(questions_and_answers, output_file)
                except Exception as e:
                    print(f"Error processing {pdf_path}: {e}")













import os
import PyPDF2
import pandas as pd
import json
from langchain.prompts.prompt import PromptTemplate
from langchain.chains import LLMChain
from langchain.chat_models import AzureChatOpenAI

# Tokenization (Whitespace-Based)
def calculate_tokens(text):
    """
    Calculate the number of tokens in a given text using whitespace tokenization.
    """
    return len(text.split())

# Prompts
FACTUAL_PROMPT = """
    You are a financial expert with deep expertise in corporate finance, investment strategies, and accounting.
    Your task is to generate up to {num_questions} distinct factual question-answer pairs based on the input text.

    Ensure:
    - Questions focus on specific details, names, titles, or entities mentioned in the input text.
    - Questions and answers must be distinct, unique, and not repeated.
    - If fewer unique questions are possible, return only the available ones.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "What is the name of the entity mentioned in the input text?",
            "answer": "Name or entity mentioned in the input text."
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

PROCEDURAL_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate up to {num_questions} distinct procedural question-answer pairs based on the input text.

    Ensure:
    - Questions focus on processes, methods, or sequences of steps.
    - Answers provide detailed, step-by-step instructions.
    - Questions and answers must be distinct, unique, and not repeated.
    - If fewer unique questions are possible, return only the available ones.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "What are the steps to achieve or complete this process?",
            "answer": [
                "Step 1: Brief description of the first step.",
                "Step 2: Brief description of the second step.",
                "Step 3: Add additional steps as needed."
            ]
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

INFERENTIAL_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate up to {num_questions} distinct inferential question-answer pairs based on the input text.

    Ensure:
    - Questions require interpretation or conclusions derived from the input text.
    - Answers justify the inference with clear logical reasoning.
    - Questions and answers must be distinct, unique, and not repeated.
    - If fewer unique questions are possible, return only the available ones.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "What inference can be made about {specific topic}?",
            "answer": "The inference that can be drawn is {logical explanation}."
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

CONCEPTUAL_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate up to {num_questions} distinct conceptual question-answer pairs based on the input text.

    Ensure:
    - Questions explore theories, principles, or core concepts mentioned in the text.
    - Answers provide a detailed explanation of the underlying concept or principle.
    - Questions and answers must be distinct, unique, and not repeated.
    - If fewer unique questions are possible, return only the available ones.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "What is the concept of {specific principle or idea} in the input text?",
            "answer": "The concept refers to {detailed explanation}."
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

REASONING_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate up to {num_questions} distinct reasoning-based question-answer pairs based on the input text.

    Ensure:
    - All questions begin with "Why".
    - Questions and answers must be distinct, unique, and not repeated.
    - If fewer unique questions are possible, return only the available ones.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "Why does this happen or exist based on the input text?",
            "answer": "Detailed reasoning or justification for the question."
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

# Function to extract text from a PDF
def extract_text_from_pdf(pdf_path):
    text = ""
    with open(pdf_path, 'rb') as file:
        reader = PyPDF2.PdfReader(file)
        for page in reader.pages:
            text += page.extract_text()
    return text

# Function to validate and extract valid JSON from responses
def extract_valid_json(response):
    """
    Extract valid JSON from a response string.
    """
    try:
        json_start = response.find('[')
        json_end = response.rfind(']')
        if json_start != -1 and json_end != -1:
            return json.loads(response[json_start:json_end + 1])
    except json.JSONDecodeError:
        print("Error: Invalid JSON detected.")
    return []

# Function to remove duplicate questions and answers
def remove_duplicates(questions):
    """
    Remove duplicate questions and answers.
    """
    seen_questions = set()
    seen_answers = set()
    unique_questions = []

    for qa in questions:
        question_text = qa["question"]
        answer_text = str(qa["answer"])  # Convert list-type answers to strings for comparison

        if question_text not in seen_questions and answer_text not in seen_answers:
            seen_questions.add(question_text)
            seen_answers.add(answer_text)
            unique_questions.append(qa)

    return unique_questions

# Function to generate questions for all types
def generate_questions_by_all_types(paragraph, total_questions, chunk_size=10):
    """
    Generate categorized questions and answers for all types, ensuring uniqueness.
    """
    question_types_and_prompts = {
        "Factual": FACTUAL_PROMPT,
        "Procedural": PROCEDURAL_PROMPT,
        "Reasoning-based": REASONING_PROMPT,
        "Inferential": INFERENTIAL_PROMPT,
        "Conceptual": CONCEPTUAL_PROMPT,
    }

    all_questions = []

    for question_type, prompt in question_types_and_prompts.items():
        questions = generate_questions_in_chunks(paragraph, question_type, total_questions, prompt, chunk_size)

        # Remove duplicates
        questions = remove_duplicates(questions)

        # Add metadata
        for qa in questions:
            question_text = qa["question"]
            answer_text = qa["answer"]
            all_questions.append({
                "Question Type": question_type,
                "Question": question_text,
                "Answer": answer_text,
                "Question Length (Chars)": len(question_text),
                "Answer Length (Chars)": len(str(answer_text)) if isinstance(answer_text, str) else sum(len(str(a)) for a in answer_text),
                "Question Tokens": calculate_tokens(question_text),
                "Answer Tokens": calculate_tokens(answer_text if isinstance(answer_text, str) else " ".join(answer_text))
            })

        # Break if the desired number of questions is reached
        if len(all_questions) >= total_questions:
            break

    # Return the top N unique questions
    return all_questions[:total_questions]

# Function to save results to Excel
def save_to_excel(questions_and_answers, output_file):
    """
    Save the questions, answers, and their lengths to an Excel file.
    """
    if questions_and_answers:
        df = pd.DataFrame(questions_and_answers)
        df.to_excel(output_file, index=False)
        print(f"Questions and answers saved to {output_file}.")
    else:
        print(f"No data to save for {output_file}.")

# Function to process all PDF files in a directory and its subdirectories
def process_pdfs_in_subdirectories(root_directory, total_questions=10, chunk_size=10, output_folder="output"):
    """
    Processes all PDF files in the given directory and its subdirectories.
    """
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    for dirpath, _, filenames in os.walk(root_directory):
        for filename in filenames:
            if filename.endswith('.pdf'):
                pdf_path = os.path.join(dirpath, filename)
                try:
                    print(f"Processing: {pdf_path}")
                    # Extract text from the PDF
                    pdf_text = extract_text_from_pdf(pdf_path)

                    # Generate questions
                    questions_and_answers = generate_questions_by_all_types(pdf_text, total_questions, chunk_size)

                    # Save results to Excel
                    relative_path = os.path.relpath(pdf_path, root_directory)
                    output_file = os.path.join(output_folder, relative_path.replace(".pdf", "_questions.xlsx"))

                    # Ensure the subdirectory structure in the output folder
                    os.makedirs(os.path.dirname(output_file), exist_ok=True)
                    save_to_excel(questions_and_answers, output_file)
                except Exception as e:
                    print(f"Error processing {pdf_path}: {e}")


















import os
import PyPDF2
import pandas as pd
import json
from langchain.prompts.prompt import PromptTemplate
from langchain.chains import LLMChain
from langchain.chat_models import AzureChatOpenAI

# Tokenization (Whitespace-Based)
def calculate_tokens(text):
    """
    Calculate the number of tokens in a given text using whitespace tokenization.
    """
    return len(text.split())

# Prompts
FACTUAL_PROMPT = """
    You are a financial expert with deep expertise in corporate finance, investment strategies, and accounting.
    Your task is to generate up to {num_questions} distinct factual question-answer pairs based on the input text.

    Ensure:
    - Questions focus on specific details, names, titles, or entities mentioned in the input text.
    - Questions and answers must be distinct, unique, and not repeated.
    - If fewer unique questions are possible, return only the available ones.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "What is the name of the entity mentioned in the input text?",
            "answer": "Name or entity mentioned in the input text."
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

PROCEDURAL_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate up to {num_questions} distinct procedural question-answer pairs based on the input text.

    Ensure:
    - Questions focus on processes, methods, or sequences of steps.
    - Answers provide detailed, step-by-step instructions.
    - Questions and answers must be distinct, unique, and not repeated.
    - If fewer unique questions are possible, return only the available ones.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "What are the steps to achieve or complete this process?",
            "answer": [
                "Step 1: Brief description of the first step.",
                "Step 2: Brief description of the second step.",
                "Step 3: Add additional steps as needed."
            ]
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

INFERENTIAL_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate up to {num_questions} distinct inferential question-answer pairs based on the input text.

    Ensure:
    - Questions require interpretation or conclusions derived from the input text.
    - Answers justify the inference with clear logical reasoning.
    - Questions and answers must be distinct, unique, and not repeated.
    - If fewer unique questions are possible, return only the available ones.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "What inference can be made about {specific topic}?",
            "answer": "The inference that can be drawn is {logical explanation}."
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

CONCEPTUAL_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate up to {num_questions} distinct conceptual question-answer pairs based on the input text.

    Ensure:
    - Questions explore theories, principles, or core concepts mentioned in the text.
    - Answers provide a detailed explanation of the underlying concept or principle.
    - Questions and answers must be distinct, unique, and not repeated.
    - If fewer unique questions are possible, return only the available ones.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "What is the concept of {specific principle or idea} in the input text?",
            "answer": "The concept refers to {detailed explanation}."
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

REASONING_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate up to {num_questions} distinct reasoning-based question-answer pairs based on the input text.

    Ensure:
    - All questions begin with "Why".
    - Questions require logical argumentation, critical thinking, or evaluation.
    - Questions and answers must be distinct, unique, and not repeated.
    - If fewer unique questions are possible, return only the available ones.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "Why does this happen or exist based on the input text?",
            "answer": "Detailed reasoning or justification for the question."
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

# Function to extract text from a PDF
def extract_text_from_pdf(pdf_path):
    text = ""
    with open(pdf_path, 'rb') as file:
        reader = PyPDF2.PdfReader(file)
        for page in reader.pages:
            text += page.extract_text()
    return text

# Function to validate and extract valid JSON from responses
def extract_valid_json(response):
    """
    Extract valid JSON from a response string.
    """
    try:
        json_start = response.find('[')
        json_end = response.rfind(']')
        if json_start != -1 and json_end != -1:
            return json.loads(response[json_start:json_end + 1])
    except json.JSONDecodeError:
        print("Error: Invalid JSON detected.")
    return []

# Function to remove duplicate questions and answers
def remove_duplicates(questions):
    """
    Remove duplicate questions and answers.
    """
    seen_questions = set()
    seen_answers = set()
    unique_questions = []

    for qa in questions:
        question_text = qa["question"]
        answer_text = str(qa["answer"])  # Convert list-type answers to strings for comparison

        if question_text not in seen_questions and answer_text not in seen_answers:
            seen_questions.add(question_text)
            seen_answers.add(answer_text)
            unique_questions.append(qa)

    return unique_questions

# Function to generate questions for a specific type
def generate_questions(paragraph, question_type, num_questions, prompt_template):
    llm = AzureChatOpenAI(
        temperature=0,
        api_version="2023-06-01-preview",
        azure_openai_api_base="YOUR_AZURE_ENDPOINT",  # Replace with your Azure endpoint
        deployment_name="ssgpt-40"
    )

    prompt = PromptTemplate(
        input_variables=["paragraph", "num_questions"],
        template=prompt_template
    )
    llm_chain = LLMChain(llm=llm, prompt=prompt)

    try:
        response = llm_chain.predict(
            paragraph=paragraph,
            num_questions=str(num_questions)
        )
        return extract_valid_json(response)
    except Exception as e:
        print(f"Error generating {question_type} questions: {e}")
        return []

# Function to generate questions in chunks
def generate_questions_in_chunks(paragraph, question_type, total_questions, prompt_template, chunk_size=10):
    """
    Generate questions in chunks to avoid exceeding token limits.
    """
    all_questions = []
    for _ in range(0, total_questions, chunk_size):
        try:
            chunk_questions = generate_questions(paragraph, question_type, chunk_size, prompt_template)
            all_questions.extend(chunk_questions)
        except Exception as e:
            print(f"Error generating chunk for {question_type}: {e}")
            continue
    return all_questions

# Function to generate questions for all types
def generate_questions_by_all_types(paragraph, total_questions, chunk_size=10):
    """
    Generate categorized questions and answers for all types, ensuring uniqueness.
    """
    question_types_and_prompts = {
        "Factual": FACTUAL_PROMPT,
        "Procedural": PROCEDURAL_PROMPT,
        "Reasoning-based": REASONING_PROMPT,
        "Inferential": INFERENTIAL_PROMPT,
        "Conceptual": CONCEPTUAL_PROMPT,
    }

    all_questions = []

    for question_type, prompt in question_types_and_prompts.items():
        questions = generate_questions_in_chunks(paragraph, question_type, total_questions, prompt, chunk_size)

        # Remove duplicates
        questions = remove_duplicates(questions)

        all_questions.extend(questions)

        # Break if the desired number of questions is reached
        if len(all_questions) >= total_questions:
            break

    # Return the top N unique questions
    return all_questions[:total_questions]

# Function to save results to Excel
def save_to_excel(questions_and_answers, output_file):
    """
    Save the questions, answers, and their lengths to an Excel file.
    """
    if questions_and_answers:
        df = pd.DataFrame(questions_and_answers)
        df.to_excel(output_file, index=False)
        print(f"Questions and answers saved to {output_file}.")
    else:
        print(f"No data to save for {output_file}.")

# Function to process all PDF files in a directory and its subdirectories
def process_pdfs_in_subdirectories(root_directory, total_questions=10, chunk_size=10, output_folder="output"):
    """
    Processes all PDF files in the given directory and its subdirectories.
    """
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    for dirpath, _, filenames in os.walk(root_directory):
        for filename in filenames:
            if filename.endswith('.pdf'):
                pdf_path = os.path.join(dirpath, filename)
                try:
                    print(f"Processing: {pdf_path}")
                    # Extract text from the PDF
                    pdf_text = extract_text_from_pdf(pdf_path)

                    # Generate questions
                    questions_and_answers = generate_questions_by_all_types(pdf_text, total_questions, chunk_size)

                    # Save results to Excel
                    relative_path = os.path.relpath(pdf_path, root_directory)
                    output_file = os.path.join(output_folder, relative_path.replace(".pdf", "_questions.xlsx"))

                    # Ensure the subdirectory structure in the output folder
                    os.makedirs(os.path.dirname(output_file), exist_ok=True)
                    save_to_excel(questions_and_answers, output_file)
                except Exception as e:
                    print(f"Error processing {pdf_path}: {e}")
















import os
import PyPDF2
import pandas as pd
import json
from langchain.prompts.prompt import PromptTemplate
from langchain.chains import LLMChain
from langchain.chat_models import AzureChatOpenAI

# Tokenization (Whitespace-Based)
def calculate_tokens(text):
    """
    Calculate the number of tokens in a given text using whitespace tokenization.
    """
    return len(text.split())

# Prompts
FACTUAL_PROMPT = """
    You are a financial expert with deep expertise in corporate finance, investment strategies, and accounting.
    Your task is to generate up to {num_questions} distinct factual question-answer pairs based on the input text.

    Ensure:
    - Questions focus on specific details, names, titles, or entities mentioned in the input text.
    - Questions and answers must be distinct, unique, and not repeated.
    - If fewer unique questions are possible, return only the available ones.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "What is the name of the entity mentioned in the input text?",
            "answer": "Name or entity mentioned in the input text."
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

PROCEDURAL_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate up to {num_questions} distinct procedural question-answer pairs based on the input text.

    Ensure:
    - Questions focus on processes, methods, or sequences of steps.
    - Answers provide detailed, step-by-step instructions.
    - Questions and answers must be distinct, unique, and not repeated.
    - If fewer unique questions are possible, return only the available ones.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "What are the steps to achieve or complete this process?",
            "answer": [
                "Step 1: Brief description of the first step.",
                "Step 2: Brief description of the second step.",
                "Step 3: Add additional steps as needed."
            ]
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

REASONING_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate up to {num_questions} distinct reasoning-based question-answer pairs based on the input text.

    Ensure:
    - All questions begin with "Why".
    - Questions and answers must be distinct, unique, and not repeated.
    - If fewer unique questions are possible, return only the available ones.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "Why does this happen or exist based on the input text?",
            "answer": "Detailed reasoning or justification for the question."
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

# Function to extract text from a PDF
def extract_text_from_pdf(pdf_path):
    text = ""
    with open(pdf_path, 'rb') as file:
        reader = PyPDF2.PdfReader(file)
        for page in reader.pages:
            text += page.extract_text()
    return text

# Function to validate and extract valid JSON from responses
def extract_valid_json(response):
    """
    Extract valid JSON from a response string.
    """
    try:
        json_start = response.find('[')
        json_end = response.rfind(']')
        if json_start != -1 and json_end != -1:
            return json.loads(response[json_start:json_end + 1])
    except json.JSONDecodeError:
        print("Error: Invalid JSON detected.")
    return []

# Function to remove duplicate questions and answers
def remove_duplicates(questions):
    """
    Remove duplicate questions and answers.
    """
    seen_questions = set()
    seen_answers = set()
    unique_questions = []

    for qa in questions:
        question_text = qa["question"]
        answer_text = qa["answer"]

        if question_text not in seen_questions and answer_text not in seen_answers:
            seen_questions.add(question_text)
            seen_answers.add(answer_text)
            unique_questions.append(qa)

    return unique_questions

# Function to generate questions for a specific type
def generate_questions(paragraph, question_type, num_questions, prompt_template):
    llm = AzureChatOpenAI(
        temperature=0,
        api_version="2023-06-01-preview",
        azure_openai_api_base="YOUR_AZURE_ENDPOINT",  # Replace with your Azure endpoint
        deployment_name="ssgpt-40"
    )

    prompt = PromptTemplate(
        input_variables=["paragraph", "num_questions"],
        template=prompt_template
    )
    llm_chain = LLMChain(llm=llm, prompt=prompt)

    try:
        response = llm_chain.predict(
            paragraph=paragraph,
            num_questions=str(num_questions)
        )
        return extract_valid_json(response)
    except Exception as e:
        print(f"Error generating {question_type} questions: {e}")
        return []

# Function to generate questions in chunks
def generate_questions_in_chunks(paragraph, question_type, total_questions, prompt_template, chunk_size=10):
    """
    Generate questions in chunks to avoid exceeding token limits.
    """
    all_questions = []
    for _ in range(0, total_questions, chunk_size):
        try:
            chunk_questions = generate_questions(paragraph, question_type, chunk_size, prompt_template)
            all_questions.extend(chunk_questions)
        except Exception as e:
            print(f"Error generating chunk for {question_type}: {e}")
            continue
    return all_questions

# Function to generate questions for all types
def generate_questions_by_all_types(paragraph, total_questions, chunk_size=10):
    """
    Generate categorized questions and answers for all types, ensuring uniqueness.
    """
    question_types_and_prompts = {
        "Factual": FACTUAL_PROMPT,
        "Procedural": PROCEDURAL_PROMPT,
        "Reasoning-based": REASONING_PROMPT,
    }

    all_questions = []

    for question_type, prompt in question_types_and_prompts.items():
        questions = generate_questions_in_chunks(paragraph, question_type, total_questions, prompt, chunk_size)

        # Remove duplicates
        questions = remove_duplicates(questions)

        all_questions.extend(questions)

        # Break if the desired number of questions is reached
        if len(all_questions) >= total_questions:
            break

    # Return the top N unique questions
    return all_questions[:total_questions]

# Function to save results to Excel
def save_to_excel(questions_and_answers, output_file):
    """
    Save the questions, answers, and their lengths to an Excel file.
    """
    if questions_and_answers:
        df = pd.DataFrame(questions_and_answers)
        df.to_excel(output_file, index=False)
        print(f"Questions and answers saved to {output_file}.")
    else:
        print(f"No data to save for {output_file}.")

# Function to process all PDF files in a directory and its subdirectories
def process_pdfs_in_subdirectories(root_directory, total_questions=10, chunk_size=10, output_folder="output"):
    """
    Processes all PDF files in the given directory and its subdirectories.
    """
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    for dirpath, _, filenames in os.walk(root_directory):
        for filename in filenames:
            if filename.endswith('.pdf'):
                pdf_path = os.path.join(dirpath, filename)
                try:
                    print(f"Processing: {pdf_path}")
                    # Extract text from the PDF
                    pdf_text = extract_text_from_pdf(pdf_path)

                    # Generate questions
                    questions_and_answers = generate_questions_by_all_types(pdf_text, total_questions, chunk_size)

                    # Save results to Excel
                    relative_path = os.path.relpath(pdf_path, root_directory)
                    output_file = os.path.join(output_folder, relative_path.replace(".pdf", "_questions.xlsx"))

                    # Ensure the subdirectory structure in the output folder
                    os.makedirs(os.path.dirname(output_file), exist_ok=True)
                    save_to_excel(questions_and_answers, output_file)
                except Exception as e:
                    print(f"Error processing {pdf_path}: {e}")














# Prompts for Factual, Procedural, Inferential, Conceptual, and Reasoning-based questions

FACTUAL_PROMPT = """
    You are a financial expert with deep expertise in corporate finance, investment strategies, and accounting.
    Your task is to generate up to {num_questions} distinct factual question-answer pairs based on the input text.

    Ensure:
    - Questions focus on specific details, names, titles, or entities mentioned in the input text.
    - Answers are precise and concise.
    - Questions and answers must be unique and should not repeat.
    - If fewer distinct questions are possible, return only the available ones.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "What is the name of the entity mentioned in the input text?",
            "answer": "Name or entity mentioned in the input text."
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

PROCEDURAL_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate up to {num_questions} distinct procedural question-answer pairs based on the input text.

    Ensure:
    - Questions focus on processes, methods, or sequences of steps.
    - Answers provide detailed, step-by-step instructions with clear descriptions for each step.
    - Questions and answers must be unique and should not repeat.
    - If fewer distinct questions are possible, return only the available ones.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "What are the steps to achieve or complete this process?",
            "answer": [
                "Step 1: Brief description of the first step.",
                "Step 2: Brief description of the second step.",
                "Step 3: Add additional steps as needed."
            ]
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

INFERENTIAL_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate up to {num_questions} distinct inferential question-answer pairs based on the input text.

    Ensure:
    - Questions require interpretation or conclusions derived from the input text.
    - Answers justify the inference with clear logical reasoning.
    - Questions and answers must be unique and should not repeat.
    - If fewer distinct questions are possible, return only the available ones.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "What inference can be made about {specific topic}?",
            "answer": "The inference that can be drawn is {logical explanation}."
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

CONCEPTUAL_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate up to {num_questions} distinct conceptual question-answer pairs based on the input text.

    Ensure:
    - Questions explore theories, principles, or core concepts mentioned in the text.
    - Answers provide a detailed explanation of the underlying concept or principle.
    - Questions and answers must be unique and should not repeat.
    - If fewer distinct questions are possible, return only the available ones.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "What is the concept of {specific principle or idea} in the input text?",
            "answer": "The concept refers to {detailed explanation}."
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

REASONING_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate up to {num_questions} distinct reasoning-based question-answer pairs based on the input text.

    Ensure:
    - All questions begin with "Why".
    - Questions require logical argumentation, critical thinking, or evaluation.
    - Answers justify conclusions with clear and logical reasoning.
    - Questions and answers must be unique and should not repeat.
    - If fewer distinct questions are possible, return only the available ones.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "Why does this happen or exist based on the input text?",
            "answer": "Detailed reasoning or justification for the question."
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""



















import os
import tiktoken
from langchain.prompts.prompt import PromptTemplate
from langchain.chains import LLMChain
from langchain.chat_models import AzureChatOpenAI
import PyPDF2
import pandas as pd
import json

# Tokenizer setup
tokenizer = tiktoken.get_encoding("cl100k_base")  # Use the appropriate encoding for your model

# Prompts remain the same as before

# Function to extract text from a PDF
def extract_text_from_pdf(pdf_path):
    text = ""
    with open(pdf_path, 'rb') as file:
        reader = PyPDF2.PdfReader(file)
        for page in reader.pages:
            text += page.extract_text()
    return text

# Function to calculate token counts
def calculate_tokens(text):
    """
    Calculate the number of tokens in a given text.
    """
    return len(tokenizer.encode(text))

# Function to generate questions for a specific type
def generate_questions(paragraph, question_type, num_questions, prompt_template):
    llm = AzureChatOpenAI(
        temperature=0,
        api_version="2023-06-01-preview",
        azure_openai_api_base="YOUR_AZURE_ENDPOINT",  # Replace with your Azure endpoint
        deployment_name="ssgpt-40"
    )

    prompt = PromptTemplate(
        input_variables=["paragraph", "num_questions"],
        template=prompt_template
    )
    llm_chain = LLMChain(llm=llm, prompt=prompt)

    try:
        response = llm_chain.predict(
            paragraph=paragraph,
            num_questions=str(num_questions)
        )
        return extract_valid_json(response)
    except Exception as e:
        print(f"Error generating {question_type} questions: {e}")
        return []

# Function to validate and extract valid JSON from responses
def extract_valid_json(response):
    """
    Extract valid JSON from a response string.
    """
    try:
        json_start = response.find('[')
        json_end = response.rfind(']')
        if json_start != -1 and json_end != -1:
            return json.loads(response[json_start:json_end + 1])
    except json.JSONDecodeError:
        print("Error: Invalid JSON detected.")
    return []

# Function to generate questions in chunks
def generate_questions_in_chunks(paragraph, question_type, total_questions, prompt_template, chunk_size=10):
    """
    Generate questions in chunks to avoid exceeding token limits.
    """
    all_questions = []
    for _ in range(0, total_questions, chunk_size):
        try:
            chunk_questions = generate_questions(paragraph, question_type, chunk_size, prompt_template)
            all_questions.extend(chunk_questions)
        except Exception as e:
            print(f"Error generating chunk for {question_type}: {e}")
            continue
    return all_questions

# Function to generate questions for all types
def generate_questions_by_all_types(paragraph, total_questions, chunk_size=10):
    """
    Generate categorized questions and answers for all types, including token and character counts.
    """
    question_types_and_prompts = {
        "Factual": FACTUAL_PROMPT,
        "Procedural": PROCEDURAL_PROMPT,
        "Reasoning-based": REASONING_PROMPT,
    }

    all_questions = []
    for question_type, prompt in question_types_and_prompts.items():
        questions = generate_questions_in_chunks(paragraph, question_type, total_questions, prompt, chunk_size)
        for qa in questions:
            question_text = qa["question"]
            answer_text = qa["answer"]

            # Calculate token and character counts
            question_tokens = calculate_tokens(question_text)
            answer_tokens = calculate_tokens(answer_text if isinstance(answer_text, str) else " ".join(answer_text))
            answer_length = len(answer_text) if isinstance(answer_text, str) else sum(len(str(ans)) for ans in answer_text)

            # Append question type, question, answer, and their counts
            all_questions.append({
                "Question Type": question_type,
                "Question": question_text,
                "Answer": answer_text,
                "Question Length (Chars)": len(question_text),
                "Answer Length (Chars)": answer_length,
                "Question Tokens": question_tokens,
                "Answer Tokens": answer_tokens
            })
    return all_questions

# Function to save results to Excel
def save_to_excel(questions_and_answers, output_file):
    """
    Save the questions, answers, and their lengths to an Excel file.
    """
    if questions_and_answers:
        df = pd.DataFrame(questions_and_answers)
        df.to_excel(output_file, index=False)
        print(f"Questions and answers saved to {output_file}.")
    else:
        print(f"No data to save for {output_file}.")

# Function to process all PDF files in a directory and its subdirectories
def process_pdfs_in_subdirectories(root_directory, total_questions=10, chunk_size=10, output_folder="output"):
    """
    Processes all PDF files in the given directory and its subdirectories.
    """
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    for dirpath, _, filenames in os.walk(root_directory):
        for filename in filenames:
            if filename.endswith('.pdf'):
                pdf_path = os.path.join(dirpath, filename)
                try:
                    print(f"Processing: {pdf_path}")
                    # Extract text from the PDF
                    pdf_text = extract_text_from_pdf(pdf_path)

                    # Generate questions
                    questions_and_answers = generate_questions_by_all_types(pdf_text, total_questions, chunk_size)

                    # Save results to Excel
                    relative_path = os.path.relpath(pdf_path, root_directory)
                    output_file = os.path.join(output_folder, relative_path.replace(".pdf", "_questions.xlsx"))

                    # Ensure the subdirectory structure in the output folder
                    os.makedirs(os.path.dirname(output_file), exist_ok=True)
                    save_to_excel(questions_and_answers, output_file)
                except Exception as e:
                    print(f"Error processing {pdf_path}: {e}")



















import os
from langchain.prompts.prompt import PromptTemplate
from langchain.chains import LLMChain
from langchain.chat_models import AzureChatOpenAI
import PyPDF2
import pandas as pd
import json

# Updated Factual Prompt
FACTUAL_PROMPT = """
    You are a financial expert with deep expertise in corporate finance, investment strategies, and accounting.
    Your task is to generate {num_questions} factual question-answer pairs based on the input text.

    Ensure:
    - Questions are focused on names, titles, or specific entities mentioned in the input text.
    - Answers are precise and concise.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "What is the name of the entity mentioned in the input text?",
            "answer": "Name or entity mentioned in the input text."
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

# Updated Procedural Prompt
PROCEDURAL_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate {num_questions} procedural question-answer pairs based on the input text.

    Ensure:
    - Questions focus on processes, methods, or sequences of steps.
    - Answers provide detailed, step-by-step instructions with clear descriptions for each step.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "What are the steps to achieve or complete this process?",
            "answer": [
                "Step 1: Brief description of the first step.",
                "Step 2: Brief description of the second step.",
                "Step 3: Add additional steps as needed.",
                ...
            ]
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

# Updated Reasoning-Based Prompt
REASONING_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate {num_questions} reasoning-based question-answer pairs based on the input text.

    Ensure:
    - All questions begin with "Why".
    - Questions require logical argumentation, critical thinking, or evaluation.
    - Answers justify conclusions with clear and logical reasoning.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "Why does this happen or exist based on the input text?",
            "answer": "Detailed reasoning or justification for the question."
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

# Function to extract text from a PDF
def extract_text_from_pdf(pdf_path):
    text = ""
    with open(pdf_path, 'rb') as file:
        reader = PyPDF2.PdfReader(file)
        for page in reader.pages:
            text += page.extract_text()
    return text

# Function to validate and extract valid JSON from responses
def extract_valid_json(response):
    """
    Extract valid JSON from a response string.
    """
    try:
        json_start = response.find('[')
        json_end = response.rfind(']')
        if json_start != -1 and json_end != -1:
            return json.loads(response[json_start:json_end + 1])
    except json.JSONDecodeError:
        print("Error: Invalid JSON detected.")
    return []

# Function to generate questions for a specific type
def generate_questions(paragraph, question_type, num_questions, prompt_template):
    llm = AzureChatOpenAI(
        temperature=0,
        api_version="2023-06-01-preview",
        azure_openai_api_base="YOUR_AZURE_ENDPOINT",  # Replace with your Azure endpoint
        deployment_name="ssgpt-40"
    )

    prompt = PromptTemplate(
        input_variables=["paragraph", "num_questions"],
        template=prompt_template
    )
    llm_chain = LLMChain(llm=llm, prompt=prompt)

    try:
        response = llm_chain.predict(
            paragraph=paragraph,
            num_questions=str(num_questions)
        )
        return extract_valid_json(response)
    except Exception as e:
        print(f"Error generating {question_type} questions: {e}")
        return []

# Function to generate questions in chunks
def generate_questions_in_chunks(paragraph, question_type, total_questions, prompt_template, chunk_size=10):
    """
    Generate questions in chunks to avoid exceeding token limits.
    """
    all_questions = []
    for _ in range(0, total_questions, chunk_size):
        try:
            chunk_questions = generate_questions(paragraph, question_type, chunk_size, prompt_template)
            all_questions.extend(chunk_questions)
        except Exception as e:
            print(f"Error generating chunk for {question_type}: {e}")
            continue
    return all_questions

# Function to generate questions for all types
def generate_questions_by_all_types(paragraph, total_questions, chunk_size=10):
    question_types_and_prompts = {
        "Factual": FACTUAL_PROMPT,
        "Procedural": PROCEDURAL_PROMPT,
        "Reasoning-based": REASONING_PROMPT,
    }

    all_questions = []
    for question_type, prompt in question_types_and_prompts.items():
        questions = generate_questions_in_chunks(paragraph, question_type, total_questions, prompt, chunk_size)
        for qa in questions:
            all_questions.append({
                "Question Type": question_type,
                "Question": qa["question"],
                "Answer": qa["answer"]
            })
    return all_questions

# Function to save results to Excel
def save_to_excel(questions_and_answers, output_file):
    if questions_and_answers:
        df = pd.DataFrame(questions_and_answers)
        df.to_excel(output_file, index=False)
        print(f"Questions and answers saved to {output_file}.")
    else:
        print(f"No data to save for {output_file}.")

# Function to process all PDF files in a directory and its subdirectories
def process_pdfs_in_subdirectories(root_directory, total_questions=10, chunk_size=10, output_folder="output"):
    """
    Processes all PDF files in the given directory and its subdirectories.
    """
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    for dirpath, _, filenames in os.walk(root_directory):
        for filename in filenames:
            if filename.endswith('.pdf'):
                pdf_path = os.path.join(dirpath, filename)
                try:
                    print(f"Processing: {pdf_path}")
                    # Extract text from the PDF
                    pdf_text = extract_text_from_pdf(pdf_path)

                    # Generate questions
                    questions_and_answers = generate_questions_by_all_types(pdf_text, total_questions, chunk_size)

                    # Save results to Excel
                    relative_path = os.path.relpath(pdf_path, root_directory)
                    output_file = os.path.join(output_folder, relative_path.replace(".pdf", "_questions.xlsx"))

                    # Ensure the subdirectory structure in the output folder
                    os.makedirs(os.path.dirname(output_file), exist_ok=True)
                    save_to_excel(questions_and_answers, output_file)
                except Exception as e:
                    print(f"Error processing {pdf_path}: {e}")















import os
from langchain.prompts.prompt import PromptTemplate
from langchain.chains import LLMChain
from langchain.chat_models import AzureChatOpenAI
import PyPDF2
import pandas as pd
import json

# Updated Factual Prompt
FACTUAL_PROMPT = """
    You are a financial expert with deep expertise in corporate finance, investment strategies, and accounting.
    Your task is to generate {num_questions} factual question-answer pairs based on the input text.

    Ensure:
    - Questions are focused on names, titles, or specific entities mentioned in the input text.
    - Answers are precise and concise.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "What is the name of the entity mentioned in the input text?",
            "answer": "Name or entity mentioned in the input text."
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

# Updated Procedural Prompt
PROCEDURAL_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate {num_questions} procedural question-answer pairs based on the input text.

    Ensure:
    - Questions focus on processes, methods, or sequences of steps.
    - Answers provide detailed, step-by-step instructions with clear descriptions for each step.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "What are the steps to achieve or complete this process?",
            "answer": [
                "Step 1: Describe the first action or decision clearly.",
                "Step 2: Provide the next step with clarity and details.",
                "Step 3: Add any additional steps needed for completion.",
                ...
            ]
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

# Updated Reasoning-Based Prompt
REASONING_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate {num_questions} reasoning-based question-answer pairs based on the input text.

    Ensure:
    - All questions begin with "Why".
    - Questions require logical argumentation, critical thinking, or evaluation.
    - Answers justify conclusions with clear and logical reasoning.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "Why does this happen or exist based on the input text?",
            "answer": "Detailed reasoning or justification for the question."
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

# Function to extract text from a PDF
def extract_text_from_pdf(pdf_path):
    text = ""
    with open(pdf_path, 'rb') as file:
        reader = PyPDF2.PdfReader(file)
        for page in reader.pages:
            text += page.extract_text()
    return text

# Function to generate questions for a specific type
def generate_questions(paragraph, question_type, num_questions, prompt_template):
    llm = AzureChatOpenAI(
        temperature=0,
        api_version="2023-06-01-preview",
        azure_openai_api_base="YOUR_AZURE_ENDPOINT",  # Replace with your Azure endpoint
        deployment_name="ssgpt-40"
    )

    prompt = PromptTemplate(
        input_variables=["paragraph", "num_questions"],
        template=prompt_template
    )
    llm_chain = LLMChain(llm=llm, prompt=prompt)

    try:
        response = llm_chain.predict(
            paragraph=paragraph,
            num_questions=str(num_questions)
        )
        return json.loads(response)
    except json.JSONDecodeError:
        print(f"Error: Invalid JSON for {question_type} questions.")
        return []
    except Exception as e:
        print(f"Error generating {question_type} questions: {e}")
        return []

# Function to generate questions for all types
def generate_questions_by_all_types(paragraph, num_questions):
    question_types_and_prompts = {
        "Factual": FACTUAL_PROMPT,
        "Procedural": PROCEDURAL_PROMPT,
        "Reasoning-based": REASONING_PROMPT,
    }

    all_questions = []
    for question_type, prompt in question_types_and_prompts.items():
        questions = generate_questions(paragraph, question_type, num_questions, prompt)
        for qa in questions:
            all_questions.append({
                "Question Type": question_type,
                "Question": qa["question"],
                "Answer": qa["answer"]
            })
    return all_questions

# Function to save results to Excel
def save_to_excel(questions_and_answers, output_file):
    if questions_and_answers:
        df = pd.DataFrame(questions_and_answers)
        df.to_excel(output_file, index=False)
        print(f"Questions and answers saved to {output_file}.")
    else:
        print(f"No data to sav

















import os
from langchain.prompts.prompt import PromptTemplate
from langchain.chains import LLMChain
from langchain.chat_models import AzureChatOpenAI
import PyPDF2
import pandas as pd
import json

# Prompts remain the same as earlier

# Function to extract text from a PDF
def extract_text_from_pdf(pdf_path):
    text = ""
    with open(pdf_path, 'rb') as file:
        reader = PyPDF2.PdfReader(file)
        for page in reader.pages:
            text += page.extract_text()
    return text

# Function to generate questions for a specific type
def generate_questions(paragraph, question_type, num_questions, prompt_template):
    llm = AzureChatOpenAI(
        temperature=0,
        api_version="2023-06-01-preview",
        azure_openai_api_base="YOUR_AZURE_ENDPOINT",  # Replace with your Azure endpoint
        deployment_name="ssgpt-40"
    )

    prompt = PromptTemplate(
        input_variables=["paragraph", "num_questions"],
        template=prompt_template
    )
    llm_chain = LLMChain(llm=llm, prompt=prompt)

    try:
        response = llm_chain.predict(
            paragraph=paragraph,
            num_questions=str(num_questions)
        )
        return json.loads(response)
    except json.JSONDecodeError:
        print(f"Error: Invalid JSON for {question_type} questions.")
        return []
    except Exception as e:
        print(f"Error generating {question_type} questions: {e}")
        return []

# Function to generate questions for all types
def generate_questions_by_all_types(paragraph, num_questions):
    question_types_and_prompts = {
        "Factual": FACTUAL_PROMPT,
        "Procedural": PROCEDURAL_PROMPT,
        "Explanatory": EXPLANATORY_PROMPT,
        "Inferential": INFERENTIAL_PROMPT,
        "Conceptual": CONCEPTUAL_PROMPT,
        "Reasoning-based": REASONING_PROMPT,
    }

    all_questions = []
    for question_type, prompt in question_types_and_prompts.items():
        questions = generate_questions(paragraph, question_type, num_questions, prompt)
        for qa in questions:
            all_questions.append({
                "Question Type": question_type,
                "Question": qa["question"],
                "Answer": qa["answer"]
            })
    return all_questions

# Function to save results to Excel
def save_to_excel(questions_and_answers, output_file):
    if questions_and_answers:
        df = pd.DataFrame(questions_and_answers)
        df.to_excel(output_file, index=False)
        print(f"Questions and answers saved to {output_file}.")
    else:
        print(f"No data to save for {output_file}.")

# Function to process all PDF files in a directory and its subdirectories
def process_pdfs_in_subdirectories(root_directory, num_questions=3, output_folder="output"):
    """
    Processes all PDF files in the given directory and its subdirectories.
    """
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    for dirpath, _, filenames in os.walk(root_directory):
        for filename in filenames:
            if filename.endswith('.pdf'):
                pdf_path = os.path.join(dirpath, filename)
                try:
                    print(f"Processing: {pdf_path}")
                    # Extract text from the PDF
                    pdf_text = extract_text_from_pdf(pdf_path)

                    # Generate questions
                    questions_and_answers = generate_questions_by_all_types(pdf_text, num_questions)

                    # Save results to Excel
                    relative_path = os.path.relpath(pdf_path, root_directory)
                    output_file = os.path.join(output_folder, relative_path.replace(".pdf", "_questions.xlsx"))

                    # Ensure the subdirectory structure in the output folder
                    os.makedirs(os.path.dirname(output_file), exist_ok=True)
                    save_to_excel(questions_and_answers, output_file)
                except Exception as e:
                    print(f"Error processing {pdf_path}: {e}")


















import os
from langchain.prompts.prompt import PromptTemplate
from langchain.chains import LLMChain
from langchain.chat_models import AzureChatOpenAI
import PyPDF2
import pandas as pd
import json

# Prompts remain the same as provided in earlier examples

# Function to extract text from a PDF
def extract_text_from_pdf(pdf_path):
    text = ""
    with open(pdf_path, 'rb') as file:
        reader = PyPDF2.PdfReader(file)
        for page in reader.pages:
            text += page.extract_text()
    return text

# Function to generate questions for a specific type
def generate_questions(paragraph, question_type, num_questions, prompt_template):
    llm = AzureChatOpenAI(
        temperature=0,
        api_version="2023-06-01-preview",
        azure_openai_api_base="YOUR_AZURE_ENDPOINT",  # Replace with your Azure endpoint
        deployment_name="ssgpt-40"
    )

    prompt = PromptTemplate(
        input_variables=["paragraph", "num_questions"],
        template=prompt_template
    )
    llm_chain = LLMChain(llm=llm, prompt=prompt)

    try:
        response = llm_chain.predict(
            paragraph=paragraph,
            num_questions=str(num_questions)
        )
        return json.loads(response)
    except json.JSONDecodeError:
        print(f"Error: Invalid JSON for {question_type} questions.")
        return []
    except Exception as e:
        print(f"Error generating {question_type} questions: {e}")
        return []

# Function to generate questions for all types
def generate_questions_by_all_types(paragraph, num_questions):
    question_types_and_prompts = {
        "Factual": FACTUAL_PROMPT,
        "Procedural": PROCEDURAL_PROMPT,
        "Explanatory": EXPLANATORY_PROMPT,
        "Inferential": INFERENTIAL_PROMPT,
        "Conceptual": CONCEPTUAL_PROMPT,
        "Reasoning-based": REASONING_PROMPT,
    }

    all_questions = []
    for question_type, prompt in question_types_and_prompts.items():
        questions = generate_questions(paragraph, question_type, num_questions, prompt)
        for qa in questions:
            all_questions.append({
                "Question Type": question_type,
                "Question": qa["question"],
                "Answer": qa["answer"]
            })
    return all_questions

# Function to save results to Excel
def save_to_excel(questions_and_answers, output_file):
    if questions_and_answers:
        df = pd.DataFrame(questions_and_answers)
        df.to_excel(output_file, index=False)
        print(f"Questions and answers saved to {output_file}.")
    else:
        print(f"No data to save for {output_file}.")

# Function to process all PDF files in a directory
def process_pdfs_in_directory(directory_path, num_questions=3, output_folder="output"):
    """
    Processes all PDF files in the given directory and generates categorized questions.
    """
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    pdf_files = [f for f in os.listdir(directory_path) if f.endswith('.pdf')]
    for pdf_file in pdf_files:
        pdf_path = os.path.join(directory_path, pdf_file)
        try:
            print(f"Processing: {pdf_path}")
            # Extract text from the PDF
            pdf_text = extract_text_from_pdf(pdf_path)

            # Generate questions
            questions_and_answers = generate_questions_by_all_types(pdf_text, num_questions)

            # Save results to Excel
            output_file = os.path.join(output_folder, pdf_file.replace(".pdf", "_questions.xlsx"))
            save_to_excel(questions_and_answers, output_file)
        except Exception as e:
            print(f"Error processing {pdf_file}: {e}")



















from langchain.prompts.prompt import PromptTemplate
from langchain.chains import LLMChain
from langchain.chat_models import AzureChatOpenAI
import PyPDF2
import pandas as pd
import json

# Define prompts for each question type
FACTUAL_PROMPT = """
    You are a financial expert with deep expertise in corporate finance, investment strategies, and accounting.
    Your task is to generate {num_questions} factual question-answer pairs based on the input text.

    Ensure:
    - Questions focus on specific details, definitions, or data.
    - Answers are precise and concise.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "Your factual question here",
            "answer": "Your factual answer here"
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

PROCEDURAL_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate {num_questions} procedural question-answer pairs based on the input text.

    Ensure:
    - Questions focus on processes, methods, or sequences of steps.
    - Answers provide detailed, step-by-step explanations.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "Your procedural question here",
            "answer": [
                "Step 1: Description of the first step.",
                "Step 2: Description of the second step.",
                ...
            ]
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

EXPLANATORY_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate {num_questions} explanatory question-answer pairs based on the input text.

    Ensure:
    - Questions aim to clarify concepts or ideas in the text.
    - Answers are comprehensive, including step-by-step reasoning.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "Your explanatory question here",
            "answer": [
                "Step 1: Introduction to the concept or idea.",
                "Step 2: Explanation of key elements.",
                "Step 3: How these elements interact or apply in practice.",
                ...
            ]
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

INFERENTIAL_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate {num_questions} inferential question-answer pairs based on the input text.

    Ensure:
    - Questions encourage interpretation or conclusions based on the data.
    - Answers justify inferences with logical reasoning.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "Your inferential question here",
            "answer": "Your inference-based answer with justification here."
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

CONCEPTUAL_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate {num_questions} conceptual question-answer pairs based on the input text.

    Ensure:
    - Questions explore theories, principles, or ideas.
    - Answers provide detailed explanations of the underlying concepts.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "Your conceptual question here",
            "answer": "Your conceptual answer here."
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

REASONING_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate {num_questions} reasoning-based question-answer pairs based on the input text.

    Ensure:
    - Questions require logical argumentation or critical thinking.
    - Answers justify conclusions with clear and logical reasoning.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "Your reasoning-based question here",
            "answer": "Your reasoning-based answer with justification here."
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

# Extract text from a PDF
def extract_text_from_pdf(pdf_path):
    text = ""
    with open(pdf_path, 'rb') as file:
        reader = PyPDF2.PdfReader(file)
        for page in reader.pages:
            text += page.extract_text()
    return text

# Generate questions for a specific type
def generate_questions(paragraph, question_type, num_questions, prompt_template):
    llm = AzureChatOpenAI(
        temperature=0,
        api_version="2023-06-01-preview",
        azure_openai_api_base="YOUR_AZURE_ENDPOINT",  # Replace with your Azure endpoint
        deployment_name="ssgpt-40"
    )

    prompt = PromptTemplate(
        input_variables=["paragraph", "num_questions"],
        template=prompt_template
    )
    llm_chain = LLMChain(llm=llm, prompt=prompt)

    try:
        response = llm_chain.predict(
            paragraph=paragraph,
            num_questions=str(num_questions)
        )
        return json.loads(response)
    except json.JSONDecodeError:
        print(f"Error: Invalid JSON for {question_type} questions.")
        return []
    except Exception as e:
        print(f"Error generating {question_type} questions: {e}")
        return []

# Generate questions for all types
def generate_questions_by_all_types(paragraph, num_questions):
    question_types_and_prompts = {
        "Factual": FACTUAL_PROMPT,
        "Procedural": PROCEDURAL_PROMPT,
        "Explanatory": EXPLANATORY_PROMPT,
        "Inferential": INFERENTIAL_PROMPT,
        "Conceptual": CONCEPTUAL_PROMPT,
        "Reasoning-based": REASONING_PROMPT,
    }

    all_questions = []
    for question_type, prompt in question_types_and_prompts.items():
        questions = generate_questions(paragraph, question_type, num_questions, prompt)
        for qa in questions:
            all_questions.append({
                "Question Type": question_type,
                "Question": qa["question"],
                "Answer": qa["answer"]
            })
    return all_questions

# Save results to Excel
def save_to_excel(questions_and_answers, output_file="questions_by_type.xlsx"):
    if questions_and_answers:
        df = pd.DataFrame(questions_and_answers)
        df.to_excel(output_file, index=False)
        print(f"Questions and answers saved to {output_file}.")
    else:
        print("No data to save.")

# Process multiple PDFs in a loop
def process_multiple_pdfs(pdf_paths, num_questions=3, output_folder="output"):
    """
    Process multiple PDFs and generate categorized questions for each.
    """
    for pdf_path in pdf_paths:
        try:
            print(f"Processing PDF: {pdf_path}")
            # Extract text
            pdf_text = extract_text_from_pdf(pdf_path)

            # Generate questions
            questions_and_answers = generate_questions_by_all_types(pdf_text, num_questions)

            # Save to Excel
            output_file = f"{output_folder}/{pdf_path.split('/')[-1].replace('.pdf', '_questions.xlsx')}"
            save_to_excel(questions_and_answers, output_file)

        except Exception as e:
            print(f"Error processing {pdf_path}: {e}")



















from langchain.prompts.prompt import PromptTemplate
from langchain.chains import LLMChain
from langchain.chat_models import AzureChatOpenAI
import PyPDF2
import pandas as pd
import json

# Define separate prompts for each question type
FACTUAL_PROMPT = """
    You are a financial expert with deep expertise in corporate finance, investment strategies, and accounting.
    Your task is to generate {num_questions} factual question-answer pairs based on the input text.

    Ensure:
    - Questions focus on specific details, definitions, or data.
    - Answers are precise and concise.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "Your factual question here",
            "answer": "Your factual answer here"
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

PROCEDURAL_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate {num_questions} procedural question-answer pairs based on the input text.

    Ensure:
    - Questions focus on processes, methods, or sequences of steps.
    - Answers provide detailed, step-by-step explanations.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "Your procedural question here",
            "answer": [
                "Step 1: Description of the first step.",
                "Step 2: Description of the second step.",
                ...
            ]
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

EXPLANATORY_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate {num_questions} explanatory question-answer pairs based on the input text.

    Ensure:
    - Questions aim to clarify concepts or ideas in the text.
    - Answers are comprehensive, including step-by-step reasoning.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "Your explanatory question here",
            "answer": [
                "Step 1: Introduction to the concept or idea.",
                "Step 2: Explanation of key elements.",
                "Step 3: How these elements interact or apply in practice.",
                ...
            ]
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

INFERENTIAL_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate {num_questions} inferential question-answer pairs based on the input text.

    Ensure:
    - Questions encourage interpretation or conclusions based on the data.
    - Answers justify inferences with logical reasoning.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "Your inferential question here",
            "answer": "Your inference-based answer with justification here."
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

CONCEPTUAL_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate {num_questions} conceptual question-answer pairs based on the input text.

    Ensure:
    - Questions explore theories, principles, or ideas.
    - Answers provide detailed explanations of the underlying concepts.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "Your conceptual question here",
            "answer": "Your conceptual answer here."
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

REASONING_PROMPT = """
    You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
    Generate {num_questions} reasoning-based question-answer pairs based on the input text.

    Ensure:
    - Questions require logical argumentation or critical thinking.
    - Answers justify conclusions with clear and logical reasoning.

    Input Text: {paragraph}

    Output format:
    [
        {{
            "question": "Your reasoning-based question here",
            "answer": "Your reasoning-based answer with justification here."
        }},
        ...
    ]
    Ensure the response is a valid JSON array.
"""

# Function to extract text from a PDF
def extract_text_from_pdf(pdf_path):
    """
    Extracts text from a PDF file.
    """
    text = ""
    with open(pdf_path, 'rb') as file:
        reader = PyPDF2.PdfReader(file)
        for page in reader.pages:
            text += page.extract_text()
    return text

# Function to generate questions for a specific type
def generate_questions(paragraph, question_type, num_questions, prompt_template):
    """
    Generates questions for a specific question type.
    """
    llm = AzureChatOpenAI(
        temperature=0,
        api_version="2023-06-01-preview",
        azure_openai_api_base="YOUR_AZURE_ENDPOINT",  # Replace with your Azure endpoint
        deployment_name="ssgpt-40"
    )

    prompt = PromptTemplate(
        input_variables=["paragraph", "num_questions"],
        template=prompt_template
    )
    llm_chain = LLMChain(llm=llm, prompt=prompt)

    try:
        response = llm_chain.predict(
            paragraph=paragraph,
            num_questions=str(num_questions)
        )
        return json.loads(response)
    except json.JSONDecodeError:
        print(f"Error: Invalid JSON for {question_type} questions.")
        print("Raw Response:", response)
        return []
    except Exception as e:
        print(f"Error generating {question_type} questions: {e}")
        return []

# Main function to generate questions for all types
def generate_questions_by_all_types(paragraph, num_questions):
    """
    Generate categorized questions for all types.
    """
    question_types_and_prompts = {
        "Factual": FACTUAL_PROMPT,
        "Procedural": PROCEDURAL_PROMPT,
        "Explanatory": EXPLANATORY_PROMPT,
        "Inferential": INFERENTIAL_PROMPT,
        "Conceptual": CONCEPTUAL_PROMPT,
        "Reasoning-based": REASONING_PROMPT,
    }

    all_questions = []
    for question_type, prompt in question_types_and_prompts.items():
        questions = generate_questions(paragraph, question_type, num_questions, prompt)
        for qa in questions:
            all_questions.append({
                "Question Type": question_type,
                "Question": qa["question"],
                "Answer": qa["answer"]
            })
    return all_questions

# Function to save results to Excel
def save_to_excel(questions_and_answers, output_file="questions_by_type.xlsx"):
    """
    Saves categorized questions and answers to an Excel file.
    """
    if questions_and_answers:
        df = pd.DataFrame(questions_and_answers)
        df.to_excel(output_file, index=False)
        print(f"Questions and answers saved to {output_file}.")
    else:
        print("No data to save.")

# Main Execution
if __name__ == "__main__":
    pdf_path = "your_pdf_file.pdf"  # Replace with the path to your PDF file

    try:
        # Extract text from the PDF
        pdf_text = extract_text_from_pdf(pdf_path)

        # Generate categorized questions
        questions_and_answers = generate_questions_by_all_types(pdf_text, num_questions=3)

        # Save the output to an Excel file
        if questions_and_answers:
            save_to_excel(questions_and_answers, "questions_by_type.xlsx")
        else:
            print("No questions generated.")
    except Exception as e:
        print(f"Error: {e}")










from langchain.prompts.prompt import PromptTemplate
from langchain.chains import LLMChain
from langchain.chat_models import AzureChatOpenAI
import pandas as pd
import json

def generate_questions_by_type(paragraph, num_questions=3):
    """
    Generates categorized questions and answers (Factual, Procedural, etc.)
    """
    question_types = [
        "Factual",
        "Procedural",
        "Explanatory",
        "Inferential",
        "Conceptual",
        "Reasoning-based"
    ]

    # Define prompts for each question type
    prompt_templates = {
        "Factual": """
            You are a financial expert with a deep understanding of corporate finance, investment strategies, and accounting.
            Generate {num_questions} factual question-answer pairs based on the input text.
            
            Factual questions should:
            - Focus on specific details, definitions, or data.
            - Provide precise answers without unnecessary elaboration.

            Input Text: {paragraph}

            Output:
            [
                {{
                    "question": "Your factual question here",
                    "answer": "Your factual answer here"
                }},
                ...
            ]
            Ensure the response is a valid JSON object.
        """,
        "Procedural": """
            You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
            Generate {num_questions} procedural question-answer pairs based on the input text.

            Procedural questions should:
            - Focus on processes, methods, or sequences of steps.
            - Provide step-by-step answers that are logical and easy to follow.

            Input Text: {paragraph}

            Output:
            [
                {{
                    "question": "Your procedural question here",
                    "answer": [
                        "Step 1: Description of the first step.",
                        "Step 2: Description of the second step.",
                        "Step 3: Description of the third step."
                    ]
                }},
                ...
            ]
            Ensure the response is a valid JSON object.
        """,
        "Explanatory": """
            You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
            Generate {num_questions} explanatory question-answer pairs based on the input text.

            Explanatory questions should:
            - Clarify complex concepts or ideas in the text.
            - Provide step-by-step explanations to improve understanding.

            Input Text: {paragraph}

            Output:
            [
                {{
                    "question": "Your explanatory question here",
                    "answer": [
                        "Step 1: Introduction to the concept or idea.",
                        "Step 2: Explanation of the key elements.",
                        "Step 3: How these elements interact or apply in practice.",
                        "Step 4: Conclusion or summary of the explanation."
                    ]
                }},
                ...
            ]
            Ensure the response is a valid JSON object.
        """,
        "Inferential": """
            You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
            Generate {num_questions} inferential question-answer pairs based on the input text.

            Inferential questions should:
            - Require interpreting information or drawing logical conclusions.
            - Encourage predictions or implications based on the provided data.
            - Include answers that justify the inference with clear reasoning.

            Input Text: {paragraph}

            Output:
            [
                {{
                    "question": "Your inferential question here",
                    "answer": "Your inference-based answer with justification here."
                }},
                ...
            ]
            Ensure the response is a valid JSON object.
        """,
        "Conceptual": """
            You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
            Generate {num_questions} conceptual question-answer pairs based on the input text.

            Conceptual questions should:
            - Explore theories, principles, or abstract ideas.
            - Provide answers that are detailed and cover the underlying concepts comprehensively.

            Input Text: {paragraph}

            Output:
            [
                {{
                    "question": "Your conceptual question here",
                    "answer": "Your conceptual answer here."
                }},
                ...
            ]
            Ensure the response is a valid JSON object.
        """,
        "Reasoning-based": """
            You are a financial expert with expertise in corporate finance, investment strategies, and accounting.
            Generate {num_questions} reasoning-based question-answer pairs based on the input text.

            Reasoning-based questions should:
            - Require logical argumentation, critical thinking, or evaluation.
            - Include answers that justify conclusions with a logical explanation.

            Input Text: {paragraph}

            Output:
            [
                {{
                    "question": "Your reasoning-based question here",
                    "answer": "Your reasoning-based answer with justification here."
                }},
                ...
            ]
            Ensure the response is a valid JSON object.
        """
    }

    # Initialize the Azure LLM
    llm = AzureChatOpenAI(
        temperature=0,
        api_version="2023-06-01-preview",
        azure_openai_api_base="YOUR_AZURE_ENDPOINT",  # Replace with your Azure endpoint
        deployment_name="ssgpt-40"
    )

    all_questions = []
    for question_type, template in prompt_templates.items():
        try:
            prompt = PromptTemplate(input_variables=["paragraph", "num_questions"], template=template)
            llm_chain = LLMChain(llm=llm, prompt=prompt)

            response = llm_chain.predict(paragraph=paragraph, num_questions=str(num_questions))
            questions_and_answers = json.loads(response)

            for qa in questions_and_answers:
                all_questions.append({
                    "Question Type": question_type,
                    "Question": qa["question"],
                    "Answer": qa["answer"]
                })
        except json.JSONDecodeError:
            print(f"Error: Invalid JSON for {question_type} questions.")
            print("Raw Response:", response)
        except Exception as e:
            print(f"Error generating {question_type} questions: {e}")

    return all_questions

# Save results to Excel
def save_to_excel(questions_and_answers, output_file="questions_by_type.xlsx"):
    """
    Saves categorized questions and answers to an Excel file.
    """
    if questions_and_answers:
        df = pd.DataFrame(questions_and_answers)
        df.to_excel(output_file, index=False)
        print(f"Questions and answers saved to {output_file}.")
    else:
        print("No data to save.")

# Main execution
if __name__ == "__main__":
    paragraph = """
    The Management Fee is a percentage of the committed capital used to cover operational costs. 
    The term of the fund is 10 years, with an option for two 1-year extensions. 
    Investors are responsible for operational and organizational expenses, including the Investor Servicing Fee.
    """
    try:
        questions_and_answers = generate_questions_by_type(paragraph, num_questions=3)
        if questions_and_answers:
            save_to_excel(questions_and_answers, "questions_by_type.xlsx")
        else:
            print("No questions generated.")
    except Exception as e:
        print(f"Error: {e}")















from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

# Set Hugging Face cache directory
hf_home_path = r"/Volumes/dev2_catalog_01/default/txt-wtf-pe/hf/all-MiniLM-L6-v2"

# Load the model
model = SentenceTransformer(hf_home_path)
print("Model loaded successfully!")

# Example sentences
sentences = [
    "The weather is sunny and warm.",
    "It's a bright and sunny day.",
    "I love going to the beach when the weather is nice.",
    "Rainy days make me want to stay indoors."
]

# Generate embeddings for sentences
print("\nGenerating embeddings for sentences...")
embeddings = model.encode(sentences)
print("Embeddings generated!")

# Display embeddings
print("\nSentence embeddings:")
for i, embedding in enumerate(embeddings):
    print(f"Sentence {i + 1}: {sentences[i]}")
    print(f"Embedding (first 5 dimensions): {embedding[:5]}\n")

# Compute similarity between two sentences
print("\nCalculating similarity between the first two sentences...")
similarity = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]
print(f"Similarity between '{sentences[0]}' and '{sentences[1]}': {similarity:.2f}")

# Perform semantic search
print("\nPerforming semantic search...")
query = "What is the weather like?"
query_embedding = model.encode(query)
similarities = cosine_similarity([query_embedding], embeddings)[0]

# Find the most similar sentence
most_similar_idx = np.argmax(similarities)
print(f"Query: {query}")
print(f"Most similar sentence: {sentences[most_similar_idx]} (Similarity: {similarities[most_similar_idx]:.2f})")








combined_prompt_template = PromptTemplate(
    input_variables=["paragraph", "num_questions"],
    template="""
        You are an expert in finance and accounting. Your task is to generate {num_questions} question-answer pairs covering all the following types:
        - Factual
        - Procedural
        - Explanatory
        - Inferential
        - Conceptual
        - Reasoning-based

        Requirements:
        - Ensure an even distribution of questions among all types.
        - Questions should be clear, concise, and relevant to the text.
        - Answers should be accurate, comprehensive, and easy to understand.

        Input Text: {paragraph}

        Generate the response in the following JSON format:
        [
            {{
                "question": "Your question here",
                "answer": "Your answer here",
                "type": "Type of the question here (e.g., Factual, Procedural, etc.)"
            }},
            ...
        ]
        Ensure the response is a valid JSON and contains no extra text outside the JSON format.
    """
)







from langchain.prompts.prompt import PromptTemplate
from langchain.chains import LLMChain
from langchain.chat_models import AzureChatOpenAI
import pandas as pd
import json

def generate_questions_by_type(paragraph, num_questions=3):
    """
    Generates categorized questions and answers (Procedural, Explanatory, etc.)
    """
    question_types = [
        "Factual",
        "Procedural",
        "Explanatory",
        "Inferential",
        "Conceptual",
        "Reasoning-based"
    ]

    # Template for generating categorized questions
    prompt_template = PromptTemplate(
        input_variables=["paragraph", "question_type", "num_questions"],
        template="""
            You are a financial expert with expertise in corporate finance, investment strategies, and accounting. 
            Your task is to generate {num_questions} {question_type} question-answer pairs based on the input text.

            Ensure:
            - The questions are clear, concise, and aligned with the {question_type} type.
            - Answers are comprehensive yet easy to understand.
            - The response is a valid JSON array in the format:
              [
                  {{
                      "question": "Your question here",
                      "answer": "Your answer here"
                  }},
                  ...
              ]

            Input Text: {paragraph}
        """
    )

    # Create the LLM
    llm = AzureChatOpenAI(
        temperature=0,
        api_version="2023-06-01-preview",
        azure_openai_api_base="YOUR_AZURE_ENDPOINT",  # Replace with your Azure endpoint
        deployment_name="ssgpt-40"
    )

    llm_chain = LLMChain(llm=llm, prompt=prompt_template)

    # Generate questions for each type
    all_questions = []
    for question_type in question_types:
        try:
            response = llm_chain.predict(
                paragraph=paragraph,
                question_type=question_type,
                num_questions=str(num_questions)
            )
            questions_and_answers = json.loads(response)

            for qa in questions_and_answers:
                all_questions.append({
                    "Question Type": question_type,
                    "Question": qa["question"],
                    "Answer": qa["answer"]
                })
        except json.JSONDecodeError:
            print(f"Error: Invalid JSON for {question_type} questions.")
            continue
        except Exception as e:
            print(f"Error: {e}")
            continue

    return all_questions

def save_to_excel(questions_and_answers, output_file="questions_by_type.xlsx"):
    """
    Saves categorized questions and answers to an Excel file.
    """
    if questions_and_answers:
        df = pd.DataFrame(questions_and_answers)
        df.to_excel(output_file, index=False)
        print(f"Questions and answers saved to {output_file}.")
    else:
        print("No data to save.")

# Example Usage
paragraph = """
The Management Fee is a percentage of the committed capital used to cover operational costs. 
The term of the fund is 10 years, with an option for two 1-year extensions. 
Investors are responsible for operational and organizational expenses, including the Investor Servicing Fee.
"""

try:
    questions_and_answers = generate_questions_by_type(paragraph, num_questions=3)
    if questions_and_answers:
        save_to_excel(questions_and_answers, "questions_by_type.xlsx")
    else:
        print("No questions generated.")
except Exception as e:
    print(f"Error: {e}")













from langchain.prompts.prompt import PromptTemplate
from langchain.chains import LLMChain
from langchain.chat_models import AzureChatOpenAI
import PyPDF2
import pandas as pd
import json

def extract_text_from_pdf(pdf_path):
    """
    Extracts text from a PDF file.
    """
    text = ""
    with open(pdf_path, 'rb') as file:
        reader = PyPDF2.PdfReader(file)
        for page in reader.pages:
            text += page.extract_text()
    return text

def generate_questions_from_text(pdf_text, num_questions=25):
    """
    Generates question-answer pairs from the given text.
    """
    # Define the prompt template
    prompt_template = PromptTemplate(
        input_variables=["paragraph", "num_questions"],
        template="""
            You are a Financial expert with a deep understanding of corporate finance, investment strategies, and accounting. 
            Your task is to generate precise and accurate question-answer pairs based on the input text. 
            Each question should be clear, concise, and relevant to the financial domain, while the answers should be comprehensive yet easy to understand. 
            
            Ensure the questions target different levels of difficulty ranging from beginner to expert. Also, make sure there are different types of questions such as:
            - Factual
            - Procedural
            - Explanatory
            - Inferential
            - Conceptual
            - Reasoning-based

            Input Text: {paragraph}

            Generate {num_questions} questions along with their answers in the following JSON format:
            [
                {
                    "question": "Your question here",
                    "answer": "Your answer here"
                },
                ...
            ]
            Ensure the JSON format is valid and parsable.
        """
    )
    
    # Create the LLM
    llm = AzureChatOpenAI(
        temperature=0,
        api_version="2023-06-01-preview",
        azure_openai_api_base="YOUR_AZURE_ENDPOINT",  # Replace with your Azure endpoint
        deployment_name="ssgpt-40"
    )
    
    # Create LLM Chain
    llm_chain = LLMChain(llm=llm, prompt=prompt_template)
    
    # Generate the response
    try:
        response = llm_chain.predict(paragraph=pdf_text, num_questions=num_questions)
        questions_and_answers = json.loads(response)
        return questions_and_answers
    except json.JSONDecodeError:
        print("Error: The model response is not valid JSON.")
        print("Raw Response:", response)
        return []
    except Exception as e:
        print(f"Error: {e}")
        return []

def save_to_excel(questions_and_answers, output_file="questions_and_answers.xlsx"):
    """
    Saves the questions and answers to an Excel file.
    """
    if questions_and_answers:
        # Convert to DataFrame
        df = pd.DataFrame(questions_and_answers)
        # Save to Excel
        df.to_excel(output_file, index=False)
        print(f"Questions and answers saved to {output_file}.")
    else:
        print("No data to save.")

# Main Function to Process Entire PDF
pdf_path = "your_pdf_file.pdf"  # Replace with the actual PDF file path

try:
    # Step 1: Extract text from the PDF
    pdf_text = extract_text_from_pdf(pdf_path)
    print("PDF Text Extracted Successfully.")

    # Step 2: Generate questions and answers
    questions_and_answers = generate_questions_from_text(pdf_text, num_questions=25)
    if questions_and_answers:
        print("Questions and Answers Generated Successfully.")

        # Step 3: Save to Excel
        save_to_excel(questions_and_answers, "questions_and_answers.xlsx")
    else:
        print("No questions generated.")
except Exception as e:
    print(f"Error: {e}")









from langchain.prompts.prompt import PromptTemplate
from langchain.chains import LLMChain
from langchain.chat_models import AzureChatOpenAI
import PyPDF2
import pandas as pd
import json

def extract_text_from_pdf(pdf_path):
    """
    Extracts text from a PDF file.
    """
    text = ""
    with open(pdf_path, 'rb') as file:
        reader = PyPDF2.PdfReader(file)
        for page in reader.pages:
            text += page.extract_text()
    return text

def generate_questions_from_text(pdf_text, num_questions=25):
    """
    Generates question-answer pairs from the given text.
    """
    # Define the prompt template
    prompt_template = PromptTemplate(
        input_variables=["paragraph", "num_questions"],
        template="""
            You are a Financial expert with a deep understanding of corporate finance, investment strategies, and accounting. 
            Your task is to generate precise and accurate question-answer pairs based on the input text. 
            Each question should be clear, concise, and relevant to the financial domain, while the answers should be comprehensive yet easy to understand. 
            
            Ensure the questions target different levels of difficulty ranging from beginner to expert. Also, make sure there are different types of questions such as:
            - Factual
            - Procedural
            - Explanatory
            - Inferential
            - Conceptual
            - Reasoning-based

            Input Text: {paragraph}

            Generate {num_questions} questions along with their answers in the following JSON format:
            [
                {
                    "question": "Your question here",
                    "answer": "Your answer here"
                },
                ...
            ]
            Ensure the JSON format is valid and parsable.
        """
    )
    
    # Create the LLM
    llm = AzureChatOpenAI(
        temperature=0,
        api_version="2023-06-01-preview",  # Replace with your API version
        azure_openai_api_base="YOUR_AZURE_ENDPOINT",  # Replace with your Azure endpoint
        deployment_name="ssgpt-40"
    )
    
    # Create LLM Chain
    llm_chain = LLMChain(llm=llm, prompt=prompt_template)
    
    # Generate the response
    try:
        response = llm_chain.predict(paragraph=pdf_text, num_questions=num_questions)
        questions_and_answers = json.loads(response)
        return questions_and_answers
    except json.JSONDecodeError:
        print("Error: The model response is not valid JSON.")
        print("Raw Response:", response)
        return []
    except Exception as e:
        print(f"Error: {e}")
        return []

def save_to_excel(questions_and_answers, output_file="questions_and_answers.xlsx"):
    """
    Saves the questions and answers to an Excel file.
    """
    if questions_and_answers:
        # Convert to DataFrame
        df = pd.DataFrame(questions_and_answers)
        # Save to Excel
        df.to_excel(output_file, index=False)
        print(f"Questions and answers saved to {output_file}.")
    else:
        print("No data to save.")

# Path to the PDF file
pdf_path = "your_pdf_file.pdf"  # Replace with the actual file path

try:
    # Extract text from the PDF
    pdf_text = extract_text_from_pdf(pdf_path)
    print("PDF Text Extracted Successfully.")

    # Generate questions and answers
    questions_and_answers = generate_questions_from_text(pdf_text, num_questions=25)
    print("Questions and Answers Generated Successfully.")

    # Save to Excel
    save_to_excel(questions_and_answers, "questions_and_answers.xlsx")
except Exception as e:
    print(f"Error: {e}")







from langchain.prompts.prompt import PromptTemplate
from langchain.chains import LLMChain
from langchain.chat_models import AzureChatOpenAI
import PyPDF2
import pandas as pd
import json

def extract_text_from_pdf(pdf_path):
    """
    Extracts text from a PDF file.
    """
    text = ""
    with open(pdf_path, 'rb') as file:
        reader = PyPDF2.PdfReader(file)
        for page in reader.pages:
            text += page.extract_text()
    return text

def generate_questions_from_text(pdf_text, num_questions=25):
    """
    Generates question-answer pairs from the given text.
    """
    # Define the prompt template
    prompt_template = """
        You are a Financial expert with a deep understanding of corporate finance, investment strategies, and accounting. 
        Your task is to generate precise and accurate question-answer pairs based on the input text. 
        Each question should be clear, concise, and relevant to the financial domain, while the answers should be comprehensive yet easy to understand. 
        
        Ensure the questions target different levels of difficulty ranging from beginner to expert. Also, make sure there are different types of questions such as:
        - Factual
        - Procedural
        - Explanatory
        - Inferential
        - Conceptual
        - Reasoning-based

        Input Text: {paragraph}

        Generate {num_questions} questions along with their answers in the following JSON format:
        [
            {
                "question": "Your question here",
                "answer": "Your answer here"
            },
            ...
        ]
        Ensure the JSON format is valid and parsable.
    """
    
    # Create the LLM
    llm = AzureChatOpenAI(
        temperature=0,
        api_version="2023-06-01-preview",  # Replace with your API version
        azure_openai_api_base="YOUR_AZURE_ENDPOINT",  # Replace with your Azure endpoint
        deployment_name="ssgpt-40"
    )
    
    # Set up the prompt
    formatted_prompt = prompt_template.format(paragraph=pdf_text, num_questions=num_questions)
    
    # Generate the response
    response = llm(formatted_prompt)
    
    try:
        # Attempt to parse the response as JSON
        questions_and_answers = json.loads(response)
        return questions_and_answers
    except json.JSONDecodeError:
        print("Error: The model response is not valid JSON. Cleaning the response...")
        # Attempt to clean and parse
        cleaned_response = response.replace("\n", "").strip()
        try:
            questions_and_answers = json.loads(cleaned_response)
            return questions_and_answers
        except Exception as e:
            print("Failed to clean and parse JSON response.")
            print("Raw Response:", response)
            return []

def save_to_excel(questions_and_answers, output_file="questions_and_answers.xlsx"):
    """
    Saves the questions and answers to an Excel file.
    """
    if questions_and_answers:
        # Convert to DataFrame
        df = pd.DataFrame(questions_and_answers)
        # Save to Excel
        df.to_excel(output_file, index=False)
        print(f"Questions and answers saved to {output_file}.")
    else:
        print("No data to save.")

# Path to the PDF file
pdf_path = "your_pdf_file.pdf"  # Replace with the actual file path

try:
    # Extract text from the PDF
    pdf_text = extract_text_from_pdf(pdf_path)
    print("PDF Text Extracted Successfully.")

    # Generate questions and answers
    questions_and_answers = generate_questions_from_text(pdf_text, num_questions=25)
    print("Questions and Answers Generated Successfully.")

    # Save to Excel
    save_to_excel(questions_and_answers, "questions_and_answers.xlsx")
except Exception as e:
    print(f"Error: {e}")













from langchain.prompts.prompt import PromptTemplate
from langchain.chains import LLMChain
from langchain.chat_models import AzureChatOpenAI
import PyPDF2
import json
import pandas as pd

def extract_text_from_pdf(pdf_path):
    """
    Extracts text from a PDF file.
    """
    text = ""
    with open(pdf_path, 'rb') as file:
        reader = PyPDF2.PdfReader(file)
        for page in reader.pages:
            text += page.extract_text()
    return text

def generate_questions_from_text(pdf_text, num_questions=25):
    """
    Generates question-answer pairs from the given text.
    """
    # Define the prompt template
    prompt_template = """
        You are a Financial expert with a deep understanding of corporate finance, investment strategies, and accounting. 
        Your task is to generate precise and accurate question-answer pairs based on the input text. 
        Each question should be clear, concise, and relevant to the financial domain, while the answers should be comprehensive yet easy to understand. 
        
        Ensure the questions target different levels of difficulty ranging from beginner to expert. Also, make sure there are different types of questions such as:
        - Factual
        - Procedural
        - Explanatory
        - Inferential
        - Conceptual
        - Reasoning-based

        Input Text: {paragraph}

        Generate {num_questions} questions along with their answers in the following JSON format:
        [
            {
                "question": "Your question here",
                "answer": "Your answer here"
            },
            ...
        ]
        Ensure the JSON format is valid and parsable.
    """
    
    # Create the LLM
    llm = AzureChatOpenAI(
        temperature=0,
        api_version="2023-06-01-preview",  # Replace with your API version
        azure_openai_api_base="YOUR_AZURE_ENDPOINT",  # Replace with your Azure endpoint
        deployment_name="ssgpt-40"
    )
    
    # Set up the prompt
    formatted_prompt = prompt_template.format(paragraph=pdf_text, num_questions=num_questions)
    
    # Generate the response
    response = llm(formatted_prompt)
    
    try:
        # Attempt to parse the response as JSON
        questions_and_answers = json.loads(response)
        return questions_and_answers
    except json.JSONDecodeError:
        print("Error: The model response is not valid JSON.")
        print("Model Response:", response)
        return []

def save_to_excel(questions_and_answers, output_file="questions_and_answers.xlsx"):
    """
    Saves the questions and answers to an Excel file.
    """
    if questions_and_answers:
        # Convert to DataFrame
        df = pd.DataFrame(questions_and_answers)
        # Save to Excel
        df.to_excel(output_file, index=False)
        print(f"Questions and answers saved to {output_file}.")
    else:
        print("No data to save.")

# Path to the PDF file
pdf_path = "your_pdf_file.pdf"  # Replace with the actual file path

try:
    # Extract text from the PDF
    pdf_text = extract_text_from_pdf(pdf_path)
    print("PDF Text Extracted Successfully.")

    # Generate questions and answers
    questions_and_answers = generate_questions_from_text(pdf_text, num_questions=25)
    print("Questions and Answers Generated Successfully.")

    # Save to Excel
    save_to_excel(questions_and_answers, "questions_and_answers.xlsx")
except Exception as e:
    print(f"Error: {e}")










from langchain.prompts.prompt import PromptTemplate
from langchain.chains import LLMChain
from langchain.chat_models import AzureChatOpenAI
import PyPDF2
import json

def extract_text_from_pdf(pdf_path):
    """
    Extracts text from a PDF file.
    """
    text = ""
    with open(pdf_path, 'rb') as file:
        reader = PyPDF2.PdfReader(file)
        for page in reader.pages:
            text += page.extract_text()
    return text

def generate_questions_from_text(pdf_text, num_questions=25):
    """
    Generates question-answer pairs from the given text.
    """
    # Define the prompt template
    prompt_template = """
        You are a Financial expert with a deep understanding of corporate finance, investment strategies, and accounting. 
        Your task is to generate precise and accurate question-answer pairs based on the input text. 
        Each question should be clear, concise, and relevant to the financial domain, while the answers should be comprehensive yet easy to understand. 
        
        Ensure the questions target different levels of difficulty ranging from beginner to expert. Also, make sure there are different types of questions such as:
        - Factual
        - Procedural
        - Explanatory
        - Inferential
        - Conceptual
        - Reasoning-based

        Input Text: {paragraph}

        Generate {num_questions} questions along with their answers in the following JSON format:
        [
            {
                "question": "Your question here",
                "answer": "Your answer here"
            },
            ...
        ]
        Ensure the JSON format is valid and parsable.
    """
    
    # Create the LLM
    llm = AzureChatOpenAI(
        temperature=0,
        api_version="2023-06-01-preview",  # Replace with your API version
        azure_openai_api_base="YOUR_AZURE_ENDPOINT",  # Replace with your Azure endpoint
        deployment_name="ssgpt-40"
    )
    
    # Set up the prompt
    formatted_prompt = prompt_template.format(paragraph=pdf_text, num_questions=num_questions)
    
    # Generate the response
    response = llm(formatted_prompt)
    
    try:
        # Attempt to parse the response as JSON
        questions_and_answers = json.loads(response)
        return questions_and_answers
    except json.JSONDecodeError:
        print("Error: The model response is not valid JSON.")
        print("Model Response:", response)
        return []

# Path to the PDF file
pdf_path = "your_pdf_file.pdf"  # Replace with the actual file path

try:
    # Extract text from the PDF
    pdf_text = extract_text_from_pdf(pdf_path)
    print("PDF Text Extracted Successfully.")

    # Generate questions and answers
    questions_and_answers = generate_questions_from_text(pdf_text, num_questions=25)
    print("Questions and Answers Generated Successfully.")

    # Display the results
    print(json.dumps(questions_and_answers, indent=2))
except Exception as e:
    print(f"Error: {e}")







from langchain.prompts.prompt import PromptTemplate
from langchain.chains import LLMChain
from langchain.chat_models import AzureChatOpenAI
import PyPDF2
import json

def extract_text_from_pdf(pdf_path):
    """
    Extracts text from a PDF file.
    
    Args:
        pdf_path (str): Path to the PDF file.
        
    Returns:
        str: Combined text from all pages of the PDF.
    """
    text = ""
    with open(pdf_path, 'rb') as file:
        reader = PyPDF2.PdfReader(file)
        for page in reader.pages:
            text += page.extract_text()
    return text

def generate_questions_from_text(pdf_text, num_questions=25):
    """
    Generates question-answer pairs from the given text.
    
    Args:
        pdf_text (str): Input text to generate questions from.
        num_questions (int): Number of question-answer pairs to generate.
    
    Returns:
        list: List of question-answer pairs in JSON format.
    """
    # Define the prompt template
    prompt_template = """
        You are a Financial expert with a deep understanding of corporate finance, investment strategies, and accounting. 
        Your task is to generate precise and accurate question-answer pairs based on the input text. 
        Each question should be clear, concise, and relevant to the financial domain, while the answers should be comprehensive yet easy to understand. 
        
        Ensure the questions target different levels of difficulty ranging from beginner to expert. Also, make sure there are different types of questions such as:
        - Factual
        - Procedural
        - Explanatory
        - Inferential
        - Conceptual
        - Reasoning-based

        Input Text: {paragraph}

        Generate {num_questions} questions along with their answers. Present the output in JSON format as:
        [
            {
                "question": "Question text here",
                "answer": "Answer text here"
            },
            ...
        ]
    """
    
    # Create the LLM
    llm = AzureChatOpenAI(
        temperature=0,
        api_version="2023-06-01-preview",  # Replace with your actual API version
        azure_openai_api_base="YOUR_AZURE_ENDPOINT",  # Replace with your Azure endpoint
        deployment_name="ssgpt-40"
    )
    
    # Set up the prompt
    formatted_prompt = prompt_template.format(paragraph=pdf_text, num_questions=num_questions)
    
    # Generate the response
    response = llm(formatted_prompt)
    
    return json.loads(response)  # Parse the JSON output

# Path to the PDF file
pdf_path = "your_pdf_file.pdf"  # Replace with the actual file path

try:
    # Step 1: Extract text from the PDF
    pdf_text = extract_text_from_pdf(pdf_path)
    print("PDF Text Extracted Successfully.")

    # Step 2: Generate questions and answers
    questions_and_answers = generate_questions_from_text(pdf_text, num_questions=25)
    print("Questions and Answers Generated Successfully.")

    # Step 3: Display the results
    print(json.dumps(questions_and_answers, indent=2))

except Exception as e:
    print(f"Error: {e}")



# Path to the PDF file
pdf_path = "your_pdf_file.pdf"  # Replace with the actual file path

try:
    # Step 1: Extract text from the PDF
    pdf_text = extract_text_from_pdf(pdf_path)
    print("PDF Text Extracted Successfully.")

    # Step 2: Generate questions and answers
    questions_and_answers = generate_questions_from_text(pdf_text, num_questions=25)
    print("Questions and Answers Generated Successfully.")

    # Step 3: Display the results
    print(json.dumps(questions_and_answers, indent=2))

except Exception as e:
    print(f"Error: {e}")







from langchain.prompts import PromptTempla



te
from langchain.chains import LLMChain
from langchain.llms import AzureChatOpenAI
import PyPDF2

def extract_text_from_pdf(pdf_path):
    """
    Extracts text from a PDF file.
    
    Args:
        pdf_path (str): Path to the PDF file.
        
    Returns:
        str: Combined text from all pages of the PDF.
    """
    text = ""
    with open(pdf_path, 'rb') as file:
        reader = PyPDF2.PdfReader(file)
        for page in reader.pages:
            text += page.extract_text()
    return text

def generate_questions_from_text(pdf_text, num_questions=25):
    """
    Generates question-answer pairs from the given text.
    
    Args:
        pdf_text (str): Input text to generate questions from.
        num_questions (int): Number of question-answer pairs to generate.
    
    Returns:
        list: List of question-answer pairs in JSON format.
    """
    # Prompt template for generating questions and answers
    prompt_template = PromptTemplate.from_template("""
        You are a Financial expert with a deep understanding of corporate finance, investment strategies, and accounting. 
        Your task is to generate precise and accurate question-answer pairs based on the input text. 
        Each question should be clear, concise, and relevant to the financial domain, while the answers should be comprehensive yet easy to understand. 
        
        Ensure the questions target different levels of difficulty ranging from beginner to expert. Also, make sure there are different types of questions such as:
        - Factual
        - Procedural
        - Explanatory
        - Inferential
        - Conceptual
        - Reasoning-based

        Input Text: {paragraph}

        Generate {num_questions} questions along with their answers. Present the output in JSON format as:
        [
            {
                "question": "Question text here",
                "answer": "Answer text here"
            },
            ...
        ]
    """)

    # LLM setup
    llm = AzureChatOpenAI(
        temperature=0, 
        api_version="2023-06-01-preview",  # Replace with your actual API version
        azure_endpoint="YOUR_AZURE_ENDPOINT",  # Replace with your Azure endpoint
        deployment_name="ssgpt-40", 
        seed=42
    )

    # Create LLM Chain
    llm_chain = LLMChain(llm=llm, prompt=prompt_template)

    # Predict output
    output = llm_chain.predict(paragraph=pdf_text, num_questions=num_questions)

    return output


# Path to the PDF file
pdf_path = "your_pdf_file.pdf"  # Replace with the actual file path

try:
    # Step 1: Extract text from the PDF
    pdf_text = extract_text_from_pdf(pdf_path)
    print("PDF Text Extracted Successfully.")

    # Step 2: Generate questions and answers
    questions_and_answers = generate_questions_from_text(pdf_text, num_questions=25)
    print("Questions and Answers Generated Successfully.")

    # Step 3: Display the results
    import json
    print(json.dumps(questions_and_answers, indent=2))

except Exception as e:
    print(f"Error: {e}")













import os
from pathlib import Path
from sentence_transformers import SentenceTransformer

# Set Hugging Face cache directory
hf_home_path = r"C:\Users\subba\OneDrive\Desktop\test"
os.environ["HF_HOME"] = hf_home_path

# Ensure the directory exists
if not os.path.exists(hf_home_path):
    os.makedirs(hf_home_path, exist_ok=True)
print(f"Hugging Face cache directory set to: {hf_home_path}")

# Load model
try:
    print("Downloading model...")
    model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2", cache_folder=hf_home_path)
    print("Model downloaded successfully.")
except Exception as e:
    print(f"Error downloading model: {e}")

# Verify downloaded files
print(f"Checking downloaded files in: {hf_home_path}")
try:
    files = list(Path(hf_home_path).rglob("*"))
    if files:
        print("Downloaded files:")
        for file in files:
            print(file)
    else:
        print("No files found. Model might not have been saved properly.")
except Exception as e:
    print(f"Error checking files: {e}")   "give me example how we load the model use it
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

# Set Hugging Face cache directory
hf_home_path = r"C:\Users\subba\OneDrive\Desktop\test"

# Load the model
model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2", cache_folder=hf_home_path)
print("Model loaded successfully!")

# Example sentences
sentences = [
    "The weather is sunny and warm.",
    "Its a bright and sunny day.",
    "I love going to the beach when the weather is nice.",
    "Rainy days make me want to stay indoors."
]

# Generate embeddings for sentences
print("\nGenerating embeddings for sentences...")
embeddings = model.encode(sentences)
print("Embeddings generated!")

# Display embeddings
print("\nSentence embeddings:")
for i, embedding in enumerate(embeddings):
    print(f"Sentence {i+1}: {sentences[i]}")
    print(f"Embedding (first 5 dimensions): {embedding[:5]}\n")

# Compute similarity between two sentences
print("\nCalculating similarity between the first two sentences...")
similarity = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]
print(f"Similarity between '{sentences[0]}' and '{sentences[1]}': {similarity:.2f}")

# Perform semantic search
print("\nPerforming semantic search...")
query = "What is the weather like?"
query_embedding = model.encode(query)
similarities = cosine_similarity([query_embedding], embeddings)[0]

# Find the most similar sentence
most_similar_idx = np.argmax(similarities)
print(f"Query: {query}")
print(f"Most similar sentence: {sentences[most_similar_idx]} (Similarity: {similarities[most_similar_idx]:.2f})")








# Step 1: Stop Proxy
import os
from pathlib import Path
from transformers import AutoModelForCausalLM, AutoTokenizer

# Remove proxy settings if they exist
if "https_proxy" in os.environ:
    del os.environ["https_proxy"]
if "http_proxy" in os.environ:
    del os.environ["http_proxy"]

print("Proxy settings have been removed.")

# Step 2: Set Hugging Face Cache Directory
# Set the Hugging Face home to a writable directory in Databricks
hf_home_path = "/dbfs/tmp/huggingface_cache/"
os.environ["HF_HOME"] = hf_home_path

# Ensure the directory exists
if not os.path.exists(hf_home_path):
    os.makedirs(hf_home_path, exist_ok=True)
print(f"Hugging Face cache directory set to: {hf_home_path}")

# Step 3: Download Model and Tokenizer
model_name = "gpt2"  # Small model for testing

try:
    print("Downloading model...")
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        device_map="auto",  # Automatically map model to available devices
        trust_remote_code=True  # Allow downloading custom models if needed
    )
    print("Model downloaded successfully.")
except Exception as e:
    print(f"Error downloading model: {e}")

try:
    print("Downloading tokenizer...")
    tokenizer = AutoTokenizer.from_pretrained(
        model_name,
        trust_remote_code=True
    )
    print("Tokenizer downloaded successfully.")
except Exception as e:
    print(f"Error downloading tokenizer: {e}")

# Step 4: Verify Downloaded Files
print(f"Checking downloaded files in: {hf_home_path}")
try:
    files = list(Path(hf_home_path).rglob("*"))
    if files:
        print("Downloaded files:")
        for file in files:
            print(file)
    else:
        print("No files found. Model might not have been saved properly.")
except Exception as e:
    print(f"Error checking files: {e}")







import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
import os

# Environment setup
os.environ['CURL_CA_BUNDLE'] = ''
os.environ["HF_HOME"] = "/Volumes/dev2_catalog_01/default/txt-wtf-pe/hf/test-model/"  # Change to a test directory

# Small model for testing
model_name = "gpt2"  # You can also try "bert-base-uncased" or any lightweight model

# Load the model
print("Downloading model...")
try:
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        device_map='auto',  # Automatically map model to available devices
        trust_remote_code=True  # Allow downloading custom models if needed
    )
    print("Model downloaded successfully.")
except Exception as e:
    print(f"Error downloading model: {e}")

# Load the tokenizer
print("Downloading tokenizer...")
try:
    tokenizer = AutoTokenizer.from_pretrained(
        model_name,
        trust_remote_code=True
    )
    print("Tokenizer downloaded successfully.")
except Exception as e:
    print(f"Error downloading tokenizer: {e}")

# Check if the model and tokenizer are saved
hf_home_path = os.environ["HF_HOME"]
print(f"Checking model files in: {hf_home_path}")
try:
    from pathlib import Path

    files = list(Path(hf_home_path).rglob("*"))
    if files:
        print("Downloaded files:")
        for file in files:
            print(file)
    else:
        print("No files found. Model might not have been saved properly.")
except Exception as e:
    print(f"Error checking files: {e}")








import openai
import pandas as pd

# Set your OpenAI API key
openai.api_key = "your_openai_api_key"

def generate_questions(paragraph, num_questions=5):
    """
    Generate questions based on a paragraph using GPT-4.
    """
    prompt = f"""
    Based on the following paragraph, generate {num_questions} meaningful and relevant questions:
    
    Paragraph:
    {paragraph}
    
    Questions:
    """
    try:
        # Call GPT-4 model
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are a helpful assistant for generating questions."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=500,
            temperature=0.7
        )
        # Extract and return the questions
        questions = response['choices'][0]['message']['content']
        return questions.strip()
    except Exception as e:
        return f"Error: {e}"

def process_excel(file_path, output_path, num_questions=5):
    """
    Process the Excel file, generate questions for each paragraph, and save the results.
    """
    # Read the Excel file
    df = pd.read_excel(file_path)

    # Check for the required columns
    if 'Paragraph' not in df.columns:
        raise ValueError("The Excel file must contain a 'Paragraph' column.")

    # Generate questions for each paragraph
    questions_list = []
    for index, row in df.iterrows():
        paragraph = row['Paragraph']
        if pd.isna(paragraph):  # Skip empty paragraphs
            questions_list.append("")
            continue
        print(f"Generating questions for S. No {row['S. No']}...")
        questions = generate_questions(paragraph, num_questions=num_questions)
        questions_list.append(questions)

    # Add questions to a new column
    df['Questions'] = questions_list

    # Save the updated DataFrame to a new Excel file
    df.to_excel(output_path, index=False)
    print(f"Questions have been added and saved to {output_path}")

if __name__ == "__main__":
    # Input Excel file path
    input_file = "input_file.xlsx"  # Replace with your input file path
    output_file = "output_with_questions.xlsx"  # Replace with your desired output file path

    # Number of questions to generate per paragraph
    num_questions = 5

    # Process the Excel file
    process_excel(input_file, output_file, num_questions=num_questions)




import fitz  # PyMuPDF
import csv
import re

def is_invalid_heading(text):
    """Check if a heading is invalid (empty, only special characters, or only numbers)."""
    return re.fullmatch(r"[\W_]*|\d+", text.strip()) is not None

def extract_headings(line):
    """Extract headings or subheadings from a given line."""
    match = re.match(r"^(\d+(\.\d+)*\.?)\s+([^\.\n]+)", line)  # Match section numbers and titles
    heading = None

    if match:
        section = match.group(1)  # Section number (e.g., "1.", "1.1.")
        title = match.group(3)  # Title text (e.g., "Formation and Continuation")

        if not is_invalid_heading(title):  # Check if the heading is valid
            if len(section.split(".")) == 1:  # Top-level heading
                heading = {
                    "type": "Heading",
                    "section": section,
                    "text": section.strip() + " " + title.strip(),  # Combine section and title
                }
            elif len(section.split(".")) > 1:  # Subheading
                heading = {
                    "type": "Subheading",
                    "section": section,
                    "text": section.strip() + " " + title.strip(),  # Combine section and title
                }

    return heading

def extract_headings_from_pdf(pdf_path):
    """Extract headings from a PDF file."""
    headings = []
    document = fitz.open(pdf_path)

    for page_number in range(len(document)):
        page = document[page_number]
        blocks = page.get_text("dict")["blocks"]

        temp = ""

        for block in blocks:
            for line in block.get("lines", []):
                for span in line.get("spans", []):
                    # Identify headings based on font size or style
                    if span["size"] >= 10:  # Adjust threshold if needed
                        line_text = span["text"].strip()

                        if line_text != "":
                            if re.match(r'^\d+\.*\s*$', line_text):
                                # Likely a standalone section number
                                temp = line_text
                            else:
                                # Combine with previous line if it's a continuation
                                line_text = temp + " " + line_text if temp else line_text
                                temp = ""  # Reset temp after combining

                                # Extract headings
                                heading = extract_headings(line_text.strip())
                                if heading:
                                    headings.append({
                                        "page_number": page_number + 1,
                                        "type": heading["type"],
                                        "text": heading["text"].strip(),
                                    })

    return headings

def save_headings_to_csv(pdf_path):
    """Extract headings and save them to a CSV file."""
    headings = extract_headings_from_pdf(pdf_path)
    csv_file = pdf_path.replace(".pdf", "_headings.csv").replace(".PDF", "_headings.csv")

    with open(csv_file, mode="w", newline="", encoding="utf-8") as file:
        writer = csv.writer(file)
        writer.writerow(["Page", "Type", "Text"])  # CSV header
        for heading in headings:
            writer.writerow([heading["page_number"], heading["type"], heading["text"]])

    print(f"Results saved to the file: {csv_file}")

# Example usage:
# save_headings_to_csv("example.pdf")













import fitz  # PyMuPDF
import csv
import re

def is_invalid_heading(text):
    # Check if a heading is invalid (empty, only special characters, or only numbers).
    return re.fullmatch(r"[\W_]*|\d+", text.strip()) is not None

def extract_headings(line):
    # Match patterns like "1.", "1.1", etc., followed by a heading
    match = re.match(r"^(\d+(\.\d+)*\.?)\s+([^\.\n]+)", line)
    heading = None

    if match:
        section = match.group(1)  # Section number (e.g., "1.", "1.1.")
        title = match.group(3)    # Title text
        if not is_invalid_heading(title):
            if len(section.split(".")) == 1:  # Top-level heading (e.g., "1.")
                heading = {
                    "type": "Heading",
                    "section": section,
                    "text": title.strip()
                }
            elif len(section.split(".")) > 1:  # Subheading (e.g., "1.1")
                heading = {
                    "type": "Subheading",
                    "section": section,
                    "text": title.strip()
                }
    return heading

def extract_headings_from_pdf(pdf_path):
    headings = []
    document = fitz.open(pdf_path)

    for page_number in range(len(document)):
        page = document[page_number]
        blocks = page.get_text("dict")["blocks"]

        for block in blocks:
            temp_line = ""
            for line in block.get("lines", []):
                for span in line.get("spans", []):
                    if span["size"] >= 10:  # Adjust this threshold for font size
                        line_text = span["text"].strip()
                        if re.match(r'^\d+\.*$', line_text):  # Handle cases where section number is on a separate line
                            temp_line = line_text
                        else:
                            if temp_line:
                                line_text = temp_line + " " + line_text
                                temp_line = ""
                            heading = extract_headings(line_text)
                            if heading:
                                headings.append({
                                    "page_number": page_number + 1,
                                    "type": heading["type"],
                                    "text": heading["text"]
                                })
    return headings

# Save results to a CSV file
def save_to_csv(pdf_path, headings):
    csv_file = pdf_path.replace(".pdf", "_headings.csv").replace(".PDF", "_headings.csv")
    with open(csv_file, mode="w", newline="", encoding="utf-8") as file:
        writer = csv.writer(file)
        writer.writerow(["Page", "Type", "Heading"])
        for heading in headings:
            writer.writerow([heading['page_number'], heading['type'], heading['text']])
    print(f"Results saved to the file: {csv_file}")

# Main Function
pdf_path = "example.pdf"  # Replace with your PDF file path
headings = extract_headings_from_pdf(pdf_path)
save_to_csv(pdf_path, headings)








import fitz  # PyMuPDF
import pytesseract
from pdf2image import convert_from_path
import re
import csv

# Configure Tesseract path (if not in PATH)
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"  # Update with your Tesseract path

# Configure Poppler path (for Windows users)
POPPLER_PATH = r"C:\poppler\bin"  # Update with your Poppler installation path

def is_invalid_heading(text):
    """
    Check if a heading is invalid (empty, only special characters, or only numbers).
    """
    return re.fullmatch(r"[\W_]*|\d+", text.strip()) is not None

def extract_text_from_pdf(pdf_path):
    """
    Extract text from a PDF using PyMuPDF for text-based PDFs.
    If PyMuPDF fails, fallback to OCR using pytesseract.
    """
    document = fitz.open(pdf_path)
    text_content = []

    for page_number in range(len(document)):
        page = document[page_number]
        text = page.get_text()

        if not text.strip():  # If the page has no text, fallback to OCR
            images = convert_from_path(pdf_path, first_page=page_number + 1, last_page=page_number + 1, poppler_path=POPPLER_PATH)
            for image in images:
                ocr_text = pytesseract.image_to_string(image)
                text_content.append(ocr_text)
        else:
            text_content.append(text)

    return "\n".join(text_content)

def extract_headings_and_content(text):
    """
    Extract headings, subheadings, and their associated content.
    """
    results = []
    lines = text.splitlines()

    current_heading = None
    current_content = []

    for line in lines:
        line = line.strip()

        # Regex to match headings and subheadings
        # Matches: "1. Organization", "1.1 Formation and Continuation", "1.1.1 Details"
        match = re.match(r"^(\d+(\.\d+)*\.?)\s+([^\.\n]+)\.", line)
        if match:
            section = match.group(1)  # Section number (e.g., "1.", "1.1.")
            title = match.group(3)  # Title text

            if not is_invalid_heading(title):
                # If there is a current heading, save it with its content
                if current_heading:
                    results.append({
                        "type": current_heading["type"],
                        "section": current_heading["section"],
                        "text": current_heading["text"],
                        "content": " ".join(current_content).strip()
                    })

                # Start a new heading or subheading
                heading_type = "Heading" if len(section.split(".")) == 1 else "Subheading"
                current_heading = {
                    "type": heading_type,
                    "section": section,
                    "text": title.strip() + "."
                }
                current_content = []  # Reset content for the new heading/subheading
        else:
            # Add non-heading lines as content for the current heading/subheading
            if current_heading:
                current_content.append(line)

    # Save the last heading/subheading with its content
    if current_heading:
        results.append({
            "type": current_heading["type"],
            "section": current_heading["section"],
            "text": current_heading["text"],
            "content": " ".join(current_content).strip()
        })

    return results

def save_headings_to_csv(headings, csv_file):
    """
    Save the extracted headings, subheadings, and their content to a CSV file.
    """
    with open(csv_file, mode="w", newline="", encoding="utf-8") as file:
        writer = csv.writer(file)
        writer.writerow(["Type", "Section", "Text", "Content"])
        for heading in headings:
            writer.writerow([heading["type"], heading["section"], heading["text"], heading["content"]])

def main(pdf_path):
    """
    Main function to extract and save headings, subheadings, and their content from a PDF.
    """
    csv_file = pdf_path.replace(".pdf", "_headings_and_content.csv").replace(".PDF", "_headings_and_content.csv")

    # Step 1: Extract text from the PDF
    print("Extracting text from PDF...")
    text = extract_text_from_pdf(pdf_path)

    # Step 2: Extract headings, subheadings, and content
    print("Extracting headings, subheadings, and content...")
    headings = extract_headings_and_content(text)

    # Step 3: Save to CSV
    print(f"Saving to CSV file: {csv_file}")
    save_headings_to_csv(headings, csv_file)

    # Output results
    count = len(headings)
    print(f"Extracted {count} headings and subheadings with content:")
    for heading in headings:
        print(f"{heading['type']} ({heading['section']}): {heading['text']}")
        print(f"Content: {heading['content']}\n")

if __name__ == "__main__":
    pdf_path = "example.pdf"  # Replace with the path to your PDF file
    main(pdf_path)








import fitz  # PyMuPDF
import csv
import re

def is_invalid_heading(text):
    # Check if a heading is invalid (empty, only special characters, or only numbers).
    return re.fullmatch(r"[\W_]*|\d+", text.strip()) is not None

def extract_headings(line):
    match = re.match(r"^(\d+(\.\d+)*\.?)\s+([^\.\n]+)", line)
    heading = None

    if match:
        section = match.group(1)  # Section number (e.g., "1.", "1.1.")
        title = match.group(3)    # Title text
        if not is_invalid_heading(title):
            if len(section.split(".")) == 1:  # Top-level heading (e.g., "1.")
                heading = {
                    "type": "Heading",
                    "section": section,
                    "text": line.strip()
                }
            elif len(section.split(".")) > 1:  # Subheading (e.g., "1.1")
                heading = {
                    "type": "Subheading",
                    "section": section,
                    "text": line.strip()
                }
    return heading

def extract_headings_from_pdf(pdf_path):
    headings = []
    document = fitz.open(pdf_path)

    for page_number in range(len(document)):
        page = document[page_number]
        blocks = page.get_text("dict")["blocks"]

        for block in blocks:
            for line in block.get("lines", []):
                for span in line.get("spans", []):
                    if span["size"] >= 10:  # Adjust this threshold as needed
                        line_text = span["text"].strip()
                        if line_text != "":
                            heading = extract_headings(line_text)
                            if heading:
                                headings.append({
                                    "page_number": page_number + 1,
                                    "type": heading["type"],
                                    "text": heading["text"]
                                })
    return headings

# Save results to a CSV file
def save_to_csv(pdf_path, headings):
    csv_file = pdf_path.replace(".pdf", "_headings.csv").replace(".PDF", "_headings.csv")
    with open(csv_file, mode="w", newline="", encoding="utf-8") as file:
        writer = csv.writer(file)
        writer.writerow(["Page", "Type", "Heading"])
        for heading in headings:
            writer.writerow([heading['page_number'], heading['type'], heading['text']])
    print(f"Results saved to the file: {csv_file}")

# Main Function
pdf_path = "example.pdf"  # Replace with your PDF file path
headings = extract_headings_from_pdf(pdf_path)
save_to_csv(pdf_path, headings)










import fitz  # PyMuPDF
import pytesseract
from pdf2image import convert_from_path
import re
import csv

# Configure Tesseract path (if not in PATH)
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"  # Update with your Tesseract path

# Configure Poppler path (for Windows users)
POPPLER_PATH = r"C:\poppler\bin"  # Update with your Poppler installation path

def is_invalid_heading(text):
    """
    Check if a heading is invalid (empty, only special characters, or only numbers).
    """
    return re.fullmatch(r"[\W_]*|\d+", text.strip()) is not None

def extract_text_from_pdf(pdf_path):
    """
    Extract text from a PDF using PyMuPDF for text-based PDFs.
    If PyMuPDF fails, fallback to OCR using pytesseract.
    """
    document = fitz.open(pdf_path)
    text_content = []

    for page_number in range(len(document)):
        page = document[page_number]
        text = page.get_text()

        if not text.strip():  # If the page has no text, fallback to OCR
            images = convert_from_path(pdf_path, first_page=page_number + 1, last_page=page_number + 1, poppler_path=POPPLER_PATH)
            for image in images:
                ocr_text = pytesseract.image_to_string(image)
                text_content.append(ocr_text)
        else:
            text_content.append(text)

    return "\n".join(text_content)

def extract_headings_and_subheadings(text):
    """
    Extract both headings (e.g., '1. Organization') and subheadings (e.g., '1.1 Formation and Continuation').
    """
    headings = []
    lines = text.splitlines()

    for line in lines:
        line = line.strip()
        # Regex to match headings and subheadings
        # Matches: "1. Organization", "1.1 Formation and Continuation", "1.1.1 Details"
        match = re.match(r"^(\d+(\.\d+)*\.?)\s+([^\.\n]+)\.", line)
        if match:
            section = match.group(1)  # Section number (e.g., "1.", "1.1.")
            title = match.group(3)  # Title text

            if not is_invalid_heading(title):
                if len(section.split(".")) == 1:  # Top-level heading (e.g., "1.")
                    headings.append({
                        "type": "Heading",
                        "section": section,
                        "text": title.strip() + "."
                    })
                elif len(section.split(".")) > 1:  # Subheading (e.g., "1.1")
                    headings.append({
                        "type": "Subheading",
                        "section": section,
                        "text": title.strip() + "."
                    })

    return headings

def save_headings_to_csv(headings, csv_file):
    """
    Save the extracted headings and subheadings to a CSV file.
    """
    with open(csv_file, mode="w", newline="", encoding="utf-8") as file:
        writer = csv.writer(file)
        writer.writerow(["Type", "Section", "Text"])
        for heading in headings:
            writer.writerow([heading["type"], heading["section"], heading["text"]])

def main(pdf_path):
    """
    Main function to extract and save headings and subheadings from a PDF.
    """
    csv_file = pdf_path.replace(".pdf", "_headings.csv").replace(".PDF", "_headings.csv")

    # Step 1: Extract text from the PDF
    print("Extracting text from PDF...")
    text = extract_text_from_pdf(pdf_path)

    # Step 2: Extract headings and subheadings
    print("Extracting headings and subheadings...")
    headings = extract_headings_and_subheadings(text)

    # Step 3: Save to CSV
    print(f"Saving to CSV file: {csv_file}")
    save_headings_to_csv(headings, csv_file)

    # Output results
    count = len(headings)
    print(f"Extracted {count} headings and subheadings:")
    for heading in headings:
        print(f"{heading['type']}: {heading['section']} {heading['text']}")

if __name__ == "__main__":
    pdf_path = "example.pdf"  # Replace with the path to your PDF file
    main(pdf_path)















POPPLER_PATH = r"C:\poppler\bin"  # Replace with the path to your Poppler installation

def extract_text_from_pdf(pdf_path):
    """
    Extract text from a PDF using PyMuPDF for text-based PDFs.
    If PyMuPDF fails, fallback to OCR using pytesseract.
    """
    document = fitz.open(pdf_path)
    text_content = []

    for page_number in range(len(document)):
        page = document[page_number]
        text = page.get_text()

        if not text.strip():  # If the page has no text, fallback to OCR
            images = convert_from_path(pdf_path, first_page=page_number + 1, last_page=page_number + 1, poppler_path=POPPLER_PATH)
            for image in images:
                ocr_text = pytesseract.image_to_string(image)
                text_content.append(ocr_text)
        else:
            text_content.append(text)

    return "\n".join(text_content)
Step 3: Install Required Python Libraries
Ensure the following libraries are installed:

bash
Copy code
pip install PyMuPDF pdf2image pytesseract pillow
Step 4: Test Poppler Installation
Run the following command to verify that Poppler is installed correctly:

bash
Copy code
pdftoppm -h
If you see the help message, Poppler is correctly installed.

Step 5: Run the Script
After configuring the Poppler path and installing dependencies, run the script:

bash
Copy code
python your_script.py
Expected Output
If everything is set up correctly, the script will extract headings and subheadings from your PDF and save them to a CSV file.

Let me know if you encounter further issues!












ChatGPT can make mistakes. Check important info.








import fitz  # PyMuPDF
import pytesseract
from pdf2image import convert_from_path
import re
import csv
import os

def is_invalid_heading(text):
    """
    Check if a heading is invalid (empty, only special characters, or only numbers).
    """
    return re.fullmatch(r"[\W_]*|\d+", text.strip()) is not None

def extract_text_from_pdf(pdf_path):
    """
    Extract text from a PDF using PyMuPDF for text-based PDFs.
    If PyMuPDF fails, fallback to OCR using pytesseract.
    """
    document = fitz.open(pdf_path)
    text_content = []

    for page_number in range(len(document)):
        page = document[page_number]
        text = page.get_text()

        if not text.strip():  # If the page has no text, fallback to OCR
            images = convert_from_path(pdf_path, first_page=page_number + 1, last_page=page_number + 1)
            for image in images:
                ocr_text = pytesseract.image_to_string(image)
                text_content.append(ocr_text)
        else:
            text_content.append(text)

    return "\n".join(text_content)

def extract_headings_and_subheadings(text):
    """
    Extract both headings (e.g., '1. Organization') and subheadings (e.g., '1.1 Formation and Continuation').
    """
    headings = []
    lines = text.splitlines()

    for line in lines:
        line = line.strip()
        # Regex to match headings and subheadings
        # Matches: "1. Organization", "1.1 Formation and Continuation", "1.1.1 Details"
        match = re.match(r"^(\d+(\.\d+)*\.?)\s+([^\.\n]+)\.", line)
        if match:
            section = match.group(1)  # Section number (e.g., "1.", "1.1.")
            title = match.group(3)  # Title text

            if not is_invalid_heading(title):
                if len(section.split(".")) == 1:  # Top-level heading (e.g., "1.")
                    headings.append({
                        "type": "Heading",
                        "section": section,
                        "text": title.strip() + "."
                    })
                elif len(section.split(".")) > 1:  # Subheading (e.g., "1.1")
                    headings.append({
                        "type": "Subheading",
                        "section": section,
                        "text": title.strip() + "."
                    })

    return headings

def save_headings_to_csv(headings, csv_file):
    """
    Save the extracted headings and subheadings to a CSV file.
    """
    with open(csv_file, mode="w", newline="", encoding="utf-8") as file:
        writer = csv.writer(file)
        writer.writerow(["Type", "Section", "Text"])
        for heading in headings:
            writer.writerow([heading["type"], heading["section"], heading["text"]])

def main(pdf_path):
    """
    Main function to extract and save headings and subheadings from a PDF.
    """
    csv_file = pdf_path.replace(".pdf", "_headings.csv").replace(".PDF", "_headings.csv")

    # Step 1: Extract text from the PDF
    print("Extracting text from PDF...")
    text = extract_text_from_pdf(pdf_path)

    # Step 2: Extract headings and subheadings
    print("Extracting headings and subheadings...")
    headings = extract_headings_and_subheadings(text)

    # Step 3: Save to CSV
    print(f"Saving to CSV file: {csv_file}")
    save_headings_to_csv(headings, csv_file)

    # Output results
    count = len(headings)
    print(f"Extracted {count} headings and subheadings:")
    for heading in headings:
        print(f"{heading['type']}: {heading['section']} {heading['text']}")

if __name__ == "__main__":
    pdf_path = "example.pdf"  # Replace with the path to your PDF file
    main(pdf_path)










import fitz  # PyMuPDF
import re
import csv

def is_invalid_heading(text):
    """
    Check if a heading is invalid (empty, only special characters, or only numbers).
    """
    return re.fullmatch(r"[\W_]*|\d+", text.strip()) is not None

def extract_headings_and_subheadings(pdf_path):
    """
    Extract both headings (e.g., '1. Organization') and subheadings (e.g., '1.1 Formation and Continuation') from a PDF.
    """
    headings = []

    # Open the PDF file
    document = fitz.open(pdf_path)

    for page_number in range(len(document)):
        page = document[page_number]
        blocks = page.get_text("dict")["blocks"]

        for block in blocks:
            for line in block.get("lines", []):
                for span in line.get("spans", []):
                    font_name = span["font"]
                    font_size = span["size"]
                    text = span["text"].strip()

                    # Regex to match headings and subheadings
                    # Matches: "1. Organization", "1.1 Formation and Continuation", "1.1.1 Details"
                    match = re.match(r"^(\d+(\.\d+)*\.?)\s+([^\.\n]+)\.", text)
                    if match:
                        section = match.group(1)  # Section number (e.g., "1.", "1.1.")
                        title = match.group(3)  # Title text

                        # Exclude invalid headings
                        if not is_invalid_heading(title):
                            if len(section.split(".")) == 1:  # Top-level heading (e.g., "1.")
                                headings.append({
                                    "type": "Heading",
                                    "section": section,
                                    "text": title.strip() + ".",
                                    "page_number": page_number + 1
                                })
                            elif len(section.split(".")) > 1:  # Subheading (e.g., "1.1")
                                headings.append({
                                    "type": "Subheading",
                                    "section": section,
                                    "text": title.strip() + ".",
                                    "page_number": page_number + 1
                                })

    return headings

def save_headings_to_csv(headings, csv_file):
    """
    Save the extracted headings and subheadings to a CSV file.
    """
    with open(csv_file, mode="w", newline="", encoding="utf-8") as file:
        writer = csv.writer(file)
        writer.writerow(["Page", "Type", "Section", "Text"])
        for heading in headings:
            writer.writerow([
                heading["page_number"],
                heading["type"],
                heading["section"],
                heading["text"]
            ])

def main(pdf_path):
    """
    Main function to extract and save headings and subheadings from a PDF.
    """
    csv_file = pdf_path.replace(".pdf", "_headings.csv").replace(".PDF", "_headings.csv")
    headings = extract_headings_and_subheadings(pdf_path)
    
    count = 0
    for heading in headings:
        print(f"Page {heading['page_number']} ({heading['type']}): {heading['section']} {heading['text']}")
        count += 1

    print(f"Number of headings and subheadings: {count}")
    save_headings_to_csv(headings, csv_file)
    print(f"Headings and subheadings saved to {csv_file}")

# Example usage
if __name__ == "__main__":
    pdf_path = "example.pdf"  # Replace with the path to your PDF file
    main(pdf_path)










import fitz  # PyMuPDF
import re
import csv

def is_invalid_heading(text):
    """
    Check if a heading is invalid (empty, only special characters, or only numbers).
    """
    return re.fullmatch(r"[\W_]*|\d+", text.strip()) is not None

def extract_headings_and_subheadings(pdf_path):
    """
    Extract both top-level headings (e.g., '1. Organization') and clean subheadings (e.g., '1.1 Mission Statement') from a PDF.
    """
    headings = []

    # Open the PDF file
    document = fitz.open(pdf_path)

    for page_number in range(len(document)):
        page = document[page_number]
        blocks = page.get_text("dict")["blocks"]

        for block in blocks:
            for line in block.get("lines", []):
                for span in line.get("spans", []):
                    font_name = span["font"]
                    font_size = span["size"]
                    text = span["text"].strip()
                    is_upper = text.isupper()

                    # Regex to match headings and subheadings
                    # Matches: "1. Organization", "1.1 Mission Statement", "1.1.1 Details"
                    match = re.match(r"^(\d+(\.\d+)*\.?)\s+(.*?)(\.|\s)*$", text)
                    if match:
                        section = match.group(1)  # Section number (e.g., "1.", "1.1.")
                        title = match.group(3)  # Title text

                        # Exclude invalid headings
                        if not is_invalid_heading(title):
                            # Differentiate between top-level headings and subheadings
                            if len(section.split(".")) == 1:  # Top-level heading (e.g., "1.")
                                headings.append({
                                    "type": "Heading",
                                    "section": section,
                                    "text": title.strip(),
                                    "page_number": page_number + 1
                                })
                            elif len(section.split(".")) > 1:  # Subheading (e.g., "1.1")
                                headings.append({
                                    "type": "Subheading",
                                    "section": section,
                                    "text": title.strip(),
                                    "page_number": page_number + 1
                                })

    return headings

def save_headings_to_csv(headings, csv_file):
    """
    Save the extracted headings and subheadings to a CSV file.
    """
    with open(csv_file, mode="w", newline="", encoding="utf-8") as file:
        writer = csv.writer(file)
        writer.writerow(["Page", "Type", "Section", "Text"])
        for heading in headings:
            writer.writerow([
                heading["page_number"],
                heading["type"],
                heading["section"],
                heading["text"]
            ])

def main(pdf_path):
    """
    Main function to extract and save headings and subheadings from a PDF.
    """
    csv_file = pdf_path.replace(".pdf", "_headings.csv").replace(".PDF", "_headings.csv")
    headings = extract_headings_and_subheadings(pdf_path)
    
    count = 0
    for heading in headings:
        print(f"Page {heading['page_number']} ({heading['type']}): {heading['section']} {heading['text']}")
        count += 1

    print(f"Number of headings and subheadings: {count}")
    save_headings_to_csv(headings, csv_file)
    print(f"Headings and subheadings saved to {csv_file}")

# Example usage
if __name__ == "__main__":
    pdf_path = "example.pdf"  # Replace with the path to your PDF file
    main(pdf_path)












import fitz  # PyMuPDF
import re
import csv

def is_invalid_heading(text):
    """
    Check if a heading is invalid (empty, only special characters, or only numbers).
    """
    return re.fullmatch(r"[\W_]*|\d+", text.strip()) is not None

def extract_headings_and_subheadings(pdf_path):
    """
    Extract both top-level headings (e.g., '1. Organization') and subheadings (e.g., '1.1 Something') from a PDF.
    """
    headings = []

    # Open the PDF file
    document = fitz.open(pdf_path)

    for page_number in range(len(document)):
        page = document[page_number]
        blocks = page.get_text("dict")["blocks"]

        for block in blocks:
            for line in block.get("lines", []):
                for span in line.get("spans", []):
                    font_name = span["font"]
                    font_size = span["size"]
                    text = span["text"].strip()
                    is_upper = text.isupper()

                    # Regex to match headings and subheadings
                    # Matches: "1. Organization", "2. List", "1.1 Something", "1.1.1 Details"
                    match = re.match(r"^(\d+(\.\d+)*\.?)\s+(.*)$", text)
                    if match:
                        section = match.group(1)  # Section number (e.g., "1.", "1.1.")
                        title = match.group(3)  # Title text

                        # Exclude invalid headings
                        if not is_invalid_heading(title):
                            # Differentiate between top-level headings and subheadings
                            if len(section.split(".")) == 1:  # Top-level heading (e.g., "1.")
                                headings.append({
                                    "type": "Heading",
                                    "section": section,
                                    "text": title.strip(),
                                    "page_number": page_number + 1
                                })
                            elif len(section.split(".")) > 1:  # Subheading (e.g., "1.1")
                                headings.append({
                                    "type": "Subheading",
                                    "section": section,
                                    "text": title.strip(),
                                    "page_number": page_number + 1
                                })

    return headings

def save_headings_to_csv(headings, csv_file):
    """
    Save the extracted headings and subheadings to a CSV file.
    """
    with open(csv_file, mode="w", newline="", encoding="utf-8") as file:
        writer = csv.writer(file)
        writer.writerow(["Page", "Type", "Section", "Text"])
        for heading in headings:
            writer.writerow([
                heading["page_number"],
                heading["type"],
                heading["section"],
                heading["text"]
            ])

def main(pdf_path):
    """
    Main function to extract and save headings and subheadings from a PDF.
    """
    csv_file = pdf_path.replace(".pdf", "_headings.csv").replace(".PDF", "_headings.csv")
    headings = extract_headings_and_subheadings(pdf_path)
    
    count = 0
    for heading in headings:
        print(f"Page {heading['page_number']} ({heading['type']}): {heading['section']} {heading['text']}")
        count += 1

    print(f"Number of headings and subheadings: {count}")
    save_headings_to_csv(headings, csv_file)
    print(f"Headings and subheadings saved to {csv_file}")

# Example usage
if __name__ == "__main__":
    pdf_path = "example.pdf"  # Replace with the path to your PDF file
    main(pdf_path)







import fitz  # PyMuPDF
import re
import csv

def is_invalid_heading(text):
    """
    Check if a heading is invalid (empty, only special characters, or only numbers).
    """
    return re.fullmatch(r"[\W_]*|\d+", text.strip()) is not None

def extract_headings_and_subheadings(pdf_path):
    """
    Extract headings (e.g., '1. Organization') and subheadings (e.g., '1.1 Something') from a PDF.
    """
    headings = []

    # Open the PDF file
    document = fitz.open(pdf_path)

    for page_number in range(len(document)):
        page = document[page_number]
        blocks = page.get_text("dict")["blocks"]

        for block in blocks:
            for line in block.get("lines", []):
                for span in line.get("spans", []):
                    font_name = span["font"]
                    font_size = span["size"]
                    text = span["text"].strip()
                    is_upper = text.isupper()
                    is_underlined = bool(span.get("flags", 0) & 4)  # Check for underline flag

                    # Regex to match headings and subheadings
                    # Matches: "1. Organization", "1.1 Something", "1.1.1 Details"
                    match = re.match(r"^(\d+(\.\d+)*\.?)\s+(.*)$", text)
                    if match:
                        section = match.group(1)  # Section number (e.g., "1.", "1.1.")
                        title = match.group(3)  # Title text

                        # Exclude invalid headings
                        if not is_invalid_heading(text):
                            if len(section.split(".")) == 1:  # Heading (e.g., "1.")
                                headings.append({
                                    "type": "Heading",
                                    "section": section,
                                    "text": title.strip(),
                                    "page_number": page_number + 1
                                })
                            else:  # Subheading (e.g., "1.1", "1.1.1")
                                headings.append({
                                    "type": "Subheading",
                                    "section": section,
                                    "text": title.strip(),
                                    "page_number": page_number + 1
                                })

    return headings

def save_headings_to_csv(headings, csv_file):
    """
    Save the extracted headings and subheadings to a CSV file.
    """
    with open(csv_file, mode="w", newline="", encoding="utf-8") as file:
        writer = csv.writer(file)
        writer.writerow(["Page", "Type", "Section", "Text"])
        for heading in headings:
            writer.writerow([
                heading["page_number"],
                heading["type"],
                heading["section"],
                heading["text"]
            ])

def main(pdf_path):
    """
    Main function to extract and save headings and subheadings from a PDF.
    """
    csv_file = pdf_path.replace(".pdf", "_headings.csv").replace(".PDF", "_headings.csv")
    headings = extract_headings_and_subheadings(pdf_path)
    
    count = 0
    for heading in headings:
        print(f"Page {heading['page_number']} ({heading['type']}): {heading['section']} {heading['text']}")
        count += 1

    print(f"Number of headings and subheadings: {count}")
    save_headings_to_csv(headings, csv_file)
    print(f"Headings and subheadings saved to {csv_file}")

# Example usage
if __name__ == "__main__":
    pdf_path = "example.pdf"  # Replace with the path to your PDF file
    main(pdf_path)











import fitz  # PyMuPDF
import re
import csv

def is_invalid_heading(text):
    """
    Check if a heading is invalid (empty, only special characters, or only numbers).
    """
    return re.fullmatch(r"[\W_]*|\d+", text.strip()) is not None

def extract_headings_and_subheadings(pdf_path):
    """
    Extract both headings and underlined subheadings from a PDF.
    """
    headings = []

    # Open the PDF file
    document = fitz.open(pdf_path)

    for page_number in range(len(document)):
        page = document[page_number]
        blocks = page.get_text("dict")["blocks"]

        for block in blocks:
            for line in block.get("lines", []):
                for span in line.get("spans", []):
                    font_name = span["font"]
                    font_size = span["size"]
                    text = span["text"].strip()
                    is_upper = text.isupper()
                    is_underlined = bool(span.get("flags", 0) & 4)  # Check for underline flag

                    # Regex to match headings and subheadings
                    # Matches: "1. Organization", "2. Capital", "3.2.3 Distribution"
                    match = re.match(r"^(\d+(\.\d+)*\.?)\s+(.*)$", text)
                    if match:
                        section = match.group(1)  # Section number (e.g., "1.", "3.2.")
                        title = match.group(3)  # Title text

                        # Exclude invalid headings
                        if not is_invalid_heading(text):
                            if is_upper or "Bold" in font_name or font_size >= 12:  # Heading
                                headings.append({
                                    "type": "Heading",
                                    "section": section,
                                    "text": title.strip(),
                                    "page_number": page_number + 1
                                })
                            elif is_underlined or "Italic" in font_name:  # Subheading
                                headings.append({
                                    "type": "Subheading",
                                    "section": section,
                                    "text": title.strip(),
                                    "page_number": page_number + 1
                                })

    return headings

def save_headings_to_csv(headings, csv_file):
    """
    Save the extracted headings and subheadings to a CSV file.
    """
    with open(csv_file, mode="w", newline="", encoding="utf-8") as file:
        writer = csv.writer(file)
        writer.writerow(["Page", "Type", "Section", "Text"])
        for heading in headings:
            writer.writerow([
                heading["page_number"],
                heading["type"],
                heading["section"],
                heading["text"]
            ])

def main(pdf_path):
    """
    Main function to extract and save headings and subheadings from a PDF.
    """
    csv_file = pdf_path.replace(".pdf", "_headings.csv").replace(".PDF", "_headings.csv")
    headings = extract_headings_and_subheadings(pdf_path)
    
    count = 0
    for heading in headings:
        print(f"Page {heading['page_number']} ({heading['type']}): {heading['section']} {heading['text']}")
        count += 1

    print(f"Number of headings and subheadings: {count}")
    save_headings_to_csv(headings, csv_file)
    print(f"Headings and subheadings saved to {csv_file}")

# Example usage
if __name__ == "__main__":
    pdf_path = "example.pdf"  # Replace with the path to your PDF file
    main(pdf_path)









import fitz  # PyMuPDF
import re
import csv

def is_invalid_heading(text):
    """
    Check if a heading is invalid (empty, only special characters, or only numbers).
    """
    return re.fullmatch(r"[\W_]*|\d+", text.strip()) is not None

def extract_headings_and_subheadings(pdf_path):
    """
    Extract headings (e.g., '1. Organization') and underlined subheadings from a PDF.
    """
    headings = []

    # Open the PDF file
    document = fitz.open(pdf_path)

    for page_number in range(len(document)):
        page = document[page_number]
        blocks = page.get_text("dict")["blocks"]

        for block in blocks:
            for line in block.get("lines", []):
                for span in line.get("spans", []):
                    font_name = span["font"]
                    font_size = span["size"]
                    text = span["text"].strip()
                    is_upper = text.isupper()
                    is_underlined = bool(span.get("flags", 0) & 4)  # Check for underline flag

                    # Regex to match headings (e.g., '1. Organization') and subheadings (e.g., '1.1 Distribution')
                    match = re.match(r"^(\d+\.)\s+(.*)$", text)
                    if match:
                        section = match.group(1)  # Section number
                        title = match.group(2)  # Title text

                        # Exclude invalid headings
                        if not is_invalid_heading(text):
                            if is_upper or "Bold" in font_name or font_size >= 12:  # Heading
                                headings.append({
                                    "type": "Heading",
                                    "section": section,
                                    "text": title.strip(),
                                    "page_number": page_number + 1
                                })
                            elif is_underlined:  # Subheading
                                headings.append({
                                    "type": "Subheading",
                                    "section": section,
                                    "text": title.strip(),
                                    "page_number": page_number + 1
                                })

    return headings

def save_headings_to_csv(headings, csv_file):
    """
    Save the extracted headings and subheadings to a CSV file.
    """
    with open(csv_file, mode="w", newline="", encoding="utf-8") as file:
        writer = csv.writer(file)
        writer.writerow(["Page", "Type", "Section", "Text"])
        for heading in headings:
            writer.writerow([
                heading["page_number"],
                heading["type"],
                heading["section"],
                heading["text"]
            ])

def main(pdf_path):
    """
    Main function to extract and save headings and subheadings from a PDF.
    """
    csv_file = pdf_path.replace(".pdf", "_headings.csv").replace(".PDF", "_headings.csv")
    headings = extract_headings_and_subheadings(pdf_path)
    
    count = 0
    for heading in headings:
        print(f"Page {heading['page_number']} ({heading['type']}): {heading['section']} {heading['text']}")
        count += 1

    print(f"Number of headings and subheadings: {count}")
    save_headings_to_csv(headings, csv_file)
    print(f"Headings and subheadings saved to {csv_file}")

# Example usage
if __name__ == "__main__":
    pdf_path = "example.pdf"  # Replace with the path to your PDF file
    main(pdf_path)












import fitz  # PyMuPDF
import re
import csv

def is_invalid_heading(text):
    """
    Check if a heading is invalid (empty, only special characters, or only numbers).
    """
    return re.fullmatch(r"[\W_]*|\d+", text.strip()) is not None

def extract_headings_and_underlined_subheadings(pdf_path):
    """
    Extract headings and underlined subheadings from a PDF.
    Only keeps text before the first sentence-ending punctuation.
    """
    headings = []

    # Open the PDF file
    document = fitz.open(pdf_path)

    for page_number in range(len(document)):
        page = document[page_number]
        blocks = page.get_text("dict")["blocks"]

        for block in blocks:
            for line in block.get("lines", []):
                for span in line.get("spans", []):
                    font_name = span["font"]
                    font_size = span["size"]
                    text = span["text"].strip()
                    is_upper = text.isupper()
                    is_underlined = bool(span.get("flags", 0) & 4)  # Check for underline flag

                    # Extract only headings and underlined subheadings
                    if not is_invalid_heading(text):
                        if is_upper or "Bold" in font_name:  # Heading
                            # Keep only the section number and title
                            match = re.match(r"^(\d+(\.\d+)*\.?)\s+(.*)$", text)
                            if match:
                                section = match.group(1)  # Section number
                                title = match.group(3)  # Title text
                                headings.append({
                                    "type": "Heading",
                                    "section": section,
                                    "text": title.strip(),
                                    "page_number": page_number + 1
                                })
                        elif is_underlined:  # Subheading with underline
                            # Keep only the section number and title
                            match = re.match(r"^(\d+(\.\d+)*\.?)\s+(.*)$", text)
                            if match:
                                section = match.group(1)  # Section number
                                title = match.group(3)  # Title text
                                headings.append({
                                    "type": "Subheading",
                                    "section": section,
                                    "text": title.strip(),
                                    "page_number": page_number + 1
                                })

    return headings

def save_headings_to_csv(headings, csv_file):
    """
    Save the extracted headings and subheadings to a CSV file.
    """
    with open(csv_file, mode="w", newline="", encoding="utf-8") as file:
        writer = csv.writer(file)
        writer.writerow(["Page", "Type", "Section", "Text"])
        for heading in headings:
            writer.writerow([
                heading["page_number"],
                heading["type"],
                heading["section"],
                heading["text"]
            ])

def main(pdf_path):
    """
    Main function to extract and save headings and underlined subheadings from a PDF.
    """
    csv_file = pdf_path.replace(".pdf", "_headings.csv").replace(".PDF", "_headings.csv")
    headings = extract_headings_and_underlined_subheadings(pdf_path)
    
    count = 0
    for heading in headings:
        print(f"Page {heading['page_number']} ({heading['type']}): {heading['section']} {heading['text']}")
        count += 1

    print(f"Number of headings and underlined subheadings: {count}")
    save_headings_to_csv(headings, csv_file)
    print(f"Headings and subheadings saved to {csv_file}")

# Example usage
if __name__ == "__main__":
    pdf_path = "example.pdf"  # Replace with the path to your PDF file
    main(pdf_path)












import fitz  # PyMuPDF
import re
import csv

def is_invalid_heading(text):
    """
    Check if a heading is invalid (empty, only special characters, or only numbers).
    """
    return re.fullmatch(r"[\W_]*|\d+", text.strip()) is not None

def extract_headings_and_underlined_subheadings(pdf_path):
    """
    Extract headings and underlined subheadings from a PDF.
    """
    headings = []

    # Open the PDF file
    document = fitz.open(pdf_path)

    for page_number in range(len(document)):
        page = document[page_number]
        blocks = page.get_text("dict")["blocks"]

        for block in blocks:
            for line in block.get("lines", []):
                for span in line.get("spans", []):
                    font_name = span["font"]
                    font_size = span["size"]
                    text = span["text"].strip()
                    is_upper = text.isupper()
                    is_underlined = bool(span.get("flags", 0) & 4)  # Check for underline flag

                    # Extract only headings and underlined subheadings
                    if not is_invalid_heading(text):
                        if is_upper or "Bold" in font_name:  # Heading
                            headings.append({
                                "type": "Heading",
                                "text": text,
                                "page_number": page_number + 1
                            })
                        elif is_underlined:  # Subheading with underline
                            headings.append({
                                "type": "Subheading",
                                "text": text,
                                "page_number": page_number + 1
                            })

    return headings

def save_headings_to_csv(headings, csv_file):
    """
    Save the extracted headings and subheadings to a CSV file.
    """
    with open(csv_file, mode="w", newline="", encoding="utf-8") as file:
        writer = csv.writer(file)
        writer.writerow(["Page", "Type", "Text"])
        for heading in headings:
            writer.writerow([
                heading["page_number"],
                heading["type"],
                heading["text"]
            ])

def main(pdf_path):
    """
    Main function to extract and save headings and underlined subheadings from a PDF.
    """
    csv_file = pdf_path.replace(".pdf", "_headings.csv").replace(".PDF", "_headings.csv")
    headings = extract_headings_and_underlined_subheadings(pdf_path)
    
    count = 0
    for heading in headings:
        print(f"Page {heading['page_number']} ({heading['type']}): {heading['text']}")
        count += 1

    print(f"Number of headings and underlined subheadings: {count}")
    save_headings_to_csv(headings, csv_file)
    print(f"Headings and subheadings saved to {csv_file}")

# Example usage
if __name__ == "__main__":
    pdf_path = "example.pdf"  # Replace with the path to your PDF file
    main(pdf_path)












import fitz  # PyMuPDF
import re
import csv

def is_invalid_heading(text):
    """
    Check if a heading is invalid (empty, only special characters, or only numbers).
    """
    return re.fullmatch(r"[\W_]*|\d+", text.strip()) is not None

def extract_headings_and_subheadings(pdf_path):
    """
    Extract headings and subheadings from a PDF.
    Subheadings are identified by underlining, and normal content is ignored.
    """
    headings = []

    # Open the PDF file
    document = fitz.open(pdf_path)

    for page_number in range(len(document)):
        page = document[page_number]
        blocks = page.get_text("dict")["blocks"]

        for block in blocks:
            for line in block.get("lines", []):
                for span in line.get("spans", []):
                    font_name = span["font"]
                    font_size = span["size"]
                    text = span["text"].strip()
                    is_upper = text.isupper()
                    is_underlined = bool(span.get("flags", 0) & 4)  # Check for underline flag

                    # Ignore normal content and extract only headings and subheadings
                    if not is_invalid_heading(text):
                        if is_upper or "Bold" in font_name:  # Heading
                            headings.append({
                                "type": "Heading",
                                "text": text,
                                "font_name": font_name,
                                "font_size": font_size,
                                "page_number": page_number + 1
                            })
                        elif is_underlined:  # Subheading
                            headings.append({
                                "type": "Subheading",
                                "text": text,
                                "font_name": font_name,
                                "font_size": font_size,
                                "page_number": page_number + 1
                            })

    return headings

def save_headings_to_csv(headings, csv_file):
    """
    Save the extracted headings and subheadings to a CSV file.
    """
    with open(csv_file, mode="w", newline="", encoding="utf-8") as file:
        writer = csv.writer(file)
        writer.writerow(["Page", "Type", "Heading", "Font_Size", "Font_Name"])
        for heading in headings:
            writer.writerow([
                heading["page_number"],
                heading["type"],
                heading["text"],
                heading["font_size"],
                heading["font_name"]
            ])

def main(pdf_path):
    """
    Main function to extract and save headings and subheadings from a PDF.
    """
    csv_file = pdf_path.replace(".pdf", "_headings.csv").replace(".PDF", "_headings.csv")
    headings = extract_headings_and_subheadings(pdf_path)
    
    count = 0
    for heading in headings:
        print(f"Page {heading['page_number']} ({heading['type']}): {heading['text']} (Font: {heading['font_name']}, Size: {heading['font_size']})")
        count += 1

    print(f"Number of headings and subheadings: {count}")
    save_headings_to_csv(headings, csv_file)
    print(f"Headings and subheadings saved to {csv_file}")

# Example usage
if __name__ == "__main__":
    pdf_path = "example.pdf"  # Replace with the path to your PDF file
    main(pdf_path)









import fitz  # PyMuPDF
import re
import csv

def is_invalid_heading(text):
    """
    Check if a heading is invalid (empty, only special characters, or only numbers).
    """
    return re.fullmatch(r"[\W_]*|\d+", text.strip()) is not None

def extract_headings_and_subheadings(pdf_path):
    """
    Extract headings and subheadings from a PDF.
    Subheadings are identified by underlining.
    """
    headings = []

    # Open the PDF file
    document = fitz.open(pdf_path)

    for page_number in range(len(document)):
        page = document[page_number]
        blocks = page.get_text("dict")["blocks"]

        for block in blocks:
            for line in block.get("lines", []):
                for span in line.get("spans", []):
                    font_name = span["font"]
                    font_size = span["size"]
                    text = span["text"].strip()
                    is_upper = text.isupper()
                    is_underlined = bool(span.get("flags", 0) & 4)  # Check for underline flag

                    # Identify headings and subheadings
                    if not is_invalid_heading(text):
                        if is_upper or "Bold" in font_name:  # Heading
                            headings.append({
                                "type": "Heading",
                                "text": text,
                                "font_name": font_name,
                                "font_size": font_size,
                                "page_number": page_number + 1
                            })
                        elif is_underlined:  # Subheading
                            headings.append({
                                "type": "Subheading",
                                "text": text,
                                "font_name": font_name,
                                "font_size": font_size,
                                "page_number": page_number + 1
                            })

    return headings

def save_headings_to_csv(headings, csv_file):
    """
    Save the extracted headings and subheadings to a CSV file.
    """
    with open(csv_file, mode="w", newline="", encoding="utf-8") as file:
        writer = csv.writer(file)
        writer.writerow(["Page", "Type", "Heading", "Font_Size", "Font_Name"])
        for heading in headings:
            writer.writerow([
                heading["page_number"],
                heading["type"],
                heading["text"],
                heading["font_size"],
                heading["font_name"]
            ])

def main(pdf_path):
    """
    Main function to extract and save headings and subheadings from a PDF.
    """
    csv_file = pdf_path.replace(".pdf", "_headings.csv").replace(".PDF", "_headings.csv")
    headings = extract_headings_and_subheadings(pdf_path)
    
    count = 0
    for heading in headings:
        print(f"Page {heading['page_number']} ({heading['type']}): {heading['text']} (Font: {heading['font_name']}, Size: {heading['font_size']})")
        count += 1

    print(f"Number of headings and subheadings: {count}")
    save_headings_to_csv(headings, csv_file)
    print(f"Headings and subheadings saved to {csv_file}")

# Example usage
if __name__ == "__main__":
    pdf_path = "example.pdf"  # Replace with the path to your PDF file
    main(pdf_path)






import fitz  # PyMuPDF
import re

def extract_headings_and_subheadings(pdf_path):
    headings = []
    section_pattern = re.compile(r'^\d+(\.\d+)*')  # Matches patterns like 1, 1.1, 1.1.1, etc.
    
    # Open the PDF
    doc = fitz.open(pdf_path)
    
    for page_num in range(len(doc)):
        page = doc[page_num]
        blocks = page.get_text("dict")["blocks"]
        
        for block in blocks:
            if "lines" in block:
                for line in block["lines"]:
                    # Extract font size and text
                    text = " ".join(span["text"] for span in line["spans"]).strip()
                    font_size = line["spans"][0]["size"]  # Assuming all spans in the line have the same size
                    
                    if section_pattern.match(text):  # Match section numbers
                        headings.append((font_size, text))
    
    # Post-process: Categorize by font size
    # Assuming larger font sizes are main headings
    font_sizes = [size for size, _ in headings]
    threshold = sum(font_sizes) / len(font_sizes)  # Use average font size as a threshold
    
    main_headings = [text for size, text in headings if size > threshold]
    subheadings = [text for size, text in headings if size <= threshold]
    
    return main_headings, subheadings

# Usage
pdf_path = "your_document.pdf"
main_headings, subheadings = extract_headings_and_subheadings(pdf_path)

print("Main Headings:")
print("\n".join(main_headings))

print("\nSubheadings:")
print("\n".join(subheadings))






import fitz  # PyMuPDF
import re

def extract_headings_from_pdf(pdf_path):
    headings = []
    section_pattern = re.compile(r'^\d+(\.\d+)*')  # Matches patterns like 1, 1.1, 1.1.1, etc.
    
    # Open the PDF
    doc = fitz.open(pdf_path)
    
    for page_num in range(len(doc)):
        page = doc[page_num]
        blocks = page.get_text("dict")["blocks"]
        
        for block in blocks:
            if "lines" in block:
                for line in block["lines"]:
                    text = " ".join(span["text"] for span in line["spans"]).strip()
                    if section_pattern.match(text):  # Match section numbers
                        headings.append(text)
    
    return headings

# Usage
pdf_path = "your_document.pdf"
headings = extract_headings_from_pdf(pdf_path)
print("\n".join(headings))









import fitz  # PyMuPDF
import re





def extract_headings_with_sections(pdf_path):
    """
    Extract headings, subheadings, and section numbers from a PDF using PyMuPDF,
    filtering out noisy content like standalone numbers and retaining valid headings.

    Parameters:
        pdf_path (str): Path to the PDF file.

    Returns:
        list: A list of dictionaries containing page number, section number, and cleaned text.
    """
    # Open the PDF
    doc = fitz.open(pdf_path)
    extracted_data = []

    for page_num in range(len(doc)):
        page = doc[page_num]
        blocks = page.get_text("dict")["blocks"]

        for block in blocks:
            if "lines" not in block:
                continue

            for line in block["lines"]:
                if "spans" not in line:
                    continue

                for span in line["spans"]:
                    text = span["text"].strip()

                    # Skip noisy content: Only keep lines with valid text and patterns
                    if len(text) <= 2 or text.isdigit():
                        continue

                    # Clean the text: Remove dots or unwanted characters
                    cleaned_text = re.sub(r"[\.]{2,}", "", text).strip()
                    cleaned_text = re.sub(r"\s{2,}", " ", cleaned_text)  # Remove extra spaces

                    # Regex to identify valid section numbers (e.g., 1, 1.1, 1.1.1)
                    match = re.match(r"^(\d+(\.\d+)*)(\s+.+)", cleaned_text)
                    if match:
                        section_number = match.group(1).strip()  # Extract the section number
                        heading_text = match.group(3).strip()    # Extract the heading text

                        # Append valid headings only
                        if heading_text:
                            extracted_data.append({
                                "page": page_num + 1,
                                "section_number": section_number,
                                "text": heading_text
                            })

    return extracted_data


def print_extracted_data(data):
    """
    Print extracted headings, subheadings, and section numbers in a formatted table.

    Parameters:
        data (list): List of extracted data dictionaries.
    """
    print(f"{'Page':<6} {'Section':<10} {'Text'}")
    print("=" * 50)
    for item in data:
        print(f"{item['page']:<6} {item['section_number']:<10} {item['text']}")


# Path to your PDF file
pdf_path = "example.pdf"

# Extract headings, subheadings, and section numbers
extracted_data = extract_headings_with_sections(pdf_path)

# Print the extracted data
if extracted_data:
    print_extracted_data(extracted_data)
else:
    print("No valid headings or subheadings found in the document.")











import fitz  # PyMuPDF
import re

def extract_headings_with_sections(pdf_path):
    """
    Extract headings, subheadings, and section numbers from a PDF using PyMuPDF,
    filtering out noisy content like standalone numbers.

    Parameters:
        pdf_path (str): Path to the PDF file.

    Returns:
        list: A list of dictionaries containing page number, section number, and cleaned text.
    """
    # Open the PDF
    doc = fitz.open(pdf_path)
    extracted_data = []

    for page_num in range(len(doc)):
        page = doc[page_num]
        blocks = page.get_text("dict")["blocks"]

        for block in blocks:
            if "lines" not in block:
                continue

            for line in block["lines"]:
                if "spans" not in line:
                    continue

                for span in line["spans"]:
                    text = span["text"].strip()

                    # Skip noisy content: Ignore lines that are only numbers
                    if text.isdigit():
                        continue

                    # Clean the text to remove unwanted dots or patterns
                    cleaned_text = re.sub(r"[\.]{2,}", "", text).strip()
                    cleaned_text = re.sub(r"\s{2,}", " ", cleaned_text)  # Remove extra spaces

                    # Regex to match valid section numbers and headings
                    match = re.match(r"^(\d+(\.\d+)*)(\s+.*)", cleaned_text)
                    if match:
                        section_number = match.group(1).strip()  # Extract the section number
                        heading_text = match.group(3).strip()    # Extract the heading text

                        # Filter out empty or short headings and numeric-only headings
                        if heading_text and not heading_text.isdigit() and len(heading_text) > 1:
                            extracted_data.append({
                                "page": page_num + 1,
                                "section_number": section_number,
                                "text": heading_text
                            })

    return extracted_data


def print_extracted_data(data):
    """
    Print extracted headings, subheadings, and section numbers in a formatted table.

    Parameters:
        data (list): List of extracted data dictionaries.
    """
    print(f"{'Page':<6} {'Section':<10} {'Text'}")
    print("=" * 50)
    for item in data:
        print(f"{item['page']:<6} {item['section_number']:<10} {item['text']}")


# Path to your PDF file
pdf_path = "example.pdf"

# Extract headings, subheadings, and section numbers
extracted_data = extract_headings_with_sections(pdf_path)

# Print the extracted data
if extracted_data:
    print_extracted_data(extracted_data)
else:
    print("No valid headings or subheadings found in the document.")









import fitz  # PyMuPDF
import re

def extract_headings_with_sections(pdf_path):
    """
    Extract headings, subheadings, and section numbers from a PDF using PyMuPDF.

    Parameters:
        pdf_path (str): Path to the PDF file.

    Returns:
        list: A list of dictionaries containing page number, section number, text, and position.
    """
    doc = fitz.open(pdf_path)
    extracted_data = []

    for page_num in range(len(doc)):
        page = doc[page_num]
        blocks = page.get_text("dict")["blocks"]

        page_data = []

        for block in blocks:
            if "lines" not in block:
                continue

            for line in block["lines"]:
                if "spans" not in line:
                    continue

                for span in line["spans"]:
                    text = span["text"].strip()
                    bbox = span["bbox"]

                    # Regex to match valid section numbers and headings
                    match = re.match(r"^(\d+(\.\d+)*)(\s+.*)", text)
                    if match:
                        section_number = match.group(1).strip()
                        heading_text = match.group(3).strip()

                        # Filtering noisy content: Only include lines with proper section numbering
                        if heading_text and len(heading_text) > 1:
                            page_data.append({
                                "page": page_num + 1,
                                "section_number": section_number,
                                "text": heading_text,
                                "position": bbox
                            })

        # Add data for this page only if valid headings exist
        if page_data:
            extracted_data.extend(page_data)

    return extracted_data


def print_extracted_data(data):
    """
    Print extracted headings, subheadings, and section numbers in a formatted table.

    Parameters:
        data (list): List of extracted data dictionaries.
    """
    print(f"{'Page':<6} {'Section':<10} {'Text'}")
    print("=" * 50)
    for item in data:
        print(f"{item['page']:<6} {item['section_number']:<10} {item['text']}")


# Path to your PDF file
pdf_path = "example.pdf"

# Extract headings, subheadings, and section numbers
extracted_data = extract_headings_with_sections(pdf_path)

# Print the extracted data
if extracted_data:
    print_extracted_data(extracted_data)
else:
    print("No valid headings or subheadings found in the document.")





import fitz  # PyMuPDF
import re

def extract_headings_with_sections(pdf_path):
    """
    Extract headings, subheadings, and section numbers from a PDF using PyMuPDF,
    excluding unwanted characters like '............'.

    Parameters:
        pdf_path (str): Path to the PDF file.

    Returns:
        list: A list of dictionaries containing page number, section number, and cleaned text.
    """
    doc = fitz.open(pdf_path)
    extracted_data = []

    for page_num in range(len(doc)):
        page = doc[page_num]
        blocks = page.get_text("dict")["blocks"]

        page_data = []

        for block in blocks:
            if "lines" not in block:
                continue

            for line in block["lines"]:
                if "spans" not in line:
                    continue

                for span in line["spans"]:
                    text = span["text"].strip()

                    # Clean the text to remove unwanted dots or similar patterns
                    cleaned_text = re.sub(r"[\.]{2,}", "", text).strip()  # Remove repeated dots
                    cleaned_text = re.sub(r"\s{2,}", " ", cleaned_text)   # Remove extra spaces

                    # Regex to match valid section numbers and headings
                    match = re.match(r"^(\d+(\.\d+)*)(\s+.*)", cleaned_text)
                    if match:
                        section_number = match.group(1).strip()
                        heading_text = match.group(3).strip()

                        # Filter out invalid or empty headings
                        if heading_text and len(heading_text) > 1:
                            page_data.append({
                                "page": page_num + 1,
                                "section_number": section_number,
                                "text": heading_text
                            })

        # Add data for this page only if valid headings exist
        if page_data:
            extracted_data.extend(page_data)

    return extracted_data


def print_extracted_data(data):
    """
    Print extracted headings, subheadings, and section numbers in a formatted table.

    Parameters:
        data (list): List of extracted data dictionaries.
    """
    print(f"{'Page':<6} {'Section':<10} {'Text'}")
    print("=" * 50)
    for item in data:
        print(f"{item['page']:<6} {item['section_number']:<10} {item['text']}")


# Path to your PDF file
pdf_path = "example.pdf"

# Extract headings, subheadings, and section numbers
extracted_data = extract_headings_with_sections(pdf_path)

# Print the extracted data
if extracted_data:
    print_extracted_data(extracted_data)
else:
    print("No valid headings or subheadings found in the document.")






import fitz  # PyMuPDF
import re

def extract_headings_with_sections(pdf_path):
    """
    Extract headings, subheadings, and section numbers from a PDF using PyMuPDF.

    Parameters:
        pdf_path (str): Path to the PDF file.

    Returns:
        list: A list of dictionaries containing page number, section number, text, and position.
    """
    # Open the PDF
    doc = fitz.open(pdf_path)
    extracted_data = []

    for page_num in range(len(doc)):
        page = doc[page_num]
        # Extract blocks of text from the page
        blocks = page.get_text("dict")["blocks"]

        page_data = []  # Temporary storage for headings on this page

        for block in blocks:
            # Check if the block contains lines
            if "lines" not in block:
                continue

            for line in block["lines"]:
                # Check if the line contains spans
                if "spans" not in line:
                    continue

                for span in line["spans"]:
                    text = span["text"].strip()
                    bbox = span["bbox"]  # Bounding box for text position

                    # Regex to identify section numbers (e.g., 1, 1.1, 1.1.1)
                    match = re.match(r"^(\d+(\.\d+)*)(.*)", text)
                    if match:
                        section_number = match.group(1).strip()  # Extract the section number
                        heading_text = match.group(3).strip()    # Extract the heading text
                        page_data.append({
                            "page": page_num + 1,
                            "section_number": section_number,
                            "text": heading_text,
                            "position": bbox
                        })

        # Add data from this page only if it contains headings/subheadings
        if page_data:
            extracted_data.extend(page_data)

    return extracted_data


def print_extracted_data(data):
    """
    Print extracted headings, subheadings, and section numbers in a formatted table.

    Parameters:
        data (list): List of extracted data dictionaries.
    """
    print(f"{'Page':<6} {'Section':<10} {'Text'}")
    print("=" * 50)
    for item in data:
        print(f"{item['page']:<6} {item['section_number']:<10} {item['text']}")


# Path to your PDF file
pdf_path = "example.pdf"

# Extract headings, subheadings, and section numbers
extracted_data = extract_headings_with_sections(pdf_path)

# Print the extracted data
if extracted_data:
    print_extracted_data(extracted_data)
else:
    print("No headings or subheadings found in the document.")







import fitz  # PyMuPDF
import re

def extract_headings_with_sections(pdf_path):
    """
    Extract headings, subheadings, and section numbers from a PDF using PyMuPDF.

    Parameters:
        pdf_path (str): Path to the PDF file.

    Returns:
        list: A list of dictionaries containing page number, section number, text, and position.
    """
    # Open the PDF
    doc = fitz.open(pdf_path)
    extracted_data = []

    for page_num in range(len(doc)):
        page = doc[page_num]
        # Extract blocks of text from the page
        blocks = page.get_text("dict")["blocks"]

        for block in blocks:
            # Check if the block contains lines
            if "lines" not in block:
                continue

            for line in block["lines"]:
                # Check if the line contains spans
                if "spans" not in line:
                    continue

                for span in line["spans"]:
                    text = span["text"].strip()
                    bbox = span["bbox"]  # Bounding box for text position

                    # Regex to identify section numbers (e.g., 1, 1.1, 1.1.1)
                    match = re.match(r"^(\d+(\.\d+)*)(.*)", text)
                    if match:
                        section_number = match.group(1).strip()  # Extract the section number
                        heading_text = match.group(3).strip()    # Extract the heading text
                        extracted_data.append({
                            "page": page_num + 1,
                            "section_number": section_number,
                            "text": heading_text,
                            "position": bbox
                        })

    return extracted_data


def print_extracted_data(data):
    """
    Print extracted headings, subheadings, and section numbers in a formatted table.

    Parameters:
        data (list): List of extracted data dictionaries.
    """
    print(f"{'Page':<6} {'Section':<10} {'Text'}")
    print("=" * 50)
    for item in data:
        print(f"{item['page']:<6} {item['section_number']:<10} {item['text']}")


# Path to your PDF file
pdf_path = "example.pdf"

# Extract headings, subheadings, and section numbers
extracted_data = extract_headings_with_sections(pdf_path)

# Print the extracted data
print_extracted_data(extracted_data)





import fitz  # PyMuPDF
import re

def extract_headings_with_sections(pdf_path):
    """
    Extract headings, subheadings, and section numbers from a PDF using PyMuPDF.

    Parameters:
        pdf_path (str): Path to the PDF file.

    Returns:
        list: A list of dictionaries containing page number, section number, text, and position.
    """
    # Open the PDF
    doc = fitz.open(pdf_path)
    extracted_data = []

    for page_num in range(len(doc)):
        page = doc[page_num]
        # Extract blocks of text from the page
        blocks = page.get_text("dict")["blocks"]

        for block in blocks:
            for line in block["lines"]:
                for span in line["spans"]:
                    text = span["text"].strip()
                    bbox = span["bbox"]  # Bounding box for text position

                    # Regex to identify section numbers (e.g., 1, 1.1, 1.1.1)
                    match = re.match(r"^(\d+(\.\d+)*)(.*)", text)
                    if match:
                        section_number = match.group(1).strip()  # Extract the section number
                        heading_text = match.group(3).strip()    # Extract the heading text
                        extracted_data.append({
                            "page": page_num + 1,
                            "section_number": section_number,
                            "text": heading_text,
                            "position": bbox
                        })

    return extracted_data


def print_extracted_data(data):
    """
    Print extracted headings, subheadings, and section numbers in a formatted table.

    Parameters:
        data (list): List of extracted data dictionaries.
    """
    print(f"{'Page':<6} {'Section':<10} {'Text'}")
    print("=" * 50)
    for item in data:
        print(f"{item['page']:<6} {item['section_number']:<10} {item['text']}")


# Path to your PDF file
pdf_path = "example.pdf"

# Extract headings, subheadings, and section numbers
extracted_data = extract_headings_with_sections(pdf_path)

# Print the extracted data
print_extracted_data(extracted_data)


=SUMPRODUCT(--(ISNUMBER(SEARCH(TRIM(MID(SUBSTITUTE(A1, " ", REPT(" ", 100)), ROW(INDIRECT("1:" & LEN(A1)-LEN(SUBSTITUTE(A1, " ", ""))+1))*100-99, 100)), B1)))) / (LEN(A1)-LEN(SUBSTITUTE(A1, " ", ""))+1) * 100




# Initialize counters and sums
correct_matches = 0  # Total correctly matched paragraphs
matched_completeness_sum = 0  # Sum of completeness scores for matched paragraphs
matched_count = 0  # Count of matched paragraphs
total_gt_paragraphs = len(ground_truth_paragraphs)  # Total ground truth paragraphs
completeness_sum = 0  # Sum of completeness scores for all predictions

# Process predictions and ground truth
for gt_para, predicted_para in zip(ground_truth_paragraphs, predicted_paragraphs):
    # Find best match score and index for each ground truth paragraph
    best_match_score, best_match_idx = get_best_match(gt_para, predicted_para)

    if best_match_score > 0:  # Match found
        correct_matches += 1
        matched_completeness_sum += best_match_score  # Only for matched paragraphs
        matched_count += 1

    completeness_sum += best_match_score  # Sum completeness for all paragraphs

    # Append row-wise results
    result_rows.append({
        "groundTruth": gt_para,
        "predicted": predicted_para if predicted_para else "",
        "extracted": best_match_score > 0,  # True if a match exists
        "matching_ai_index": best_match_idx if best_match_score > 0 else -1,
        "completeness": best_match_score,
        "correctness": 1 if best_match_score > 0 else 0
    })

# Process extra ground truth paragraphs not matched with any prediction
extra_gts = [gt for gt in ground_truth_paragraphs if gt not in [row["groundTruth"] for row in result_rows]]

for pr_gt in extra_gts:
    result_rows.append({
        "groundTruth": pr_gt,
        "predicted": None,
        "extracted": False,
        "matching_ai_index": None,
        "completeness": 0,
        "correctness": 0
    })

# Calculate Overall Metrics
overall_correctness = correct_matches / total_gt_paragraphs if total_gt_paragraphs > 0 else 0
overall_completeness = (
    matched_completeness_sum / matched_count if matched_count > 0 else 0
)

# Calculate Recall and Precision
count_based_recall = correct_matches / total_gt_paragraphs if total_gt_paragraphs > 0 else 0
count_based_precision = correct_matches / len(predicted_paragraphs) if len(predicted_paragraphs) > 0 else 0

# Calculate Business Score
business_score = (0.6 * overall_correctness) + (0.4 * overall_completeness)

# Summary of results
summary = {
    "Overall Correctness": overall_correctness,
    "Overall Completeness": overall_completeness,
    "Recall": count_based_recall,
    "Precision": count_based_precision,
    "Business Score": business_score
}

# Return final result rows and summary
return result_rows, summary






Algorithm for the Document Processing Workflow
Here's a step-by-step algorithm that outlines the complete process for the document processing workflow using Azure and AI services:

Initialize Connections and Load Configurations

Establish connections to Azure Blob Storage using managed identity configurations (pm_azure_blob_connection and di_azure_blob_connection).
Load configurations for AI models, regex patterns, and document processing settings.
Input Document Acquisition

Retrieve the input document from Azure Blob Storage using the specified connection details.
Validate the document's format and accessibility.
Artifact Generation and Initialization

Initialize artifacts to capture essential document metadata:
Page Dimensions: Record the size of each page in the document.
Document Layout: Identify structural elements such as text blocks, tables, and images.
Logical Chunks: Segment the document into manageable sections for targeted analysis.
Document Parsing using Azure Document Intelligence

Parse the document using the Azure Cognitive Services model (prebuilt-layout).
Extract and store the document layout, page dimensions, and logical chunks for further processing.
Regex Filtering of Logical Chunks

Apply regex patterns to the logical chunks to filter out sections containing specific financial keywords.
Extract chunks that match the keywords such as Management Fee, Compensation, and other relevant terms.
AI Filtering of Extracts Using Azure OpenAI

Use Azure OpenAI models to further refine the filtered logical chunks.
Input: Filtered logical chunks.
Output: AI-filtered extracts containing relevant paragraphs that answer predefined financial questions.
Key Terms Identification

Identify key financial and legal terms within the AI-filtered extracts using the AI model.
Extract a list of key terms that are significant for understanding the financial context of the document.
Regex Filtering of Key Term Definitions

Apply regex patterns to further filter the identified key terms to pinpoint exact definitions within the document.
Extract text snippets that provide definitions for the key terms.
AI Filtered Key Term Definitions

Use Azure OpenAI to refine and enhance the definitions of the key terms.
Input: Regex-filtered key term definitions.
Output: Contextualized, detailed definitions of each key term.
AI MFees Interpretations

Generate interpretations of the management fee-related extracts using AI models.
Simplify complex financial language into concise, understandable summaries.
Provide interpretations that highlight critical insights about management fees and their calculations.
AI Key Term Definitions Interpretations

Use AI models to provide clear and comprehensive interpretations of the key term definitions.
Cross-reference key term definitions with relevant document content to ensure accuracy.
Generate summarized interpretations that facilitate easy understanding of complex financial and legal terms.
Output Generation

Compile the results, including page dimensions, document layout, logical chunks, filtered extracts, key terms, definitions, and interpretations.
Format the output data for presentation, reporting, or further analysis by end-users.
Error Handling and Validation

Implement error handling for data retrieval, model processing, and interpretation stages.
Validate outputs at each stage to ensure consistency and accuracy before final output generation.
End of Process

Save the processed data and results back to Azure Blob Storage or an alternative storage solution as required.
Log the process flow and outputs for auditing and troubleshooting purposes.
Key Points
The algorithm leverages a combination of regex filtering and AI-driven extraction techniques to ensure precise identification and interpretation of key financial terms within complex documents.
Each step is validated and cross-referenced to ensure data integrity and accuracy, providing reliable outputs that enhance decision-making.
The integration of Azure OpenAI models adds contextual understanding to the extracted information, making it easier to navigate complex legal and financial language.
This algorithm provides a structured approach to processing and analyzing financial documents, enabling automated insights that are critical for legal, financial, and compliance needs. Let me know if you need further details or specific code implementations for each step!










ChatGPT can make mistakes. Check









1. Input Document Acquisition
Description: This stage involves fetching the input documents from Azure Blob Storage using a managed identity for secure access. The system connects to specific Azure Blob containers using predefined connection settings to locate and retrieve the document files needed for processing.
Purpose: To provide the initial data required for analysis, ensuring that the documents are securely accessed and correctly identified.
2. Artifact Generation and Initialization
Description: Once the documents are retrieved, the system initializes various artifacts that are essential for further processing. This includes setting up data structures like page dimensions, document layout, logical chunks, key term lists, and more. These artifacts help in organizing and structuring the content of the document for subsequent analysis.
Components:
Page Dimensions: Captures the size and layout of each page.
Document Layout: Defines the structure of the document.
Logical Chunks: Divides the document into meaningful sections for processing.
3. Document Parsing
Description: In this stage, Azure Document Intelligence is used to analyze the document's layout and content. It identifies various elements such as text, tables, images, and other structural components. This process is crucial for extracting meaningful chunks of data that can be further analyzed.
Purpose: To break down the document into its fundamental parts, making it easier to target specific information during subsequent analysis.
4. Regex Filtering of Logical Chunks
Description: The logical chunks of the document are filtered using predefined regex patterns to identify specific keywords related to financial and management terms, such as "Management Fee," "Compensation," and others. This stage narrows down the content to the most relevant sections based on the target terms.
Purpose: To refine the document content by focusing on relevant sections that contain specific key terms, allowing for more efficient and targeted analysis.
5. AI Filtering of Extracts
Description: This stage uses Azure OpenAI models to further refine the extracts identified by the regex filtering. The AI models are prompted to answer specific financial questions or highlight relevant content related to management fees and other terms.
Purpose: To enhance the filtering process by leveraging AI's ability to understand context and provide insights beyond simple keyword matching.
6. Key Terms Identification
Description: AI models analyze the filtered content to identify key financial and legal terms. This process involves scanning the text to detect significant terms that are essential for understanding the document's content.
Purpose: To create a comprehensive list of key terms that are critical for interpreting the financial information presented in the document.
7. Regex Filtering of Key Term Definitions
Description: Identified key terms are subjected to another round of filtering using regex patterns to pinpoint the precise definitions within the document. This helps in associating each key term with its most relevant and accurate description.
Purpose: To ensure that each key term is clearly defined within the context of the document, enhancing comprehension for further analysis.
8. AI Filtered Key Term Definitions
Description: Azure OpenAI models are used to refine the definitions of the key terms identified in the previous stage. The models are prompted to provide detailed, contextual definitions based on the document content.
Purpose: To deliver clear, context-specific definitions that help in understanding the financial and legal nuances of the key terms.
9. AI MFees Interpretations
Description: The AI models interpret and summarize the management fee-related content extracted from the document. This involves breaking down complex financial language into simpler, more digestible summaries.
Purpose: To provide actionable insights and interpretations of management fee structures, calculations, and related financial information.
10. AI Key Term Definitions Interpretations
Description: In the final stage, AI models provide interpretations of the key term definitions, summarizing the financial and legal implications in a clear and concise manner. This includes cross-referencing the definitions with the document's content to ensure accuracy.
Purpose: To synthesize the key term definitions into understandable interpretations that can be easily used by non-experts, supporting decision-making and compliance.
These descriptions outline the specific functionality and purpose of each stage in the document processing workflow, highlighting how Azure and AI services are integrated to achieve comprehensive document analysis. Let me know if you need further details on any of these stages!






You said:
Overall description about the project 
ChatGPT said:
ChatGPT
Overall Description of the Project
The project is a comprehensive document processing and analysis system designed to handle complex financial and legal documents using Azure and AI technologies. The primary goal of the system is to extract, interpret, and summarize critical information related to management fees and other key financial terms found within these documents. This automated process aims to provide accurate, relevant insights, reducing manual effort and enhancing the efficiency of document analysis for financial institutions, legal firms, and other stakeholders.

Key Objectives
Automate Document Parsing and Analysis: Utilize Azure Document Intelligence and OpenAI models to automate the extraction and analysis of complex documents, thereby reducing the time and effort required for manual review.
Identify and Interpret Key Financial Terms: Use AI and regex-based filtering to identify key terms related to financial management, such as management fees, compensation, and other expenses, ensuring that relevant information is accurately highlighted.
Provide Clear, Actionable Insights: Interpret the extracted content to deliver concise, understandable summaries of complex financial terms, enabling better decision-making and compliance review.
Technical Components
Azure Blob Storage: Serves as the secure storage location for all input documents, enabling easy access and retrieval through managed identity connections.
Azure Cognitive Services (Document Intelligence): Analyzes the document structure, extracting logical chunks, page layouts, and other relevant information necessary for detailed processing.
Azure OpenAI Models: Plays a central role in refining the extracted content, identifying key terms, and generating interpretations and definitions that are contextually accurate.
Regex Filtering: Combines traditional pattern matching techniques with AI models to ensure precise extraction of financial and legal terms.
Workflow Overview
Document Acquisition: The process begins with retrieving the document from Azure Blob Storage, followed by artifact initialization to prepare the document for analysis.
Document Parsing and Chunking: Azure Document Intelligence parses the document into logical sections, enabling targeted analysis of specific content areas.
Filtering and AI-Driven Extraction: Key terms and relevant paragraphs are identified using regex filtering and AI models, focusing on specific financial terms related to management fees and other expenses.
Interpretation and Summarization: AI models provide detailed interpretations of the identified content, breaking down complex legal and financial information into manageable insights.
Output Generation: The system produces clear, organized summaries and interpretations that can be used directly by stakeholders for financial analysis, legal compliance, or reporting purposes.
Benefits
Enhanced Accuracy and Efficiency: Automates the extraction and interpretation of critical information, significantly reducing the risk of human error.
Time Savings: Speeds up the document review process, allowing analysts and legal professionals to focus on higher-value tasks rather than manual content extraction.
Improved Decision-Making: Provides actionable insights by breaking down complex financial terms into understandable summaries, facilitating better decision-making and strategic planning.
Scalability: The system is designed to handle large volumes of documents, making it suitable for organizations with extensive document processing needs.
Use Cases
Financial Institutions: For processing investment fund documents, understanding fee structures, and ensuring compliance with regulatory requirements.
Legal Firms: Assisting in the review of complex contracts, identifying critical terms, and providing clear interpretations for legal advice.
Corporate Finance Teams: Analyzing management fees, compensation terms, and other expenses to optimize financial management and strategy.
Conclusion
This project leverages state-of-the-art AI and cloud technologies to transform how complex financial documents are processed and interpreted. By automating key aspects of document analysis, the system not only enhances accuracy and efficiency but also empowers users with valuable insights that drive better business outcomes.

Let me know if you need further customization or additional information!









ChatGPT can make mistakes. Check important








ChatGPT 4o







You said:
{

"version": 1,

"vars": {

"pm_azure_blob_connection": {

"auth_type": "MANAGED",

"mi_client_id": "5da05a4c-edb2-4f9f-8ad8-d11f0214f557",

"account_url": "https://npeedevgtsd01txtmrm.blob.core.windows.net",

"doc_container": "pvt-markets"

},

"di_azure_blob_connection": {

"auth_type": "MANAGED",

"mi_client_id": "5da05a4c-edb2-4f9f-8ad8-d11f0214f557",

"account_url": "https://npeedevgtsd01txtmrm.blob.core.windows.net",

"doc_container": "npeedevgtsd@1txtmrm-strgcont-txtmrm-01"

}, "input_document_path": {

"source": "AzureBlob",

I

params": { "

}

}

"connection": "{vars.pm_azure_blob_connection)",

"storage_location": "(payload.documents[0].storagePath.absolute_path}"

},

"artifacts": {

"pageDimensions": {

"source": "Transient",

"data": [],

"params": {},

"extant": false

},
"documentLayout": {

"source": "Transient",

"data": [],

"params": {},

"extant": false

},

"logicalChunks": {

"source": "AzureBlob",

"data": [],

"params": {

"connection": "{vars.di_azure_blob_connection)",

"absolute_location": "<path_to_file>",

"encoding": "utf_8 e.g.// utf_8, binary, file_like_object"

},

"extant": false

}, "extractsUsingPrescribed Language": {

"source": "Transient",

I

"data": [],

"params": {},

"extant": false

},

"aiFilteredExtracts": {

"source": "Transient",

"data": [],

"params": {}, "extant": false
},

"keyTerms": {

"source": "Transient",

"data": [],

"params": {},

"extant": false

}, "regexFilteredDefinitions": {

"source": "Transient",

"data": [],

"params": {},

"extant": false

},

"keyTermDefinitions": {

"source": "Transient",

"data": [],

"params": {},

"extant": true

},

"keyTermMapping":{

"source": "Transient",

"data": [],

"params": {},

"extant": true

},

"mFees Interpretations": {

"source": "AzureBlob",

data": [], "

"params": {

"connection": "{vars.di_azure_blob_connection)",

"absolute_location": "<path_to_file>",
"encoding": "utf_8 e.g.// utf_8, binary, file_like_object"

},

"extant": false

},

"keyTermInterpretations": {

"source": "AzureBlob",

"data": [],

"params": {

"connection": "{vars.di_azure_blob_connection)",

"absolute_location": "<path_to_file>",

"encoding": "utf_8 e.g.// utf_8, binary, file_like_object"

},

"extant": false

}

}, "output": {

"pageDimensions": "(artifacts.pageDimensions.data}", "documentLayout": "(artifacts.documentLayout.data}",

"logicalChunks": "{artifacts.logicalChunks.data}",

"extractsUsing PrescribedLanguage": "{artifacts.extractsUsing PrescribedLanguage.data}",

"keyTerms": "{artifacts.keyTerms.data)",

"keyTermDefinitions": "{artifacts.keyTermDefinitions.data)",

"keyTermMapping": "{artifacts.keyTermMapping.data)",

"aiFilteredExtracts": "{artifacts.aiFilteredExtracts.data}", "mFees Interpretations": "{artifacts.mFees Interpretations.data)",

"keyTermInterpretations": "{artifacts.keyTermInterpretations.data}"

},
"stages": [

{

"capability": "DocumentParsing",

"method": "AzureDocument Intelligence",

"label": "DocumentParsing",

"processing_config": {

"processing_engine": "Azure-openai",

"model": "prebuilt-layout",

"endpoint": "https://npee-use2-dev-fr-01.cognitiveservices.azure.com/",

"key": "bacfb986c0874ace9211551852829213"

},

"input": {

"document_path": "{vars.input_document_path}"

}, "output": {

"(artifacts.logicalChunks.data}": "logicalChunks",

"{artifacts.documentLayout.data)": "document Layout",

"(artifacts.pageDimensions.data)": "pageDimensions"

"capability": "GenAIExtraction",

"method": "RegexFiltering",

"label": "Logical Chunks Regex Filtering",

"input": {

"logicalChunks": "(artifacts.logicalChunks.data}",

"keywords": [

"Management Fee",

"Management +Fee",

I

}

"Servicing Fee", "Servicing +Fee",

"Investment Advisory Fee",
"Investment +Advisory +Fee",

"Compensation",

"Remuneration",

"Expenses",

"AIFM Fee",

"AIFM +Fee"

},

]

"{artifacts.extractsUsing Prescribed Language.data}": "extractsUsing Prescribed Language"

}

"output": {

"capability": "GenAIExtraction",

"method": "Prompting",

"label": "AI Filtered MFees Related Extracts",

"processing_config": {

"model_connection": {

"model_provider_type": "AzureOpenAI",

"openai_api_type": "azure",

"azure_openai_endpoint": "https://ssgpt-predev.openai.azure.com/",

"azure_openai_api_version": "2023-07-01-preview",

"openai_api_key": "43d6ab1448834574807eff7a195f76f3",

"deployment_name": "ssgpt-40"

}, "temperature": 0,

"seed": 17

"prompt": {

"template":" Objective \nYou will be given a list of paragraphs. You need to identify the paragraphs that helpenser one or more of exes which helped answer one or more of the questions. Ind. Create a field 'questions: List of the question Indexes that was wered by the paragra (

"input variables"

"questions":{

"indexing required": true,

"data":[

"Can you explain the calculation, payment timing, and due dates of the Management Fees?"

"How are the Management Fees affected by the Fund's Investment in any Primary Investee fund or Secondary Investee Fund, "How is the Management Fee calculated and reduced in relation to various Investments and fees

"paragraphs": {

"indexing required": true,

"date": "(artifacts.extractsUsing PrescribedLanguage.data)"

"post process required": true

"output" (

"(artifacts.eiFilteredExtracts.data)": "aifilteredExtracts"

"capability": "GenAZExtraction",

"method": "Prompting",

"label": "Keyteres Identification",

"processing config":{

model connection: (

"model provider_type": "AzurepenAI",

"openai api type": "azurM
"azure_openai_endpoint": "https://ssgpt-predev.openai.azure.com/",

"azure_openai_api_version": "2023-07-01-preview",

"openai_api_key": "43d6ab1448834574807eff7a195f76f3",

"deployment_name": "ssgpt-40"

},

"temperature": 0,

"seed": 17

},

"prompt": {

"template": "\n# Objective\nYou will be given a list of paragraphs. Your task is to identify the keyterms present in eac

ing company, financial services company and partnership.\n7. Respond back with the list of keyterms against each Paragraph in title case

"input_variables": {

"paragraphs": {

"indexing_required": true,

"data": "{artifacts.aiFilteredExtracts.data}"

}

},

"post_process_required": true

},

"output": {

"{artifacts.keyTerms.data}": "keyTerms"

"capability": "GenAIExtraction",

"method": "RegexFiltering",

"label": "Regex Filtered Keyterm Definitions",

input": { "

"logicalChunks": "fartifacts.logicalChunks.data}",

"keyTerms": "{artifacts.keyTerms.data}"

},
"output": {

"(artifacts.regexFilteredDefinitions.data)": "regexFilteredDefinitions"

}

"capability": "GenAIExtraction",

"method": "Prompting",

"label": "AI Filtered Keyterm Definitions",

processing_config": { "

"model_connection": {

"model_provider_type": "AzureOpenAI",

"openai_api_type": "azure",

"azure_openai_endpoint": "https://ssgpt-predev.openai.azure.com/",

"azure_openai_api_version": "2023-07-01-preview",

"openai_api_key": "43d6ab1448834574807eff7a195f76f3",

"deployment_name": "ssgpt-40"

},

"temperature": 0,

"seed": 2

}, "prompt": {

"template": "\n# Objective\nYou will be provided with a numbered list of Paragraphs and Keyterms. For each of the provided Keyter

hat provides the definition of the Keyterm, return -1 within a list as the index response to the Keyterm.\n\n\n# Output Instructions:\n\n## Outpu

"input_variables": { "paragraphs ": {

"indexing_required": true,

"data": "(artifacts.regexFilteredDefinitions.data)"

}, "keyterms": {

"indexing_required": true,

"data": "{artifacts.keyTerms.data)"
}

}, "post_process_required": true

}, "output": {

"(artifacts.keyTermDefinitions.data)": "keyTermDefinitions",

"(artifacts.keyTermMapping.data)": "keyTermMapping"

}

"capability": "GenAIExtraction",

"method" : "Prompting",

"label": "AI MFees Interpretations",

"processing_config": {

"model_connection": {

"model_provider_type": "AzureOpenAI",

"openai_api_type": "azure",

"azure_openai_endpoint": "https://ssgpt-predev.openai.azure.com/",

"azure_openai_api_version": "2023-07-01-preview",

"openai_api_key": "43d6ab1448834574807eff7a195f76f3",

"deployment_name": "ssgpt-40"

},

"temperature": 0,

"seed": 2

}, "prompt": {

"template": "\n# Objective\nYou are tasked to interpret and summarize legal and financial content related to investment funds and manag in title case or capital letters are not changed in the interpretation.\n6. Break down the interpretation into small sentences.\n7. If you are not able terpretations for the paragraph using the reference of 'Keyterm Definition Extracts' if required to understand the content of the paragraph for interpr

input_variables": { " "

mFees InterpretationsExtracts": {

"indexing_required": true,
"data": "(artifacts.aiFilteredExtracts.data}" },

"KeyTermDefinitionExtracts": {

"indexing_required": true,

"data": "{artifacts.keyTermDefinitions.data}"

}

},

"post_process_required": false

}, "output": {

"{artifacts.mFees Interpretations.data)": "mFees Interpretations"

}

"capability": "GenAIExtraction",

"method": "Prompting",

"label": "AI Keyterm Definitions Interpretations",

"processing_config": {

"model_connection": {

"model_provider_type": "AzureOpenAI",

"openai_api_type": "azure",

"azure_openai_endpoint": "https://ssgpt-predev.openai.azure.com/",

"azure_openai_api_version": "2023-07-01-preview", "openai_api_key": "43d6ab1448834574807eff7a195f76f3",

"deployment_name": "ssgpt-40"

},

"temperature": 0,

"seed": 2

}, "prompt": {

"template": "\n# Objective\nYou are tasked to interpret and summarize legal and financial content related to investment f wotation of the keyterm definition.\n\n# Understanding the layout of 'Keyterm Definition Extracts' provided in the i

The contents of 'Keyterm Definition Extracts' are bullet listed paragraphs, with each paragraph containing the mapping of s.",

"input_variables": {

"KeyTermDefinitionExtracts": {

"indexing_required": true,

"data": "{artifacts.keyTermDefinitions.data}"

},

"keyTermMapping": {

"indexing_required": true,

"data": "{artifacts.keyTermMapping.data}"

}

},

"post_process_required": true

},

"output": {

"{artifacts.key TermInterpretations.data}": "key Term Interpretations"

}

}

]

}



""Create a high level flowchat of work flow and create a detailed technical stage wise documentation and create service wise functinolity write up
ChatGPT said:
ChatGPT
To create a comprehensive understanding of the provided JSON configuration, we'll break it down into a detailed flowchart of the workflow and a stage-wise documentation that includes service-wise functionality descriptions. Here's the approach:

High-Level Flowchart of Workflow
Input Document Acquisition

Source: Azure Blob Storage.
Connections: pm_azure_blob_connection and di_azure_blob_connection.
Data: Input document path fetched from Azure Blob.
Artifact Generation and Initialization

Artifacts Created:
Page Dimensions
Document Layout
Logical Chunks
Extracts Using Prescribed Language
AI Filtered Extracts
Key Terms
Key Term Definitions
Key Term Mapping
MFees Interpretations
Key Term Interpretations
Document Parsing Stage

Capability: DocumentParsing
Method: AzureDocument Intelligence (prebuilt-layout model).
Output: Logical chunks, document layout, and page dimensions.
Regex Filtering Stage

Capability: GenAIExtraction
Method: RegexFiltering
Input: Logical chunks filtered with specified keywords (Management Fees, Compensation, etc.).
Output: Extracts using Prescribed Language.
AI Filtering of Extracts

Capability: GenAIExtraction
Method: Prompting with AzureOpenAI.
Output: AI Filtered MFees Related Extracts.
Key Terms Identification

Capability: GenAIExtraction
Method: Prompting with AzureOpenAI.
Output: Key Terms.
Regex Filtering of Key Term Definitions

Capability: GenAIExtraction
Method: RegexFiltering
Output: Regex Filtered Key Term Definitions.
AI Filtered Key Term Definitions

Capability: GenAIExtraction
Method: Prompting with AzureOpenAI.
Output: Key Term Definitions and Mapping.
AI MFees Interpretations

Capability: GenAIExtraction
Method: Prompting with AzureOpenAI.
Output: MFees Interpretations.
AI Key Term Definitions Interpretations

Capability: GenAIExtraction
Method: Prompting with AzureOpenAI.
Output: Key Term Interpretations.
Stage-wise Documentation
Input Document Acquisition

Description: Fetches documents from Azure Blob Storage using managed identity connections (pm_azure_blob_connection and di_azure_blob_connection).
Purpose: To provide input data for processing through the Azure OpenAI models.
Document Parsing

Description: Parses the document to identify layout and logical chunks using Azure Cognitive Services.
Functionality:
Extracts structural information like page dimensions and layout.
Identifies logical sections of the document for further analysis.
Regex Filtering of Logical Chunks

Description: Uses regex patterns to filter logical chunks for specific keywords related to fees and financial terms.
Functionality:
Focuses on terms like "Management Fee," "Compensation," and other financial keywords.
Extracts text segments relevant to fee calculations and descriptions.
AI Filtering of Extracts

Description: Applies Azure OpenAI models to refine filtered chunks by identifying relevant fee-related content.
Functionality:
Uses prompting techniques to focus on answering specific financial questions.
Outputs filtered extracts that provide relevant answers.
Key Terms Identification

Description: Identifies key financial and legal terms within the filtered extracts.
Functionality:
Uses AI models to detect and list key terms.
Provides context for understanding financial terminology within the document.
Regex Filtering of Key Term Definitions

Description: Further filters the key terms to refine their definitions using regex patterns.
Functionality:
Matches and extracts text that defines the identified key terms.
AI Filtered Key Term Definitions

Description: AI models provide detailed definitions and mapping for identified key terms.
Functionality:
Outputs refined definitions that are contextually accurate for financial interpretations.
MFees Interpretations

Description: Interprets the filtered extracts related to management fees and other financial terms.
Functionality:
Breaks down complex financial text into manageable summaries.
Provides interpretative insights for legal and financial understanding.
Key Term Definitions Interpretations

Description: Provides a clear, summarized interpretation of key term definitions with contextual mapping.
Functionality:
Offers a simplified, accurate understanding of complex legal and financial definitions.
Supports clearer comprehension for non-technical stakeholders.
Service-Wise Functionality Write-up
Azure Blob Storage

Manages document storage and retrieval securely using managed identity for access.
Azure Cognitive Services - Document Intelligence

Parses and analyzes document structure, enabling logical division and understanding of document layouts.
Azure OpenAI Services

Implements AI-driven extraction, filtering, and interpretation of financial and legal text.
Models configured with specific prompting strategies to ensure accurate, relevant outputs.
Regex Filtering and AI Extraction Methods

Ensures precise identification of terms and extracts based on defined patterns and AI model capabilities.
Enhances the accuracy of document analysis by combining deterministic regex and probabilistic AI techniques.
This documentation provides a detailed overview of each step, outlining how Azure and OpenAI services are used to process, extract, and interpret complex financial documents effectively. Let me know if you need any specific adjustments or further details!






You said:
I need flow chat diagram 
ChatGPT said:
ChatGPT

Create a flowchart diagram illustrating a document processing workflow using Azure and AI services. The flowchart should include the following stages: 1) Input Document Acquisition from Azure Blob Storage, 2) Artifact Generation and Initialization with components like Page Dimensions, Document Layout, Logical Chunks, etc., 3) Document Parsing using Azure Document Intelligence, 4) Regex Filtering of Logical Chunks with specific keywords, 5) AI Filtering of Extracts using Azure OpenAI, 6) Key Terms Identification using AI, 7) Regex Filtering of Key Term Definitions, 8) AI Filtered Key Term Definitions, 9) AI MFees Interpretations, and 10) AI Key Term Definitions Interpretations. The flowchart should have clear directional arrows showing the flow of data between each stage, with each stage represented by a distinct box labeled accordingly.
Here is the flowchart diagram illustrating the document processing workflow using Azure and AI services. It includes all the stages from document acquisition to AI interpretations as described. You can review and use it for your reference!












ChatGPT

You said:
Ai reletad taks like working on documents ""i need to send the information to my officer please give me content 
ChatGPT said:
ChatGPT
To assist you in preparing content to send to your officer, I will need more details about the specific task or type of information you're working on. Could you clarify:

What kind of document are you preparing (e.g., report, memo, email)?
What specific information needs to be included (e.g., project updates, data analysis, etc.)?
Any particular format or tone you prefer (formal, brief, detailed)?
Feel free to provide more details, and Ill help craft the content for you.






You said:
Al related tasks:

Step 1: loading pdf document

Step 2: using pdf miner or ADI we are generating the text(Prescribed language)

Step 3: Extracts management fees related extracts from prescribed language(step 2 output we are giving as input)

Step 4: Identify the keyterms from management fees related extracts(step 3 output we are giving as input)

Step 5: extracts keyterm defination from keyterms identification ((step 4 output we are giving as input)

I

Search

Inibss
ChatGPT said:
ChatGPT
It sounds like you're describing an AI workflow for processing documents, specifically for extracting and analyzing management fees-related terms from PDF documents. Heres a refined summary based on your steps:

AI Task Workflow: Document Processing for Management Fees
Step 1: Load PDF Document
Use tools like PDFMiner or Apache PDFBox to read and load the PDF document.
Step 2: Convert PDF to Text
Extract the text from the PDF using PDFMiner or ADI (Advanced Data Interface), ensuring it preserves the prescribed language or format from the document.
Step 3: Extract Management Fees-related Sections
Process the extracted text to filter out sections that mention management fees.
This can be done using Natural Language Processing (NLP) techniques, such as keyword matching or regex patterns, to isolate paragraphs or sentences that mention fees, costs, or similar terms.
Step 4: Identify Key Terms Related to Management Fees
From the extracted sections, run an analysis to detect key terms related to management fees, such as annual fee, administrative fee, etc.
This can be achieved through tokenization, Named Entity Recognition (NER), or custom dictionaries of financial terms.
Step 5: Extract Definitions of Key Terms
Once the key terms are identified, extract definitions or related explanations from the surrounding text.
This can involve proximity-based extraction, where definitions are typically found near the terms, or referencing a predefined glossary or external data source for definitions.
Tools & Libraries:
PDFMiner (for PDF text extraction)
NLTK or spaCy (for NLP tasks like keyword extraction and term recognition)
Custom Dictionaries or Financial Lexicons (for term matching)
Let me know if you need further details or if you would like me to elaborate on any specific part of this process!






You said:
Can u give me objective of the program. And whatvis your role ofvthe program " they are asking my role is building the models and also evalutingthe the model i
ChatGPT said:
ChatGPT
Heres a potential objective for the program and a description of your role based on the tasks youve outlined:

Objective of the Program:
The objective of this program is to automate the extraction, identification, and analysis of management fee-related information from PDF documents using AI and Natural Language Processing (NLP) techniques. The system aims to streamline the process of reading complex documents, isolating specific fee-related sections, identifying key financial terms, and extracting their definitions. This will help in making fee structures and related information more accessible and manageable for further analysis or reporting.

Your Role in the Program:
As a Model Developer and Evaluator, your role involves:

Building NLP Models:

Designing and implementing AI models that process PDF documents, extract relevant text, and identify key terms related to management fees.
Utilizing tools like PDFMiner for document processing and NLP libraries (e.g., NLTK, spaCy) for extracting and analyzing text.
Developing customized models for key term extraction and definition identification, ensuring they are aligned with the prescribed language and specific requirements of the task.
Evaluating Models:

Testing and validating the accuracy and efficiency of the models to ensure the extracted information is relevant, correct, and in line with expected outputs.
Evaluating the performance of the models using metrics like precision, recall, and F1-score to measure the quality of extraction and identification processes.
Continuously improving models based on evaluation results, feedback, and new data to enhance overall performance.
Optimizing the Workflow:

Ensuring the entire process, from loading documents to extracting definitions, is seamless and optimized for scalability.
Collaborating with other team members to integrate the AI models into the broader system and refine them based on user needs or new use cases.
This should give you a solid overview of both the programs objective and your critical role within it. Let me know if you'd like further adjustments or clarifications!






Is this conversation helpful so far?












AI Task Workflow: Document Processing for Management Fees
Step 1: Load PDF Document
Use tools like PDFMiner or Apache PDFBox to read and load the PDF document.
Step 2: Convert PDF to Text
Extract the text from the PDF using PDFMiner or ADI (Advanced Data Interface), ensuring it preserves the prescribed language or format from the document.
Step 3: Extract Management Fees-related Sections
Process the extracted text to filter out sections that mention management fees.
This can be done using Natural Language Processing (NLP) techniques, such as keyword matching or regex patterns, to isolate paragraphs or sentences that mention fees, costs, or similar terms.
Step 4: Identify Key Terms Related to Management Fees
From the extracted sections, run an analysis to detect key terms related to management fees, such as annual fee, administrative fee, etc.
This can be achieved through tokenization, Named Entity Recognition (NER), or custom dictionaries of financial terms.
Step 5: Extract Definitions of Key Terms
Once the key terms are identified, extract definitions or related explanations from the surrounding text.
This can involve proximity-based extraction, where definitions are typically found near the terms, or referencing a predefined glossary or external data source for definitions.
Tools & Libraries:
PDFMiner (for PDF text extraction)
NLTK or spaCy (for NLP tasks like keyword extraction and term recognition)
Custom Dictionaries or Financial Lexicons (for term matching)
Let me know if you need further details or if you would like me to elaborate on any specific part of this process!











import pandas as pd
import numpy as np

def export_evaluation_metrics_as_csv(actual, predicted, scores, file_type):
    def equalize_lengths(actual, predicted):
        # Convert to list if they are tuples or numpy arrays
        actual = list(actual) if isinstance(actual, (tuple, np.ndarray)) else actual
        predicted = list(predicted) if isinstance(predicted, (tuple, np.ndarray)) else predicted
        
        # Determine the lengths of the lists
        len_actual = len(actual)
        len_predicted = len(predicted)

        # Append None to the shorter list until both lists are the same length
        if len_actual > len_predicted:
            predicted.extend([None] * (len_actual - len_predicted))
        elif len_predicted > len_actual:
            actual.extend([None] * (len_predicted - len_actual))

        return actual, predicted

    # Ensure actual and predicted are lists of equal length
    actual, predicted = equalize_lengths(actual, predicted)

    # Convert unhashable types (like lists or dicts) to tuples
    def make_hashable(item):
        if isinstance(item, list):
            return tuple(make_hashable(sub_item) for sub_item in item)
        elif isinstance(item, dict):
            return tuple(sorted((k, make_hashable(v)) for k, v in item.items()))
        else:
            return item

    # Create sets of hashable items from actual and predicted
    actual_set = set(make_hashable(item) for item in actual)
    predicted_set = set(make_hashable(item) for item in predicted)

    # Combine sets to get all unique items
    all_items = list(actual_set.union(predicted_set))

    # Create a DataFrame
    df = pd.DataFrame(index=all_items, columns=["actual", "predicted"])

    # Populate the DataFrame
    df["actual"] = [item if item in actual_set else np.nan for item in all_items]
    df["predicted"] = [item if item in predicted_set else np.nan for item in all_items]

    # Reset index to get the items as columns instead of index
    df.reset_index(drop=True, inplace=True)

    # Ensure 'scores' is a dictionary and contains the necessary keys
    expected_keys = {"accuracy", "precision", "recall", "F1 score"}
    if not isinstance(scores, dict):
        raise ValueError("Expected 'scores' to be a dictionary with keys like 'accuracy', 'precision', 'recall', 'F1 score'.")
    missing_keys = expected_keys - scores.keys()
    if missing_keys:
        raise ValueError(f"The following keys are missing in the 'scores' dictionary: {missing_keys}")

    # Populate the DataFrame with the scores in the first row
    df.loc[0, "Accuracy"] = scores.get("accuracy", np.nan)
    df.loc[0, "Precision"] = scores.get("precision", np.nan)
    df.loc[0, "Recall"] = scores.get("recall", np.nan)
    df.loc[0, "F1 Score"] = scores.get("F1 score", np.nan)

    # Rearrange the DataFrame columns
    df = df[["actual", "predicted", "Accuracy", "Precision", "Recall", "F1 Score"]]

    # Clear non-header rows for some columns
    df.loc[1:, "Accuracy"] = np.nan
    df.loc[1:, "Precision"] = np.nan
    df.loc[1:, "Recall"] = np.nan
    df.loc[1:, "F1 Score"] = np.nan

    # Output filename
    output_filename = "evaluation_metrics.csv"

    # Save as Excel or CSV
    if file_type == "excel":
        output_filename = output_filename.replace(".csv", ".xlsx")
        df.to_excel(output_filename, index=False)
    else:
        df.to_csv(output_filename, index=False)

    print(f"{output_filename} Metrics file saved")

    return df










import pandas as pd
import numpy as np

def export_evaluation_metrics_as_csv(actual, predicted, scores, file_type):
    def equalize_lengths(actual, predicted):
        # Convert to list if they are tuples
        actual = list(actual) if isinstance(actual, (tuple, np.ndarray)) else actual
        predicted = list(predicted) if isinstance(predicted, (tuple, np.ndarray)) else predicted
        
        # Determine the lengths of the lists
        len_actual = len(actual)
        len_predicted = len(predicted)

        # Append None to the shorter list until both lists are the same length
        if len_actual > len_predicted:
            predicted.extend([None] * (len_actual - len_predicted))
        elif len_predicted > len_actual:
            actual.extend([None] * (len_predicted - len_actual))

        return actual, predicted

    # Ensure actual and predicted are lists of equal length
    actual, predicted = equalize_lengths(actual, predicted)

    # Convert unhashable types (like lists or dicts) to tuples
    def make_hashable(item):
        if isinstance(item, list):
            return tuple(make_hashable(sub_item) for sub_item in item)
        elif isinstance(item, dict):
            return tuple(sorted((k, make_hashable(v)) for k, v in item.items()))
        else:
            return item

    # Create sets of hashable items from actual and predicted
    actual_set = set(make_hashable(item) for item in actual)
    predicted_set = set(make_hashable(item) for item in predicted)

    # Combine sets to get all unique items
    all_items = list(actual_set.union(predicted_set))

    # Create a DataFrame
    df = pd.DataFrame(index=all_items, columns=["actual", "predicted"])

    # Populate the DataFrame
    df["actual"] = [item if item in actual_set else np.nan for item in all_items]
    df["predicted"] = [item if item in predicted_set else np.nan for item in all_items]

    # Reset index to get the items as columns instead of index
    df.reset_index(drop=True, inplace=True)

    # Ensure 'scores' is a dictionary and populate DataFrame columns
    if isinstance(scores, dict):
        df.loc[0, "Accuracy"] = scores.get("accuracy", np.nan)
        df.loc[0, "Precision"] = scores.get("precision", np.nan)
        df.loc[0, "Recall"] = scores.get("recall", np.nan)
        df.loc[0, "F1 Score"] = scores.get("F1 score", np.nan)
    else:
        raise ValueError("Expected 'scores' to be a dictionary with keys like 'accuracy', 'precision', etc.")

    # Rearrange the DataFrame columns
    df = df[["actual", "predicted", "Accuracy", "Precision", "Recall", "F1 Score"]]

    # Clear non-header rows for some columns
    df.loc[1:, "Accuracy"] = np.nan
    df.loc[1:, "Precision"] = np.nan
    df.loc[1:, "Recall"] = np.nan
    df.loc[1:, "F1 Score"] = np.nan

    # Output filename
    output_filename = "evaluation_metrics.csv"

    # Save as Excel or CSV
    if file_type == "excel":
        output_filename = output_filename.replace(".csv", ".xlsx")
        df.to_excel(output_filename, index=False)
    else:
        df.to_csv(output_filename, index=False)

    print(f"{output_filename} Metrics file saved")

    return df






import pandas as pd
import numpy as np

def export_evaluation_metrics_as_csv(actual, predicted, scores, file_type):
    def equalize_lengths(actual, predicted):
        # Convert to list if they are tuples
        if isinstance(actual, tuple):
            actual = list(actual)
        if isinstance(predicted, tuple):
            predicted = list(predicted)
        
        # Determine the lengths of the lists
        len_actual = len(actual)
        len_predicted = len(predicted)

        # Append None to the shorter list until both lists are the same length
        if len_actual > len_predicted:
            predicted.extend([None] * (len_actual - len_predicted))
        elif len_predicted > len_actual:
            actual.extend([None] * (len_predicted - len_actual))

        return actual, predicted

    # Ensure actual and predicted are lists of equal length
    actual, predicted = equalize_lengths(actual, predicted)

    # Convert unhashable types (like lists or dicts) to tuples
    def make_hashable(item):
        if isinstance(item, list):
            return tuple(make_hashable(sub_item) for sub_item in item)
        elif isinstance(item, dict):
            return tuple(sorted((k, make_hashable(v)) for k, v in item.items()))
        else:
            return item

    actual_set = set(make_hashable(item) for item in actual)
    predicted_set = set(make_hashable(item) for item in predicted)

    # Combine sets to get all unique items
    all_items = list(actual_set.union(predicted_set))

    # Create a DataFrame
    df = pd.DataFrame(index=all_items, columns=["actual", "predicted"])

    # Populate the DataFrame
    df["actual"] = [item if item in actual_set else np.nan for item in all_items]
    df["predicted"] = [item if item in predicted_set else np.nan for item in all_items]

    # Reset index to get the items as columns instead of index
    df.reset_index(drop=True, inplace=True)

    # Filter the dataframe to only include rows where 'actual' is not NaN
    df_eval = df.dropna(subset=["actual"])
    predicted = df_eval["predicted"].tolist()
    actual = df_eval["actual"].tolist()

    # Ensure 'scores' is a dictionary and populate DataFrame columns
    if isinstance(scores, dict):
        df["Accuracy"] = scores.get("accuracy", np.nan)
        df["Precision"] = scores.get("precision", np.nan)
        df["Recall"] = scores.get("recall", np.nan)
        df["F1 Score"] = scores.get("F1 score", np.nan)
    else:
        raise ValueError("Expected 'scores' to be a dictionary with keys like 'accuracy', 'precision', etc.")

    # Rearrange the DataFrame columns
    df = df[["actual", "predicted", "Accuracy", "Precision", "Recall", "F1 Score"]]

    # Clear non-header rows for some columns
    df.loc[1:, "input file name"] = np.nan
    df.loc[1:, "Accuracy"] = np.nan
    df.loc[1:, "Precision"] = np.nan
    df.loc[1:, "Recall"] = np.nan
    df.loc[1:, "F1 Score"] = np.nan

    # Output filename
    output_filename = "evaluation_metrics.csv"

    # Save as Excel or CSV
    if file_type == "excel":
        output_filename = output_filename.replace(".csv", ".xlsx")
        df.to_excel(output_filename, index=False)
    else:
        df.to_csv(output_filename, index=False)

    print(f"{output_filename} Metrics file saved")

    return df






import pandas as pd
import numpy as np

def export_evaluation_metrics_as_csv(actual, predicted, scores, file_type):
    def equalize_lengths(actual, predicted):
        # Convert to list if they are tuples
        if isinstance(actual, tuple):
            actual = list(actual)
        if isinstance(predicted, tuple):
            predicted = list(predicted)
        
        # Determine the lengths of the lists
        len_actual = len(actual)
        len_predicted = len(predicted)

        # Append None to the shorter list until both lists are the same length
        if len_actual > len_predicted:
            predicted.extend([None] * (len_actual - len_predicted))
        elif len_predicted > len_actual:
            actual.extend([None] * (len_predicted - len_actual))

        return actual, predicted

    # Ensure actual and predicted are lists of equal length
    actual, predicted = equalize_lengths(actual, predicted)

    # Convert unhashable types (like lists or dicts) to tuples
    def make_hashable(item):
        if isinstance(item, list):
            return tuple(item)
        elif isinstance(item, dict):
            return tuple(sorted(item.items()))
        else:
            return item

    actual_set = set(make_hashable(item) for item in actual)
    predicted_set = set(make_hashable(item) for item in predicted)

    # Combine sets to get all unique items
    all_items = list(actual_set.union(predicted_set))

    # Create a DataFrame
    df = pd.DataFrame(index=all_items, columns=["actual", "predicted"])

    # Populate the DataFrame
    df["actual"] = [item if item in actual_set else np.nan for item in all_items]
    df["predicted"] = [item if item in predicted_set else np.nan for item in all_items]

    # Reset index to get the items as columns instead of index
    df.reset_index(drop=True, inplace=True)

    # Filter the dataframe to only include rows where 'actual' is not NaN
    df_eval = df.dropna(subset=["actual"])
    predicted = df_eval["predicted"].tolist()
    actual = df_eval["actual"].tolist()

    # Ensure 'scores' is a dictionary and populate DataFrame columns
    if isinstance(scores, dict):
        df["Accuracy"] = scores.get("accuracy", np.nan)
        df["Precision"] = scores.get("precision", np.nan)
        df["Recall"] = scores.get("recall", np.nan)
        df["F1 Score"] = scores.get("F1 score", np.nan)
    else:
        raise ValueError("Expected 'scores' to be a dictionary with keys like 'accuracy', 'precision', etc.")

    # Rearrange the DataFrame columns
    df = df[["actual", "predicted", "Accuracy", "Precision", "Recall", "F1 Score"]]

    # Clear non-header rows for some columns
    df.loc[1:, "input file name"] = np.nan
    df.loc[1:, "Accuracy"] = np.nan
    df.loc[1:, "Precision"] = np.nan
    df.loc[1:, "Recall"] = np.nan
    df.loc[1:, "F1 Score"] = np.nan

    # Output filename
    output_filename = "evaluation_metrics.csv"

    # Save as Excel or CSV
    if file_type == "excel":
        output_filename = output_filename.replace(".csv", ".xlsx")
        df.to_excel(output_filename, index=False)
    else:
        df.to_csv(output_filename, index=False)

    print(f"{output_filename} Metrics file saved")

    return df






import pandas as pd
import numpy as np

def export_evaluation_metrics_as_csv(actual, predicted, scores, file_type):
    def equalize_lengths(actual, predicted):
        # Convert to list if they are tuples
        if isinstance(actual, tuple):
            actual = list(actual)
        if isinstance(predicted, tuple):
            predicted = list(predicted)
        
        # Determine the lengths of the lists
        len_actual = len(actual)
        len_predicted = len(predicted)

        # Append None to the shorter list until both lists are the same length
        if len_actual > len_predicted:
            predicted.extend([None] * (len_actual - len_predicted))
        elif len_predicted > len_actual:
            actual.extend([None] * (len_predicted - len_actual))

        return actual, predicted

    # Ensure actual and predicted are lists of equal length
    actual, predicted = equalize_lengths(actual, predicted)

    # If actual or predicted contain dictionaries, convert them to tuples
    actual_set = set(tuple(sorted(item.items())) if isinstance(item, dict) else item for item in actual)
    predicted_set = set(tuple(sorted(item.items())) if isinstance(item, dict) else item for item in predicted)

    # Combine sets to get all unique items
    all_items = list(actual_set.union(predicted_set))

    # Create a DataFrame
    df = pd.DataFrame(index=all_items, columns=["actual", "predicted"])

    # Populate the DataFrame
    df["actual"] = [item if item in actual_set else np.nan for item in all_items]
    df["predicted"] = [item if item in predicted_set else np.nan for item in all_items]

    # Reset index to get the items as columns instead of index
    df.reset_index(drop=True, inplace=True)

    # Filter the dataframe to only include rows where 'actual' is not NaN
    df_eval = df.dropna(subset=["actual"])
    predicted = df_eval["predicted"].tolist()
    actual = df_eval["actual"].tolist()

    # Ensure 'scores' is a dictionary and populate DataFrame columns
    if isinstance(scores, dict):
        df["Accuracy"] = scores.get("accuracy", np.nan)
        df["Precision"] = scores.get("precision", np.nan)
        df["Recall"] = scores.get("recall", np.nan)
        df["F1 Score"] = scores.get("F1 score", np.nan)
    else:
        raise ValueError("Expected 'scores' to be a dictionary with keys like 'accuracy', 'precision', etc.")

    # Rearrange the DataFrame columns
    df = df[["actual", "predicted", "Accuracy", "Precision", "Recall", "F1 Score"]]

    # Clear non-header rows for some columns
    df.loc[1:, "input file name"] = np.nan
    df.loc[1:, "Accuracy"] = np.nan
    df.loc[1:, "Precision"] = np.nan
    df.loc[1:, "Recall"] = np.nan
    df.loc[1:, "F1 Score"] = np.nan

    # Output filename
    output_filename = "evaluation_metrics.csv"

    # Save as Excel or CSV
    if file_type == "excel":
        output_filename = output_filename.replace(".csv", ".xlsx")
        df.to_excel(output_filename, index=False)
    else:
        df.to_csv(output_filename, index=False)

    print(f"{output_filename} Metrics file saved")

    return df






import pandas as pd
import numpy as np

def export_evaluation_metrics_as_csv(actual, predicted, scores, file_type):
    def equalize_lengths(actual, predicted):
        # Convert to list if they are tuples
        if isinstance(actual, tuple):
            actual = list(actual)
        if isinstance(predicted, tuple):
            predicted = list(predicted)
        
        # Determine the lengths of the lists
        len_actual = len(actual)
        len_predicted = len(predicted)

        # Append None to the shorter list until both lists are the same length
        if len_actual > len_predicted:
            predicted.extend([None] * (len_actual - len_predicted))
        elif len_predicted > len_actual:
            actual.extend([None] * (len_predicted - len_actual))

        return actual, predicted

    # Ensure actual and predicted are lists of equal length
    actual, predicted = equalize_lengths(actual, predicted)

    # Create sets for comparison
    actual_set = set(actual)
    predicted_set = set(predicted)

    # Combine sets to get all unique items
    all_items = list(actual_set.union(predicted_set))

    # Create a DataFrame
    df = pd.DataFrame(index=all_items, columns=["actual", "predicted"])

    # Populate the DataFrame
    df["actual"] = [item if item in actual_set else np.nan for item in all_items]
    df["predicted"] = [item if item in predicted_set else np.nan for item in all_items]

    # Reset index to get the items as columns instead of index
    df.reset_index(drop=True, inplace=True)

    # Filter the dataframe to only include rows where 'actual' is not NaN
    df_eval = df.dropna(subset=["actual"])
    predicted = df_eval["predicted"].tolist()
    actual = df_eval["actual"].tolist()

    # Debug statement to check the type of scores
    print(f"scores type: {type(scores)}, scores content: {scores}")

    # Ensure 'scores' is a dictionary and populate DataFrame columns
    if isinstance(scores, dict):
        df["Accuracy"] = scores.get("accuracy", np.nan)
        df["Precision"] = scores.get("precision", np.nan)
        df["Recall"] = scores.get("recall", np.nan)
        df["F1 Score"] = scores.get("F1 score", np.nan)
    else:
        raise ValueError("Expected 'scores' to be a dictionary with keys like 'accuracy', 'precision', etc.")

    # Rearrange the DataFrame columns
    df = df[["actual", "predicted", "Accuracy", "Precision", "Recall", "F1 Score"]]

    # Clear non-header rows for some columns
    df.loc[1:, "input file name"] = np.nan
    df.loc[1:, "Accuracy"] = np.nan
    df.loc[1:, "Precision"] = np.nan
    df.loc[1:, "Recall"] = np.nan
    df.loc[1:, "F1 Score"] = np.nan

    # Output filename
    output_filename = "evaluation_metrics.csv"

    # Save as Excel or CSV
    if file_type == "excel":
        output_filename = output_filename.replace(".csv", ".xlsx")
        df.to_excel(output_filename, index=False)
    else:
        df.to_csv(output_filename, index=False)

    print(f"{output_filename} Metrics file saved")

    return df








import pandas as pd
import numpy as np

def export_evaluation_metrics_as_csv(actual, predicted, scores, file_type):

    def equalize_lengths(actual, predicted):
        len_actual = len(actual)
        len_predicted = len(predicted)

        if len_actual > len_predicted:
            predicted.extend([None] * (len_actual - len_predicted))
        elif len_predicted > len_actual:
            actual.extend([None] * (len_predicted - len_actual))

        return actual, predicted

    actual, predicted = equalize_lengths(actual, predicted)

    actual_set = set(actual)
    predicted_set = set(predicted)

    all_items = list(actual_set.union(predicted_set))

    df = pd.DataFrame(index=all_items, columns=["actual", "predicted"])

    df["actual"] = [item if item in actual_set else np.nan for item in all_items]
    df["predicted"] = [item if item in predicted_set else np.nan for item in all_items]

    df.reset_index(drop=True, inplace=True)

    df_eval = df.dropna(subset=["actual"])
    predicted = df_eval["predicted"].tolist()
    actual = df_eval["actual"].tolist()

    all_terms = list(set(predicted + actual))

    # Debug statement to check the type of scores
    print(f"scores type: {type(scores)}, scores content: {scores}")

    if isinstance(scores, dict):
        df["Accuracy"] = scores.get("accuracy", np.nan)
        df["Precision"] = scores.get("precision", np.nan)
        df["Recall"] = scores.get("recall", np.nan)
        df["F1 Score"] = scores.get("F1 score", np.nan)
    else:
        raise ValueError("Expected 'scores' to be a dictionary with keys like 'accuracy', 'precision', etc.")

    df = df[["actual", "predicted", "Accuracy", "Precision", "Recall", "F1 Score"]]

    df.loc[1:, "input file name"] = np.nan
    df.loc[1:, "Accuracy"] = np.nan
    df.loc[1:, "Precision"] = np.nan
    df.loc[1:, "Recall"] = np.nan
    df.loc[1:, "F1 Score"] = np.nan

    output_filename = "evaluation_metrics.csv"  # Modify this as needed

    if file_type == "excel":
        output_filename = output_filename.replace(".csv", ".xlsx")
        df.to_excel(output_filename, index=False)
    else:
        df.to_csv(output_filename, index=False)

    print(f"{output_filename} Metrics file saved")

    return df





import pandas as pd
import numpy as np

def export_evaluation_metrics_as_csv(actual, predicted, scores, file_type):
    
    def equalize_lengths(actual, predicted):
        # Convert to lists if they are tuples
        if isinstance(actual, tuple):
            actual = list(actual)
        if isinstance(predicted, tuple):
            predicted = list(predicted)
        
        # Determine the lengths of the lists
        len_actual = len(actual)
        len_predicted = len(predicted)

        # Append None to the shorter list until both lists are the same length
        if len_actual > len_predicted:
            predicted.extend([None] * (len_actual - len_predicted))
        elif len_predicted > len_actual:
            actual.extend([None] * (len_predicted - len_actual))

        return actual, predicted

    actual, predicted = equalize_lengths(actual, predicted)

    # Convert lists of dictionaries to lists of strings (or tuples) to make them hashable
    actual_set = set([str(item) for item in actual])
    predicted_set = set([str(item) for item in predicted])

    # Combine sets to get all unique items
    all_items = list(actual_set.union(predicted_set))

    # Create a DataFrame
    df = pd.DataFrame(index=all_items, columns=["actual", "predicted"])

    # Populate the DataFrame
    df["actual"] = [item if item in actual_set else np.nan for item in all_items]
    df["predicted"] = [item if item in predicted_set else np.nan for item in all_items]

    # Reset index to get the items as columns instead of index
    df.reset_index(drop=True, inplace=True)

    df_eval = df.dropna(subset=["actual"])
    predicted = df_eval["predicted"].tolist()
    actual = df_eval["actual"].tolist()

    all_terms = list(set(predicted + actual))

    df["Accuracy"] = scores["accuracy"]
    df["Precision"] = scores["precision"]
    df["Recall"] = scores["recall"]
    df["F1 Score"] = scores["F1 score"]

    df = df[["actual", "predicted", "Accuracy", "Precision", "Recall", "F1 Score"]]

    df.loc[1:, "input file name"] = np.nan
    df.loc[1:, "Accuracy"] = np.nan
    df.loc[1:, "Precision"] = np.nan
    df.loc[1:, "Recall"] = np.nan
    df.loc[1:, "F1 Score"] = np.nan

    output_filename = "evaluation_metrics.csv"  # Modify this as needed

    if file_type == "excel":
        output_filename = output_filename.replace(".csv", ".xlsx")
        df.to_excel(output_filename, index=False)
    else:
        df.to_csv(output_filename, index=False)

    print(f"{output_filename} Metrics file saved")

    return df








import pandas as pd
import numpy as np

def export_evaluation_metrics_as_csv(actual, predicted, scores, file_type):
    
    def equalize_lengths(actual, predicted):
        # Convert to lists if they are tuples
        if isinstance(actual, tuple):
            actual = list(actual)
        if isinstance(predicted, tuple):
            predicted = list(predicted)
        
        # Determine the lengths of the lists
        len_actual = len(actual)
        len_predicted = len(predicted)

        # Append None to the shorter list until both lists are the same length
        if len_actual > len_predicted:
            predicted.extend([None] * (len_actual - len_predicted))
        elif len_predicted > len_actual:
            actual.extend([None] * (len_predicted - len_actual))

        return actual, predicted

    actual, predicted = equalize_lengths(actual, predicted)

    actual_set = set(actual)
    predicted_set = set(predicted)

    # Combine sets to get all unique items
    all_items = list(actual_set.union(predicted_set))

    # Create a DataFrame
    df = pd.DataFrame(index=all_items, columns=["actual", "predicted"])

    # Populate the DataFrame
    df["actual"] = [item if item in actual_set else np.nan for item in all_items]
    df["predicted"] = [item if item in predicted_set else np.nan for item in all_items]

    # Reset index to get the items as columns instead of index
    df.reset_index(drop=True, inplace=True)

    df_eval = df.dropna(subset=["actual"])
    predicted = df_eval["predicted"].tolist()
    actual = df_eval["actual"].tolist()

    all_terms = list(set(predicted + actual))

    df["Accuracy"] = scores["accuracy"]
    df["Precision"] = scores["precision"]
    df["Recall"] = scores["recall"]
    df["F1 Score"] = scores["F1 score"]

    df = df[["actual", "predicted", "Accuracy", "Precision", "Recall", "F1 Score"]]

    df.loc[1:, "input file name"] = np.nan
    df.loc[1:, "Accuracy"] = np.nan
    df.loc[1:, "Precision"] = np.nan
    df.loc[1:, "Recall"] = np.nan
    df.loc[1:, "F1 Score"] = np.nan

    output_filename = "evaluation_metrics.csv"  # Modify this as needed

    if file_type == "excel":
        output_filename = output_filename.replace(".csv", ".xlsx")
        df.to_excel(output_filename, index=False)
    else:
        df.to_csv(output_filename, index=False)

    print(f"{output_filename} Metrics file saved")

    return df








import logging
import os
from azure.identity import ManagedIdentityCredential
from azure.storage.blob import BlobServiceClient

from genai.processing_daemon.methods.adi_processing import adiProcessing
from common_svc.logger.log_util import configure_loggers

# Configure loggers
configure_loggers()
logger = logging.getLogger(__name__)

class DocumentParsing:
    def __init__(self):
        pass

    def pdfMiner(self):
        raise Exception("The method pdfMiner is not available")

    def connect_to_azure_blob(self, input_document_path):
        """
        Connect to Azure Blob Storage using Managed Identity.
        """
        try:
            connection = input_document_path['params']['connection_string']
            mi_client_id = connection["mi_client_id"]

            credential = ManagedIdentityCredential(client_id=mi_client_id)

            # Create a BlobServiceClient using the account URL and the Managed Identity Credential
            blob_service_client = BlobServiceClient(
                account_url=connection["account_url"],
                credential=credential
            )

            # Create a ContainerClient for the specified container
            container_client = blob_service_client.get_container_client(connection["container_name"])

            logger.info("Connected to Azure Blob Container")
            return container_client

        except Exception as e:
            logger.error(f"An error occurred: {e}")
            return None

    def download_pdf_from_blob(self, input_document_path, tmpdir):
        """
        Download a PDF file from Azure Blob Storage and save it to a specified directory.
        Return the file path including the file name.
        """
        container_client = self.connect_to_azure_blob(input_document_path)
        if not container_client:
            return None

        params = input_document_path["params"]
        absolute_path = params["absolute_path"]
        blob_name = os.path.basename(absolute_path)

        # Define the full path for the downloaded file
        pdf_file_path = os.path.join(tmpdir, blob_name)

        # Get the BlobClient for the specified blob
        blob_client = container_client.get_blob_client(blob_name)

        # Download the blob content and write it to the file
        try:
            with open(pdf_file_path, 'wb') as pdf_file:
                download_stream = blob_client.download_blob()
                pdf_file.write(download_stream.readall())
        except Exception as e:
            logger.error(f"Failed to download blob {blob_name} from Azure Blob Storage: {e}")
            return None

        return pdf_file_path

    def ADI(self, processing_config, input_document_path):
        """
        Run ADI processing on the downloaded PDF.
        """
        model_name = processing_config["model"]
        endpoint = processing_config["endpoint"]
        key = processing_config["key"]

        adi_object = adiProcessing()

        output_dir = os.path.join("tmp", "output")
        os.makedirs(output_dir, exist_ok=True)

        input_document_path = self.download_pdf_from_blob(input_document_path, output_dir)
        if not input_document_path:
            return None

        try:
            merged_content = adi_object.run_prescribed_extracts_azure(
                input_document_path, output_dir, model_name, endpoint, key
            )
            return merged_content
        except Exception as e:
            logger.exception("Exception Occurred while extracting ADI results: %s", e)
            return None

# Testing
processingConfig = {
    "processing_engine": "ADI",
    "model": "prebuilt-layout",
    "endpoint": "https://npeefrdns.cognitiveservices.azure.com/",
    "key": "dc7c0c7c3a9a4371b7dc983ac7b618b7"
}

input_document_path = {
    "storage_type": "blob",
    "container_name": "sample",
    "params": {
        "connection_string": {
            "account_url": "https://eventhubstorage919.blob.core.windows.net",
            "container_name": "sample",
            "mi_client_id": "5da5a4c-edb2-4f9f-8ad8-d11f0214f557"
        },
        "absolute_path": "PVT Markets/data/LPA/1719852c-91ac-498a-b4ad-508cdab7cbad/1885_private_opportunities_fund_1p_-_2nd_er_lpa_march_16_20211.pdf"
    }
}

docparser = DocumentParsing()
merged_content = docparser.ADI(processingConfig, input_document_path)
print(merged_content)








import logging
import os
from azure.identity import ManagedIdentityCredential
from azure.storage.blob import BlobServiceClient

from genai.processing_daemon.methods.adi_processing import adiProcessing
from common_svc.logger.log_util import configure_loggers

# Configure loggers
configure_loggers()
logger = logging.getLogger(__name__)

class DocumentParsing:
    def __init__(self):
        pass

    def pdfMiner(self):
        raise Exception("The method pdfMiner is not available.")

    def connect_to_azure_blob(self, input_document_path):
        # Connect to Azure Blob Storage using Managed Identity.
        connection_string = input_document_path["params"]["connection_string"]

        try:
            credential = ManagedIdentityCredential(client_id=connection_string["mi_client_id"])

            # Create a BlobServiceClient using the account URL and the Managed Identity Credential
            blob_service_client = BlobServiceClient(
                account_url=connection_string["account_url"],
                credential=credential
            )

            # Create a ContainerClient for the specified container
            container_client = blob_service_client.get_container_client(connection_string["container_name"])

            logger.info("Connected to Azure Blob Container")
            return container_client

        except Exception as e:
            logger.error(f"An error occurred: {e}")
            return None

    def download_pdf_from_blob(self, input_document_path, tmpdir):
        """
        Download a PDF file from Azure Blob Storage and save it to a specified directory.
        Return the file path including the file name.
        """
        container_client = self.connect_to_azure_blob(input_document_path)
        if not container_client:
            return None

        params = input_document_path["params"]
        storage_location = params["storage_location"]
        blob_name = os.path.basename(storage_location)

        # Define the full path for the downloaded file
        pdf_file_path = os.path.join(tmpdir, blob_name)

        # Get the BlobClient for the specified blob
        blob_client = container_client.get_blob_client(blob_name)

        # Download the blob content and write it to the file
        with open(pdf_file_path, 'wb') as pdf_file:
            download_stream = blob_client.download_blob()
            pdf_file.write(download_stream.readall())

        return pdf_file_path

    def ADI(self, processing_config, input_document_path):
        model_name = processing_config["model"]
        endpoint = processing_config["endpoint"]
        key = processing_config["key"]

        adi_object = adiProcessing()

        output_dir = os.path.join("tmp", "output")
        os.makedirs(output_dir, exist_ok=True)

        # Download PDF from Azure Blob
        input_document_path = self.download_pdf_from_blob(input_document_path, output_dir)
        if not input_document_path:
            return None

        try:
            # Example method calls assuming run_prescribed_extracts_azure exists
            page_dim_json_file_path, _doc_layout_json_file_path, doc_layout = adi_object.run_prescribed_extracts_azure(
                input_document_path, output_dir, model_name, endpoint, key)

            merged_content = adi_object.run_prescribed_extracts_azure(
                input_document_path, output_dir, model_name, endpoint, key)

            return merged_content

        except Exception as e:
            logger.exception("Exception Occurred while extracting ADI results: %s", e)
            return None

# Testing
processing_config = {
    "processing_engine": "ADI",
    "model": "Layout",
    "endpoint": "https://npeefrdns.cognitiveservices.azure.com/",
    "key": "dc7c"
}

input_document_path = {
    "storage_type": "blob",
    "container_name": "sample",
    "params": {
        "connection_string": {
            "account_url": "https://<your-account-name>.blob.core.windows.net",
            "container_name": "sample",
            "mi_client_id": "<your-managed-identity-client-id>"
        },
        "storage_location": "PVT Markets/data/LPA/1719852c-91ac-498a-b4ad-508cdab7cbad/1885_private_opportunities_fund_ip_-_2nd_ar_lpa_march_16_2021.pdf"
    }
}

docparser = DocumentParsing()
merged_content = docparser.ADI(processing_config, input_document_path)

print(merged_content)







import os
import json
import re

def get_filtered_paras(search_string, merged_para, quotation_marks_paragraphs, count):
    """
    Filters paragraphs based on the search string and updates the count.
    :param search_string: The string to search for in the paragraphs.
    :param merged_para: The paragraph to search within.
    :param quotation_marks_paragraphs: The list of paragraphs that have already been filtered.
    :param count: The current count of filtered paragraphs.
    :return: Updated list of filtered paragraphs and the count.
    """
    pattern = rf'[^"]*{re.escape(search_string)}[^"]*'
    if re.search(pattern, merged_para):
        if merged_para not in quotation_marks_paragraphs:
            filtered_para = str(count) + " " + merged_para
            quotation_marks_paragraphs.append(filtered_para)
            count += 1
    return quotation_marks_paragraphs, count

def extract_definitions(quotation_marks_paragraphs, list_indexed_keyterms):
    """
    Simulate the extraction of definitions based on indexed key terms.
    """
    # This is a placeholder for the actual definition extraction logic.
    return json.dumps({"definitions": quotation_marks_paragraphs})

def load_json(file_path):
    """
    Load JSON data from a file.
    :param file_path: Path to the JSON file.
    :return: Parsed JSON data.
    """
    with open(file_path, 'r', encoding='utf-8') as file:
        return json.load(file)

def run_keyterms_definitions_extract(pdf_path, logical_chunks_file, extracted_keyterms_json_path, output_dir):
    """
    Process a PDF and associated logical chunks file to extract key terms and their definitions.
    :param pdf_path: Path to the input PDF.
    :param logical_chunks_file: Path to the JSON file containing logical chunks.
    :param extracted_keyterms_json_path: Path to the JSON file containing key terms.
    :param output_dir: Directory where the output JSON will be saved.
    :return: JSON output and the path to the saved JSON file.
    """
    # Check if the PDF name matches the logical chunks file name
    pdf_base_name = os.path.splitext(os.path.basename(pdf_path))[0]
    logical_chunks_base_name = os.path.splitext(os.path.basename(logical_chunks_file))[0].replace("logicalchunks", "").strip()

    if pdf_base_name != logical_chunks_base_name:
        raise ValueError(f"Mismatch: PDF base name '{pdf_base_name}' does not match logical chunks base name '{logical_chunks_base_name}'.")

    extracted_definition_json_file_name = pdf_base_name + "_generated_definitions.json"
    extracted_definition_json_path = os.path.join(output_dir, extracted_definition_json_file_name)

    # Load key terms
    with open(extracted_keyterms_json_path, "r") as json_file:
        data = json.load(json_file)

    keyterm_index = 0
    list_indexed_keyterms = []

    search_strings = data["keyTerms"]
    for search_string in search_strings:
        indexed_keyterm = f"{keyterm_index} {search_string}"
        keyterm_index += 1
        list_indexed_keyterms.append(indexed_keyterm)

    # Load logical chunks
    file_data = load_json(logical_chunks_file)

    count = 0
    quotation_marks_paragraphs = []

    for items in file_data["logicalChunks"]:
        for search_string in search_strings:
            # For chunks that need merging of content
            if len(items) >= 2:
                merged_para = ""
                for i in range(len(items)):
                    para = items[i]["content"]
                    merged_para += " " + para
                quotation_marks_paragraphs, count = get_filtered_paras(search_string, merged_para.strip(), quotation_marks_paragraphs, count)
            # For chunks having only one content
            elif len(items) == 1:
                for contents in items:
                    content = contents["content"]
                    quotation_marks_paragraphs, count = get_filtered_paras(search_string, content, quotation_marks_paragraphs, count)

    # Extract definitions based on the filtered paragraphs
    output = extract_definitions(quotation_marks_paragraphs, list_indexed_keyterms)
    json_output = json.loads(output)

    # Ensure output directory exists
    os.makedirs(output_dir, exist_ok=True)

    # Save the extracted definitions to a JSON file
    with open(extracted_definition_json_path, "w", encoding="utf-8") as ff:
        json.dump(json_output, ff, ensure_ascii=False, indent=4)

    print(f"Successfully dumped the extracted definitions JSON for the PDF: {pdf_path}")

    return json_output, extracted_definition_json_path

# Testing the function
pdf_path = r"H:\management_fee_extraction\pipeline_test\LEGAL-#148074-v3-1824_Private_Equity_Fund_LP_(TJU)_-_AR_LPA.PDF"
logical_chunks_file = r"H:\management_fee_extraction\extracts_output\output5\LEGAL-#148074-v3-1824_Private_Equity_Fund_LP_(TJU)_-_AR_LPA_logical_chunks.json"
extracted_keyterms_json_path = r"H:\management_fee_extraction\extracts_output\output5\LEGAL-#148074-v3-1824_Private_Equity_Fund_LP_(TJU)_-_AR_LPA_generated_keyterms.json"
output_dir = r"H://management_fee_extraction//extracts_output//output7//"

json_output, extracted_definition_json_path = run_keyterms_definitions_extract(pdf_path, logical_chunks_file, extracted_keyterms_json_path, output_dir)

print(json_output)
print(extracted_definition_json_path)







import os
import json
import re

def load_json(file_path):
    """Utility function to load JSON data from a file."""
    with open(file_path, "r", encoding="utf-8") as file:
        return json.load(file)

def get_filtered_paras(search_string, merged_para, quotation_marks_paragraphs, count):
    """
    Filters paragraphs based on the search string and updates the count.
    :param search_string: The string to search for in the paragraphs.
    :param merged_para: The paragraph to search within.
    :param quotation_marks_paragraphs: The list of paragraphs that have already been filtered.
    :param count: The current count of filtered paragraphs.
    :return: Updated list of filtered paragraphs and the count.
    """
    pattern = rf'[^"]*{re.escape(search_string)}[^"]*'
    if re.search(pattern, merged_para):
        indexing_para = merged_para
        if indexing_para not in quotation_marks_paragraphs:
            filtered_para = str(count) + " " + merged_para
            quotation_marks_paragraphs.append(filtered_para)
            count += 1
    return quotation_marks_paragraphs, count

def extract_definitions(quotation_marks_paragraphs, list_indexed_keyterms):
    """
    This is a placeholder for the actual implementation of extracting definitions.
    It would process the filtered paragraphs and indexed keyterms to produce output.
    """
    # Assuming this function returns a JSON-serializable object as output.
    return {"definitions": [{"keyterm": keyterm, "paragraph": para} for keyterm, para in zip(list_indexed_keyterms, quotation_marks_paragraphs)]}

def run_keyterms_definitions_extract(pdf_path, logical_chunks_file, extracted_keyterms_json_path, output_dir):
    extracted_definition_json_file_name = os.path.basename(pdf_path)
    extracted_definition_json_file_name = extracted_definition_json_file_name.replace(".pdf", "_generated_definitions.json").replace(".PDF", "_generated_definitions.json")
    extracted_definition_json_path = os.path.join(output_dir, extracted_definition_json_file_name)

    # Load key terms from the JSON file
    data = load_json(extracted_keyterms_json_path)
    search_strings = data["keyTerms"]

    # Index key terms
    list_indexed_keyterms = [str(i) + " " + search_string for i, search_string in enumerate(search_strings)]

    # Load logical chunks
    file_data = load_json(logical_chunks_file)
    
    count = 0
    quotation_marks_paragraphs = []

    for items in file_data["logicalChunks"]:
        for search_string in search_strings:
            if len(items) >= 2:
                merged_para = ""
                for item in items:
                    merged_para += item["content"] + " "
                quotation_marks_paragraphs, count = get_filtered_paras(search_string, merged_para, quotation_marks_paragraphs, count)
            elif len(items) == 1:
                for item in items:
                    content = item["content"]
                    quotation_marks_paragraphs, count = get_filtered_paras(search_string, content, quotation_marks_paragraphs, count)

    # Extract definitions
    output = extract_definitions(quotation_marks_paragraphs, list_indexed_keyterms)

    # Save the extracted definitions to a JSON file
    with open(extracted_definition_json_path, "w", encoding="utf-8") as ff:
        json.dump(output, ff, ensure_ascii=False, indent=4)

    return output, extracted_definition_json_path

# Testing
pdf_path = r"H:\management_fee_extraction\pipeline_test\LEGAL-#148074-v3-1824_Private_Equity_Fund_LP_(TJU)_-_AR_LPA.PDF"
logical_chunks_file = r"H:\management_fee_extraction\extracts_output\output5\LEGAL-#148074-v3-1824_Private_Equity_Fund_LP_(TJU)_-_AR_LPA_logical_chunks.json"
extracted_keyterms_json_path = r"H:\management_fee_extraction\extracts_output\output5\LEGAL-#148074-v3-1824_Private_Equity_Fund_LP_(TJU)_-_AR_LPA_generated_keyterms.json"
output_dir = r"H:\management_fee_extraction\extracts_output\output7"

json_output, extracted_definition_json_path = run_keyterms_definitions_extract(pdf_path, logical_chunks_file, extracted_keyterms_json_path, output_dir)

print(json_output)
print(extracted_definition_json_path)
import re

def get_filtered_paras(search_string, merged_para, count, quotation_marks_paragraphs):
    """
    Filters paragraphs based on the search string and updates the count.
    :param search_string: The string to search for in the paragraphs.
    :param merged_para: The paragraph to search within.
    :param count: The current count of filtered paragraphs.
    :param quotation_marks_paragraphs: The list of paragraphs that have already been filtered.
    :return: Updated list of filtered paragraphs and the count.
    """
    # Correct the pattern for regex search
    pattern = rf'[^"]*{re.escape(search_string)}[^"]*'

    # Check if the pattern is found in the merged paragraph
    if re.search(pattern, merged_para):
        indexing_para = merged_para

        # Ensure the paragraph is not already in the list
        if indexing_para not in quotation_marks_paragraphs:
            # Correct string concatenation and append the paragraph
            filtered_para = str(count) + " " + merged_para
            print(f"filtered_para: {filtered_para}")

            quotation_marks_paragraphs.append(filtered_para)
            count += 1

    return quotation_marks_paragraphs, count

# Example usage:
search_string = "Management Fee"
merged_para = "This paragraph talks about Management Fee and other details."
count = 1
quotation_marks_paragraphs = []

result, updated_count = get_filtered_paras(search_string, merged_para, count, quotation_marks_paragraphs)

print("Filtered Paragraphs:", result)
print("Updated Count:", updated_count)





import re
import os
import json

class KeywordFilterMethod:

    def extract(self, data) -> list[dict]:
        """
        Extract the data based on keywords
        :param data: Input data as a dictionary
        :return: List of dictionaries containing extracted data
        """
        terms = [
            "Management Fee",
            "Management +Fee",
            "Servicing Fee",
            "Servicing +Fee",
            "Investment Advisory Fee",
            "Investment +Advisory +Fee",
            "Compensation",
            "Remuneration",
            "Expenses",
            "AIFM Fee",
            "AIFM +Fee",
        ]
        patterns = self.compile_search_patterns(terms)
        data_with_terms = self.extract_data_with_terms(data, patterns)
        return data_with_terms

    def compile_search_patterns(self, terms):
        """
        Compile the search pattern using the terms provided
        :param terms: List of search terms
        :return: List of compiled regex patterns
        """
        patterns = [re.compile(re.escape(term)) for term in terms]
        return patterns

    def search_terms_in_content(self, node_content, patterns):
        """
        Search the terms in content provided
        :param node_content: Content to search within
        :param patterns: List of compiled regex patterns
        :return: True if any pattern matches, otherwise False
        """
        for pattern in patterns:
            if pattern.search(node_content):
                return True
        return False

    def extract_data_with_terms(self, data, patterns):
        """
        Extract the data based on keywords
        :param data: Input data as a dictionary
        :param patterns: List of compiled regex patterns
        :return: List of dictionaries containing extracted data
        """
        extracted_data = []
        for item in data['logicalchunks']:
            for node in item:
                if self.search_terms_in_content(node['content'], patterns):
                    extracted_data.append(item)
                    break
        return extracted_data

    def merge_content(self, json_data):
        """
        Merge content from the provided JSON data
        :param json_data: Input JSON data as a dictionary
        :return: Dictionary with merged content
        """
        data = json.loads(json.dumps(json_data))
        combined_strings = []

        for item in data['extractsUsingPrescribedLanguage']:
            combined_string = ' '.join(item['content'] for item in item)
            combined_strings.append(combined_string)

        result = {'extractsUsingPrescribedLanguage': combined_strings}
        return result

def dump_json_file(json_file_path, json_data):
    """
    Dump the JSON data to a file
    :param json_file_path: Path to the JSON file
    :param json_data: Data to write to the file
    """
    try:
        with open(json_file_path, "w") as json_file:
            json.dump(json_data, json_file)
    except Exception as e:
        print(f"Error dumping JSON file: {e}")

# File paths
data_file_path = "H:/management_fee_extraction/extracts_output/output5/LEGAL-#148874-v3-1824_Private_Equity_Fund_LP_(TJU)_-_AR_LPA_docprocessing.json"
output_dest_dir = "H:/management_fee_extraction/extracts_output/output5"

with open(data_file_path, "r") as json_file:
    data = json.load(json_file)

obj = KeywordFilterMethod()
paragraphs = obj.extract(data)

print(paragraphs)

paragraphs = {"extractsUsingPrescribedLanguage": paragraphs}

file_name = os.path.splitext(os.path.basename(data_file_path))[0]

filtered_images_json_file_path = os.path.join(output_dest_dir, f"{file_name}_filtered_images.json")
dump_json_file(filtered_images_json_file_path, paragraphs)

merged_content = obj.merge_content(paragraphs)
merged_content_json_file_path = os.path.join(output_dest_dir, f"{file_name}_prescribed_extracts.json")

print(merged_content_json_file_path)
print(merged_content)

dump_json_file(merged_content_json_file_path, merged_content)






import re
import os
import json

class KeywordFilterMethod:

    def extract(self, data) -> list[dict]:
        """
        Extract the data based on keywords
        :param data: JSON data containing logicalChunks
        :return: List of dictionaries containing extracted data
        """
        terms = [
            "Management Fee",
            "Management +Fee",
            "Servicing Fee",
            "Servicing +Fee",
            "Investment Advisory Fee",
            "Investment +Advisory +Fee",
            "Compensation",
            "Remuneration",
            "Expenses",
            "AIFM Fee",
            "AIFM +Fee",
        ]
        patterns = self.compile_search_patterns(terms)
        return self.extract_data_with_terms(data, patterns)

    def compile_search_patterns(self, terms):
        """
        Compile the search pattern using the terms provided
        :param terms: List of keywords
        :return: List of compiled regex patterns
        """
        return [re.compile(re.escape(term)) for term in terms]

    def search_terms_in_content(self, node_content, patterns):
        """
        Search the terms in content provided
        :param node_content: Content of the node
        :param patterns: List of regex patterns
        :return: True if any pattern matches, otherwise False
        """
        for pattern in patterns:
            if pattern.search(node_content):
                return True
        return False

    def extract_data_with_terms(self, data, patterns):
        """
        Extract the data based on keywords
        :param data: JSON data containing logicalChunks
        :param patterns: List of regex patterns
        :return: List of dictionaries containing extracted data
        """
        extracted_data = []
        logical_chunks = data.get('logicalChunks', [])  # Ensure it's a list
        for item in logical_chunks:
            if isinstance(item, list):  # Check if item is a list
                for node in item:
                    if isinstance(node, dict):  # Check if node is a dictionary
                        content = node.get('content', '')  # Safely get content
                        if self.search_terms_in_content(content, patterns):
                            extracted_data.append(item)
                            break
        return extracted_data

    def merge_content(self, json_data):
        """
        Merge the content of the extracted data
        :param json_data: JSON data containing extractsUsingPrescribedLanguage
        :return: Merged content dictionary
        """
        extracts = json_data.get('extractsUsingPrescribedLanguage', [])  # Ensure it's a list
        combined_strings = []
        for item in extracts:
            if isinstance(item, list):  # Check if item is a list
                combined_string = ' '.join(node.get('content', '') for node in item if isinstance(node, dict))
                combined_strings.append(combined_string)
        return {'extractsUsingPrescribedLanguage': combined_strings}

def dump_json_file(json_file_path, json_data):
    """
    Dump the JSON data into a file
    :param json_file_path: Path to save the JSON file
    :param json_data: Data to save
    :return: None
    """
    try:
        with open(json_file_path, "w") as json_file:
            json.dump(json_data, json_file, indent=4)
    except Exception as e:
        print(f"Error writing JSON file {json_file_path}: {e}")

if __name__ == "__main__":
    data_file_path = r"H:\management_fee_extraction\extracts_output\output5\LEGAL-#148074-v3-1824_Private_Equity_Fund_LP_(TJU)_-_AR_LPA_docprocessing.json"
    output_dest_dir = r"H:\management_fee_extraction\extracts_output\output5"

    # Load the JSON data from file
    with open(data_file_path, "r") as json_file:
        data = json.load(json_file)

    # Create an instance of KeywordFilterMethod and process the data
    obj = KeywordFilterMethod()
    paragraphs = obj.extract(data)

    # Prepare file paths for saving the results
    file_name = os.path.splitext(os.path.basename(data_file_path))[0]

    filtered_images_json_file_path = os.path.join(output_dest_dir, f"{file_name}_filtered_images.json")
    merged_content_json_file_path = os.path.join(output_dest_dir, f"{file_name}_prescribed_extracts.json")

    # Dump filtered paragraphs to a JSON file
    dump_json_file(filtered_images_json_file_path, {'extractsUsingPrescribedLanguage': paragraphs})

    # Merge content and dump to JSON file
    merged_content = obj.merge_content({'extractsUsingPrescribedLanguage': paragraphs})
    dump_json_file(merged_content_json_file_path, merged_content)

    # Print results for verification
    print(f"Filtered images JSON saved to: {filtered_images_json_file_path}")
    print(f"Merged content JSON saved to: {merged_content_json_file_path}")
    print("Merged Content:", json.dumps(merged_content, indent=4))

